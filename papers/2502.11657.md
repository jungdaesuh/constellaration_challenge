_Under consideration for publication in J. Plasma Phys._ 1

## **How does ion temperature gradient turbulence** **depend on magnetic geometry? Insights from** **data and machine learning**


**Matt Landreman** **[1]** _†_ **, Jong Youl Choi** **[2]** **, Caio Alves** **[2]** **, Prasanna**
**Balaprakash** **[2]** **, R. Michael Churchill** **[3]** **, Rory Conlin** **[1]** **, Gareth**
**Roberg-Clark** **[4]**


1 Institute for Research in Electronics & Applied Physics, University of Maryland, College
Park, MD 20742, USA

2 Oak Ridge National Laboratory, Oak Ridge, TN 37831, USA

3 Princeton Plasma Physics Laboratory, Princeton, NJ 08540, USA

4 Max Planck Institute for Plasma Physics, Wendelsteinstraße 1, 17491 Greifswald, Germany


(Received xx; revised xx; accepted xx)


Magnetic geometry has a significant effect on the level of turbulent transport in fusion
plasmas. Here, we model and analyze this dependence using multiple machine learning
methods and a dataset of _>_ 2 _×_ 10 [5] nonlinear gyrokinetic simulations of ion-temperaturegradient turbulence in diverse non-axisymmetric geometries. The dataset is generated
using a large collection of both optimized and randomly generated stellarator equilibria.
At fixed gradients and other input parameters, the turbulent heat flux varies between
geometries by several orders of magnitude. Trends are apparent among the configurations with particularly high or particularly low heat flux. Regression and classification
techniques from machine learning are then applied to extract patterns in the dataset.
Due to a symmetry of the gyrokinetic equation, the heat flux and regressions thereof
should be invariant to translations of the raw features in the parallel coordinate, similar
to translation invariance in computer vision applications. Multiple regression models
including convolutional neural networks (CNNs) and decision trees can achieve reasonable
predictive power for the heat flux in held-out test configurations, with highest accuracy for
the CNNs. Using Spearman correlation, sequential feature selection, and Shapley values
to measure feature importance, it is consistently found that the most important geometric
lever on the heat flux is the flux surface compression in regions of bad curvature. The
second most important geometric feature relates to the magnitude of geodesic curvature.
These two features align remarkably with surrogates that have been proposed based on
theory, while the methods here allow a natural extension to more features for increased
accuracy. The dataset, released with this publication, may also be used to test other
proposed surrogates, and we find that many previously published proxies do correlate
well with both the heat flux and stability boundary.


**1. Introduction**


The level of turbulent transport in magnetized plasmas depends on the magnetic field
geometry in complicated ways. In tokamaks, geometric factors include the aspect ratio,
elongation, and triangularity, while in stellarators, there is vast additional freedom in
the nonaxisymmetric shaping. While direct numerical simulation of the turbulence can


_†_ Email address for correspondence: mattland@umd.edu


2 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


be used to evaluate the transport for specific geometries, numerical calculations do not
immediately give insight into general parametric dependencies. Numerical turbulence
simulations also require non-negligible computation time and are noisy due to the chaotic
dynamics, making it challenging to include them directly in optimization or parametric
studies. Therefore, a variety of physics-based surrogates for the geometry-dependence of
turbulent transport have been proposed (Mynick _et al._ 2010; Xanthopoulos _et al._ 2014;
Mynick _et al._ 2014; Proll _et al._ 2015; Hegna _et al._ 2018; Mackenbach _et al._ 2022; Nakata &
Matsuoka 2022; Nakayama _et al._ 2023; Roberg-Clark _et al._ 2023; Goodman _et al._ 2024).
However, owing to advances in computing hardware and simulation software, it is now
possible to assemble large sets of turbulence simulation data that span a wide range
of possible geometries, even in the high-dimensional parameter space of stellarators.
Moreover, progress in machine learning (ML) methods and software provide many new
opportunities for understanding and exploiting this data. The purpose of this article is
to show how ML methods can discover patterns in the geometry-dependence of plasma
turbulence. Specifically, we present a new method for generating training data using
random 3D geometries, we compare the accuracy of several machine learning methods
at predicting the turbulent heat flux, and we show several interpretable ML techniques
that can identify which geometric factors determine the turbulent heat flux. This last
aspect shows that ML can be more than a black-box interpolation method to accelerate
computations- it can in fact also feed back into more traditional physics analysis. For
example, the patterns in the data identified here can provide evidence for or against
physics-inspired approximate models, and motivate future theoretical studies.
The methods here extend prior work in several ways. ML methods, specifically neural
networks, have been applied previously as surrogates for transport in tokamaks (Meneghini _et al._ 2014; Citrin _et al._ 2015; Meneghini _et al._ 2017; Narita _et al._ 2019; Honda &
Narita 2019; van de Plassche _et al._ 2020; Boyer & Chadwick 2021; Abbate _et al._ 2021;
Li _et al._ 2024). In contrast to this previous work, here we allow for nonaxisymmetric
shaping, in which case the geometric parameter space is much higher dimensional. In
the context of stellarators, neural networks have been applied to neoclassical transport
coefficients (Wakasa _et al._ 2007) and magneohydrodynamic (MHD) equilibria (Merlo
_et al._ 2021; Curvo _et al._ 2024). For stellarator turbulent transport, regressions have
been performed using theory-based analytic models with tuning parameters (Nakayama
_et al._ 2023). Theory-based surrogates for transport in stellarators have previously been
compared to gyrokinetic simulations for a small number of geometries _N_, e.g. _N_ = 10
in Proll _et al._ (2015), _N_ = 4 in Mackenbach _et al._ (2022), or _N_ = 9 in Roberg-Clark
_et al._ (2023). In the present work the number of geometries considered is increased by
4 orders of magnitude to _N >_ 10 [5] . Compared to these earlier studies, the work here is
also unique in the new method of data generation using random novel 3D geometries, in
the application of both neural-network and non-neural-network-based ML methods, and
in the use of interpretable ML methods to identify important features in the geometry.
Finally, in supplemental material available at (Landreman 2025), we are making the
training dataset publicly available, so other researchers can test the accuracy of different
proposed turbulence surrogates.
In order to obtain ML models for this problem that are interpretable, we demonstrate a
novel approach that combines a large library of candidate features with forward sequential
feature selection (FSFS) and traditional regression and classification methods. The new
approach here is used to ensure that the models respect a translation-invariance in
the gyrokinetic equation: the heat flux should be invariant to periodic translation of
all geometric quantities in the direction along the magnetic field (see section 2). The
invariance is guaranteed in our models by using a library of features that respect the


_How does ITG turbulence depend on magnetic geometry?_ 3


symmetry. The use of a combinatorial library of candidate features in our method is
reminiscent of SINDy (sparse identification of nonlinear dynamics) (Brunton _et al._ 2016),
except that we are not interested in time-dependence, and we obtain parsimony through
FSFS rather than via sparsity-promoting optimization. Our method is also reminiscent of
symbolic regression (Koza 1994) in that we seek symbolic expressions for interpretability.
However unlike SINDy and symbolic regression, the method here combines the symbolic
feature library with additional regression and classification models (decision trees and
nearest-neighbors) to efficiently allow extra nonlinearity.
We find a remarkable alignment between the results of interpretable ML analysis
here and recently proposed physics-inspired surrogates for turbulence. Across several ML
regression methods and several ways to measure feature importance, the most important
two features are consistent. The most important geometric factor is found to be the
flux surface compression _|∇ψ|_ in regions of bad curvature, where 2 _πψ_ is the toroidal
flux, reflecting the gradient drive in real space in regions of linear instability. This factor
has been used as an optimization objective function for ion temperature gradient (ITG)
turbulence by Mynick _et al._ (2014), Xanthopoulos _et al._ (2014), Stroteich _et al._ (2022),
and Goodman _et al._ (2024), and a more complicated objective with these elements was
used previously by Mynick _et al._ (2010). The second most important geometric factor
identified in our analysis is the average magnitude of the geodesic curvature, equivalent
to the radial magnetic drift _∝_ **B** _× κ · ∇ψ_ where _κ_ is the curvature. This quantity has
been proposed as a correlate of turbulence by Xanthopoulos _et al._ (2011) and Nakata &
Matsuoka (2022). The theoretical motivation for this quantity is related to zonal flows:
larger geodesic curvature leads to stronger linear damping of zonal flows, resulting in
higher levels of saturated heat flux. For both of two most important features, our analysis
matches the theoretical predictions for the sign of the correlation: increased _|∇ψ|_ and
increased absolute geodesic curvature correlate with heat flux increase.
Since ML methods are most effective when large amounts of data are available that
cover the parameter space of interest, we make several simplifying assumptions in this
work. First, we consider the electrons to be adiabatic. This choice makes the direct
numerical simulations faster by a factor of _∼_ ~~�~~ _m_ _i_ _/m_ _e_, where _m_ _i_ and _m_ _e_ are the

ion and electron masses. Hence, the maximum stable time step is not limited by the
electron parallel speed, increasing the number of simulations that can be run for a given
computational budget. Compared to simulations with adiabatic electrons, simulations
with kinetic electrons have higher heat fluxes (Chen _et al._ 2003), and the difference
depends on magnetic geometry (McKinney _et al._ 2019; Goodman _et al._ 2024), so some
conclusions of the analysis here may be modified if revisited with kinetic electrons. By
the use of adiabatic electrons, our analysis is necessarily electrostatic, and focuses on ion
temperature gradient turbulence.
When attempting to model the turbulent heat flux, there are two natural options for
the independent geometric variables: one could either use shape parameters of the plasma,
or the geometric quantities appearing directly in the gyrokinetic equation. Examples of
the former include elongation and triangularity, or Fourier amplitudes of the boundary
surface, while examples of the latter include the field magnitude _|B|_ and the guiding
center drift component _B_ _[−]_ [3] **B** _× ∇B · ∇ψ_ . By taking the independent variables to be
the plasma shape parameters, an ML regression effectively models physics of both MHD
equilibrium and turbulence. If the independent variables are instead taken to be the
geometry factors in the gyrokinetic equation, the ML regression becomes a model only
for the turbulence, without including MHD equilibrium physics. Here we take the latter
approach, because by focusing on a narrower aspect of the physics, there is greater hope
for interpretability of the model. At the same time, we nonetheless generate the geometric


4 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


inputs to the gyrokinetic equation from actual global MHD equilibria so correlations and
constraints among the geometric features are respected.
To introduce the methods here in detail, we begin in the following section by reviewing
the gyrokinetic equation used in the direct numerical simulations, highlighting the
geometric inputs and its translation invariance. This translation invariance is important
because we will want ML models to respect this symmetry. The procedure for generating
data, including both MHD equilibria and turbulence simulations, is then detailed in
section 3. Neural network fits to the data are presented in section 4. Section 5 presents
alternative ML methods that do not use neural networks, allowing for greater interpretability at the expense of reduced accuracy. These alternative methods require manual
feature engineering and feature selection. In section 6 it is demonstrated how the same
dataset can be used to assess other proposed proxies for turbulence, by evaluating the
accuracy of several ITG objective functions from earlier papers. Finally, we conclude and
discuss future directions in section 7.


**2. Relevant properties of the gyrokinetic equation**


Here we review the electrostatic gyrokinetic turbulence model for a flux tube to
identify the geometric features that appear. A similar discussion can be found in Jorge
& Landreman (2020). The magnetic field can be written **B** = _∇ψ × ∇α_ where 2 _πψ_ is
the toroidal flux and _α_ is a field line label. Coordinates ( _x, y, z_ ) are introduced where _z_
is the arclength along the field line, satisfying **B** _· ∇z_ = _B_, and _x_ = _x_ ( _ψ_ ) and _y_ = _y_ ( _α_ )
are functions of ( _ψ, α_ ) that each resemble a distance. (The results of this section are
independent of the exact choice of these two functions.) We consider a flux tube, for
which the domain’s small extent in _x_ and _y_ is on the order of a few gyroradii, much
smaller than typical equilibrium scales like the minor radius. Therefore _x_ and _y_ (or _ψ_
and _α_ ) can be considered fixed for all equilibrium quantities. However we do care about
gyroradius-scale fluctuations in the distribution function and electrostatic potential, so
the _x_ - and _y_ -dependence of these perturbations is retained. Fluctuating quantities are
taken to vary with _z_ on the same scale length as the equilibrium, and the extent of the
flux tube domain in _z_ is of a comparable scale.
The fluctuating electrostatic potential _Φ_ is Fourier expanded as


_Φ_ ( _x, y, z, t_ ) = � _Φ_ ˆ **k** ( _z, t_ ) exp( _ik_ _x_ _x_ + _ik_ _y_ _y_ ) _,_ (2.1)


**k**


where **k** denotes ( _k_ _x_ _, k_ _y_ ). The distribution function of species _s_ is expanded as


_f_ _s_ = _F_ _Ms_ _−_ _[e]_ _[s]_ _[Φ]_ _F_ _Ms_ + _h_ _s_ _,_ (2.2)

_T_ _s_


where _F_ _Ms_ = _n_ _s_ (2 _π_ ) _[−]_ [3] _[/]_ [2] _v_ _s_ _[−]_ [3] exp( _−v_ [2] _/_ (2 _v_ _s_ [2] [))][ is the leading-order Maxwellian with den-]
sity _n_ _s_ and temperature _T_ _s_, _v_ is the speed, _v_ _s_ = � _T_ _s_ _/m_ _s_ is the thermal speed, and _e_ _s_ is

the species charge. The nonadiabatic part of the distribution, _h_ _s_, has a Fourier expansion


_h_ _s_ ( _X, Y, z, v_ _||_ _, µ, t_ ) = � _h_ ˆ _s,_ **k** ( _z, v_ _||_ _, µ, t_ ) exp( _ik_ _x_ _X_ + _ik_ _y_ _Y_ ) _,_ (2.3)


**k**


where ( _X, Y_ ) are the values of ( _x, y_ ) at the guiding center position, _µ_ = _v_ _⊥_ [2] _[/]_ [(2] _[B]_ [)][, and]
_v_ _||_ and _v_ _⊥_ are the velocity components along **B** or perpendicular to it. The nonadiabatic


_How does ITG turbulence depend on magnetic geometry?_ 5


distribution is computed by evolving the gyrokinetic equation (Frieman & Chen 1982),



�



_h_ [ˆ] _s,_ **k** + _v_ _||_ _∂h_ [ˆ] _s,_ **k**

_∂t_ _∂z_



_∂h_ [ˆ] _s,_ **k**

_[∂B]_

_∂z_ _∂v_



_∂h_ [ˆ] _s,_ **k**



_h_ _s,_ **k** _−_ _µ_ _[∂B]_

_∂z_ _∂z_



_T_ _s_



_h_ _s,_ **k**

_∂v_ _||_ + **v** _d_ _·∇h_ [ˆ] _s,_ **k** + _N_ _s,_ **k** = _[e]_ _[s]_ _[J]_ [0] _T_ _[,]_ **[k]** _s_ _[F]_ _[Ms]_



_∂Φ_ [ˆ] **k**

_∗s_ _[Φ]_ [ˆ] **[k]**
_∂t_ [+] _[ iω]_ _[T]_

�



+ _C_ _s,_ **k** _._



(2.4)
Here, **b** = _B_ _[−]_ [1] **B** is the unit vector along the magnetic field, _ω_ _∗_ _[T]_ _s_ = _ω_ _∗s_ [1 +
_η_ _s_ ( _m_ _s_ _v_ [2] _/_ 2 _T_ _s_ _−_ 3 _/_ 2)], and _η_ _s_ = _d_ ln _T_ _s_ _/d_ ln _n_ _s_ . Also, _ω_ _∗s_ = [ _σk_ _y_ _T_ _s_ _/_ ( _e_ _s_ _B_ _ref_ )] _d_ ln _n_ _s_ _/dx_,
and _σ_ = ( _B_ _ref_ _/B_ [2] ) **B** _· ∇x × ∇y_ = _B_ _ref_ ( _dx/dψ_ )( _dy/dα_ ) is constant over the flux tube
domain to leading order. A constant reference field strength is denoted _B_ _ref_, and _C_ _s,_ **k** is
the gyroaveraged collision operator. The factor _J_ 0 _,_ **k** is shorthand for the Bessel function
_J_ 0 ( _k_ _⊥_ _v_ _⊥_ _/Ω_ _s_ ) where _k_ _⊥_ = _|k_ _x_ _∇x_ + _k_ _y_ _∇y|_, and _Ω_ _s_ = _e_ _s_ _B/m_ _s_ is the gyrofrequency. Also,
the magnetic drift is

**v** _d_ = 2 _[m]_ _e_ _s_ _[s]_ _B_ _[v]_ _⊥_ [2][3] **[B]** _[ × ∇][B]_ [ +] _me_ _ss_ _Bv_ [2] _||_ [2] **[B]** _[ ×][ κ,]_ (2.5)

where _κ_ = **b** _· ∇_ **b** is the curvature, and _N_ _s,_ **k** denotes the nonlinear term:



_N_ _s,_ **k** = �


**k** _[′]_



_σJ_ 0 _,_ **k** _B_ _′_ _Φ_ [ˆ] _ref_ **k** _′_ _h_ [ˆ] _s,_ **k** _′′_ ( _k_ _y_ _[′]_ _[k]_ _x_ _[′′]_ _[−]_ _[k]_ _x_ _[′]_ _[k]_ _y_ _[′′]_ [)] (2.6)



where **k** _[′′]_ = **k** _−_ **k** _[′]_ . Note that where _v_ [2] is needed in _F_ _Ms_ and _ω_ _∗_ _[T]_ _s_ [, it can be computed]
from the independent variables via _v_ [2] = _v_ _||_ [2] [+ 2] _[µB]_ [, so the magnetic geometry enters via]
_B_ .

The system is closed with the quasineutrality equation:



_Φ_ ˆ **k** �


_s_



_eT_ [2] _s_ _[n]_ _s_ _[s]_ = � _e_ _s_

_s_



_d_ [3] _v J_ 0 _,_ **k** _h_ [ˆ] _s,_ **k** _._ (2.7)
�



The integral over velocity space for these velocity coordinates � _d_ [3] _v_ = 2 _π_ � _−∞∞_ _[dv]_ _[||]_ � 0 _∞_ _dµ B_
depends on the magnetic field via _B_ .
Once the potential and distribution function are computed, we are principally interested in the turbulent heat flux for the ions, _s_ = _i_ :



_Q_ = �


**k**



_d_ [3] _v_ _[m]_ _[i]_ _[v]_ [2]

2

��




_[i]_ _[v]_ [2] _h_ ˆ _i,_ **k** _ik_ _y_ _σJ_ 0 _,_ **k** _Φ_ [ˆ] _−_ **k**

2 _B_



_B_ _ref_



�



_,_ (2.8)



_−_ 1
where _⟨. . .⟩_ denotes a flux surface average: _⟨u⟩_ = �� _dℓ/B_ � � _dℓu/B_ for any quantity

_u_ .

Now, let us examine the places where the magnetic geometry enters the above model.
From the **v** _d_ term in (2.4), which can be expanded as


( **v** _d_ _· ∇x_ ) _ik_ _x_ _h_ [ˆ] _s,_ **k** + ( **v** _d_ _· ∇y_ ) _ik_ _y_ _h_ [ˆ] _s,_ **k** _,_ (2.9)


we see that the _∇x_ and _∇y_ components of the magnetic drift (2.5) appear. Note that
**b** _×∇B ·∇ψ_ = **B** _×_ _κ_ _·∇ψ_ exactly for an MHD equilibrium, even if the ratio _β_ of thermal
to magnetic pressure is not small, so the two terms in **v** _d_ _· ∇x_ can be combined as a
multiple of **b** _× ∇B · ∇x_ . Next, in the argument of the Bessel functions,

_k_ _⊥_ = ~~�~~ _k_ _x_ [2] _|∇x|_ [2] + 2 _k_ _x_ _k_ _y_ _∇x · ∇y_ + _k_ _y_ [2] _|∇y|_ [2] _,_ (2.10)


the quantities _|∇x|_ [2], _∇x · ∇y_, and _|∇y|_ [2] appear. Finally, _B_ appears in numerous places:
through _Ω_ _s_ in the Bessel functions, in the flux surface average in the heat flux, in


6 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_








|0|Col2|
|---|---|
|0<br>5|0<br>5|




Figure 1. Translation-invariance of the gyrokinetic-quasineutrality system. Left: A periodic
translation in _z_ is applied to all of the _z_ -dependent inputs to the gyrokinetic system, eq (2.11).
Only four of the seven are shown for simplicity, but all are translated. Right: The average heat
flux is unchanged by the translation.


_v_ ( _v_ _||_ _, µB_ ), in � _d_ [3] _v_, and via _∂B/∂z_ in (2.4). Thus, we find that the raw geometric features
entering the gyrokinetic model are the following seven functions of _z_ :



_B,_ **[B]** _[ × ∇][B][ · ∇][x]_



_B_ _[B]_ [3] _[ · ∇][x]_ _,_ **[B]** _[ × ∇]_ _B_ _[B]_ [3] _[ · ∇][y]_



_B_ _[B]_ [3] _[ · ∇][y]_ _,_ **[B]** _[ ×]_ _B_ _[ κ]_ [2] _[ · ∇][y]_



_, |∇x|_ [2] _, ∇x · ∇y, |∇y|_ [2] _._ (2.11)
_B_ [2]



As stated previously, the _x_ and _y_ variation of these equilibrium quantities over the flux
tube simulation domain is negligible due to the small extent of the domain in these
coordinates, so we only need the variation of these quantities in _z_ along a field line. If a
parallel coordinate _z_ other than arclength is used, there would be an additional geometric
input **b** _· ∇z_ required in the parallel streaming term of (2.4).
We can now understand a translation-invariance property of the gyrokinetic model
above, which ML models should preserve. The key idea is that _z_ does not appear explicitly
anywhere in the model - _z_ -dependence in the equations enters only through the functions
in (2.11). To precisely state the translation-invariance property, suppose the gyrokineticquasineutrality system is solved with periodic boundary conditions in _z_ . Then the heat
flux is exactly unchanged if a periodic shift _f_ ( _z_ ) _→_ _f_ ( _z_ + _∆_ ) is applied where _f_ indicates
each of the seven raw features (2.11) along with _Φ_ and _h_ _i_, where the shift _∆_ is the same
for all quantities. If the seven raw features are shifted in this way but the initial conditions
for _Φ_ and _h_ _i_ are not, the detailed dynamics will change, but under the usual assumption
that the mean heat flux is independent of the initial condition, the mean heat flux would
still be invariant. We confirmed that this translation-invariance indeed holds for nonlinear
GX simulations, as shown in figure 1. If a twist-and-shift boundary condition (Beer _et al._
1995; Martin _et al._ 2018) is used in _z_ instead of periodic boundary conditions, and a
finite number of _k_ _x_ and _k_ _y_ modes are included, the translation-invariance will be slightly
violated, because the outgoing distribution function is set to zero at the unlinked flux
tube ends. However if the simulation is well resolved with respect to the number of _k_ _x_
modes, the heat flux is evidently approximately independent of the number of times a
tube segment links to itself, and hence approximately independent of where the outgoing
distribution function is set to zero. Thus the breaking of translation-invariance should
be small.
For all results that follow, the raw features (2.11) are normalized by a reference length
_L_ _ref_ and reference field strength _B_ _ref_ . The effective minor radius _a_ is adopted for _L_ _ref_,


_How does ITG turbulence depend on magnetic geometry?_ 7


and _B_ _ref_ is defined by equating _πa_ [2] _B_ _ref_ = 2 _π|ψ_ _a_ _|_, where _ψ_ _a_ is the value of _ψ_ at the
equilibrium boundary. We choose the perpendicular coordinates to be _x_ = _a_ � _ψ/ψ_ _a_ and

_y_ = _−αx_ sign( _ψ_ _a_ ), so _σ_ = _−_ 1.


**3. Dataset generation**


In this section, we first present the method used to generate stellarator MHD equilibria
with diverse geometries. Next, details of the nonlinear gyrokinetic simulations in these
equilibria are given. After describing some general properties of the dataset, a few
configurations are highlighted that are interesting due to their extreme values of the
heat flux.


3.1. _Magnetohydrodynamic equilibria_


An MHD equilibrium is determined by the boundary shape together with two functions
of the toroidal flux, typically the pressure and enclosed toroidal current (Kruskal &
Kulsrud 1958). It is not obvious how to best sample this space, particularly the space of
boundary shapes. Boundaries with self-intersections or other such pathologies should be
avoided. Also, a compromise must be struck between preserving similarity of the shapes
to “real” devices (built experiments or theoretical configurations designed through serious
optimization) while also allowing for new possible geometries.
To balance these considerations, we assemble a set of 23,577 equilibria drawn from three
groups. The first group has heliotron-like rotating ellipse shapes, in which parameters
of the shape (number of field periods, aspect ratio, elongation, axis torsion, beta) are
sampled randomly. Equilibria in the second group are taken from the QUASR database
of quasi-axisymmetric (QA) and quasi-helically symmetric (QH) configurations (Giuliani
2024; Giuliani _et al._ 2024). We use both the original QUASR configurations, which
are all vacuum fields, and also generate new configurations by adding pressure while
keeping the plasma boundary shape fixed. For the third group, random boundary shapes
are generated by sampling Fourier modes that have been fit to a dataset of previous
stellarator shapes. The combined set of configurations includes values of aspect ratio
ranging from 2.9 to 10, volume-averaged beta from 0 to 5%, and number of field periods
from 2 through 8. Thus, the set of equilibria is diverse, and includes both omnigenous
and non-omnigenous geometries. All equilibria have the same minor radius and same
boundary toroidal flux, resulting in the same normalizing length and normalizing field
strength, so the gyro-Bohm normalizations are identical. Examples of equilibria from
the three classes are shown in figures 2-4. More details of the procedures for generating
equilibria are given in appendix A.


3.2. _Gyrokinetic simulations_


In each equilibrium, we extract at least four flux tubes, more in the QUASR vacuum
configurations so as to include more omnigenous geometries. The radial location _ρ_ = _[√]_ ~~_s_~~
for each flux tube is sampled randomly from [0 _,_ 1], where _s_ = _ψ/ψ_ _a_ is the normalized
toroidal flux. All flux tubes are stellarator-symmetric, with at least one flux tube in
every configuration centered on each of the points ( _θ, ϕ_ ) = (0 _,_ 0), ( _π,_ 0), (0 _, π/n_ fp ), and
( _π, π/n_ fp ). Nothing in the procedure limits the method to stellarator-symmetric equilibria
or flux tubes. The total number of flux tube geometries in the dataset is 100,705. The
length of the flux tubes in real space was chosen to be the same for every configuration,
75 times the minor radius, which for aspect ratio 6 corresponds to roughly two full
toroidal transits. Due to the variation in _ι_, the number of poloidal transits varied between


8 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


Figure 2. Examples of the rotating-ellipse equilibria included in the dataset. 2D plots show the
cross sections at which the toroidal angle is 0, 1 _/_ 4, 1 _/_ 2, and 3 _/_ 4 of a field period. 3D images
show each configuration from two angles, with color indicating _|B|_ (red = high, blue = low)
and field lines in black. Left columns: configurations in which the boundaries are centered on
a circle. Right columns: configurations in which the boundaries are centered on a curve with
torsion.


configurations. By making all flux tubes have the same physical length, distances in the
_z_ coordinate can be compared meaningfully between flux tubes, and for each integer _j_,
the _j_ th Fourier series coefficients in all flux tubes correspond to the same physical _k_ _||_ .
These properties may be advantageous for extracting patterns in the dataset.

Nonlinear electrostatic simulations with adiabatic electrons were then carried out with
the GX code (Mandell _et al._ 2024). We run GX twice for each flux tube, resulting in
two datasets each of size _N_ = 100 _,_ 705. In the first dataset, the temperature and density
gradients were fixed to the same values for all flux tubes. In the second dataset, these
gradients were chosen randomly for each flux tube. Using the latter dataset, models can
potentially find interactions between geometry and gradients in their effect on the heat
flux; for example, the dependence on geometry may differ close to the critical gradient
compared to far above the critical gradient. However we also assembled the dataset with
fixed gradients since it enables several of the analyses in section 5 and allows us to focus
cleanly on the effects of geometry. For the fixed-gradient dataset, we take _a/L_ _T i_ = 3
and _a/L_ _n_ = 0 _._ 9, where _a/L_ _T i_ = _−_ ( _a/T_ _i_ ) _dT_ _i_ _/dx_ and _a/L_ _n_ = _−_ ( _a/n_ ) _dn/dx_ are the
normalized gradients of ion temperature and density, reflecting typical measurements at
the _s_ = 0 _._ 5 surface of W7-X (Beurskens _et al._ 2021; Lunsford _et al._ 2021; Zhang _et al._
2023). For the varying-gradient dataset, each simulation has _a/L_ _T i_ and _a/L_ _n_ sampled
randomly within plausible experimental ranges.
Additional details of the turbulence simulations are given in appendix B.


_How does ITG turbulence depend on magnetic geometry?_ 9


Figure 3. Examples of the QUASR quasi-axisymmetric and quasi-helically symmetric equilibria
included in the dataset. 2D plots show the cross sections at which the toroidal angle is 0, 1 _/_ 4,
1 _/_ 2, and 3 _/_ 4 of a field period. 3D images show each configuration from two angles, with color
indicating _|B|_ (red = high, blue = low) and field lines in black.


3.3. _Configurations with very low or high heat flux_


The distribution of heat fluxes for the dataset is shown in figure 5. It is striking that
even for the dataset with fixed gradients, _Q_ varies by over four orders of magnitude over
the data. This variation is evidently due purely to the geometry.
It is interesting to examine configurations with particularly low or particularly high
heat flux. Several such flux tubes are displayed in figure 6. The columns represent six flux
tubes from the dataset. In the fixed gradient dataset with _a/L_ _T_ = 3 and _a/L_ _n_ = 0 _._ 9, the
first three tubes are stable, while the other three have _Q >_ 500, even though the gradients
are identical. These flux tubes are all taken from _n_ _fp_ = 3 equilibria from the group with
random boundary Fourier modes. The first six of the seven rows show the geometric
inputs to the gyrokinetic-quasineutrality system. To simplify the figure, _B_ _[−]_ [3] **B** _×∇B ·∇y_
is not shown since it is similar to _B_ _[−]_ [2] **B** _×_ _κ_ _·∇y_ . The bottom row shows the contribution
to the heat flux _Q_ as a function of _z_ . For each of the seven rows, the vertical scales are
the same for each column to allow comparison.
Several patterns are apparent. The configurations with highest heat flux have regions
with very large _|∇x|_ [2] . The high-heat-flux tubes also have larger magnitudes of _B_ _[−]_ [3] **B** _×_
_∇B · ∇x_ . The stable tubes have more negative values of _B_ _[−]_ [2] **B** _× κ · ∇y_, meaning mostly
good curvature. All of these patterns foreshadow findings in section 5.
For the geometry-gradient pairings with very large heat flux, where the gyroBohmnormalized _Q_ is not small compared to 1 _/ρ_ _∗_, with _ρ_ _∗_ the ratio of typical gyroradius
to macroscopic scale, the ordering used to derive the gyrokinetic model may no longer
be accurate. Therefore these simulation runs may not accurately describe real physical
scenarios. Nonetheless it is still reasonable to consider the _δf_ -gyrokinetic model as an
abstract mathematical function, a map from seven functions (the geometry) and two


10 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


Figure 4. Examples of the equilibria generated with random boundary Fourier modes. 2D plots
show the cross sections at which the toroidal angle is 0, 1 _/_ 4, 1 _/_ 2, and 3 _/_ 4 of a field period. 3D
images show each configuration from two angles, with color indicating _|B|_ (red = high, blue =
low) and field lines in black.







Figure 5. Distribution of heat fluxes for the fixed-gradient and varied-gradient datasets. In the
latter, 30% of the simulations were stable, with _Q ≈_ 0. Simulations with _Q <_ 0 _._ 1, considered
stable, are included in the leftmost bar.


real numbers (the gradients) to a real number ( _Q_ ), and to develop approximations of
this function. Moreover, since surrogates will be more accurate at interpolation than
extrapolation, it is desirable to include at least a few of these extreme data points in the
dataset.


_How does ITG turbulence depend on magnetic geometry?_ 11





























Figure 6. Some trends are apparent between flux tubes with very low or high heat flux. The
columns show six flux tubes from the _n_ _fp_ = 3 equilibria with random boundary Fourier modes,
the first three stable, the last three with very high _Q_ at the same gradients. The top six rows are
the inputs to the gyrokinetic-quasineutrality system ( _B_ _[−]_ [3] **B** _× ∇B · ∇y_ is omitted for simplicity
since it is similar to _B_ _[−]_ [2] **B** _× κ · ∇y_ ), while the bottom row shows the contribution to the total
heat flux vs _z_ .


3.4. _Weighting of errors for regression_


When fitting regression models to the heat flux data and assessing their accuracy, some
care is required to measure and weigh errors appropriately. The first issue is that the heat
flux can span several orders of magnitude. If a model makes an absolute prediction error
of 1 in gyro-Bohm units, this error is significant if the true heat flux is 0.5, but it is a
relatively minor error if the true heat flux is 100. Moreover, the standard deviation (over
time) of the heat flux within one simulation tends to scale approximately linearly with
the mean heat flux, so high- _Q_ cases have higher uncertainty than low- _Q_ cases. For these
reasons, it is natural to measure errors in a relative rather than absolute sense. Weighing
errors this relative sense can be achieved by performing regression on ln _Q_ rather than
_Q_ directly. In particular, models should be scored based on the mean squared error or
coefficient of determination _R_ [2] evaluated using ln _Q_ . Thus, in the standard definition
_R_ [2] = 1 _−_ �� _j_ [(] _[y]_ _[j]_ _[ −]_ _[f]_ _[j]_ [)] [2] [�] _/_ �� _j_ [(] _[y]_ _[j]_ _[ −]_ _[y]_ [¯][)] [2] [�] where _y_ _j_ are the true target values, ¯ _y_ is their



_R_ [2] = 1 _−_ �� _j_ [(] _[y]_ _[j]_ _[ −]_ _[f]_ _[j]_ [)] [2] [�] _/_ �� _j_ [(] _[y]_ _[j]_ _[ −]_ _[y]_ [¯][)] [2] [�] where _y_ _j_ are the true target values, ¯ _y_ is their

mean, and _f_ _j_ are the predicted values, one would take _y_ _j_ and _f_ _j_ to be the true and
predicted values of ln _Q_ rather than of _Q_ itself.
However, an additional important consideration is that some simulations are stable.
In a stable simulation, the heat flux is typically slightly positive but _≪_ 1 at the end of
the computation due to decay of the initial perturbation, and the exact value of _Q_ is not
very meaningful. There is not a steady state to average over, and the final _Q_ is influenced
by the magnitude of the initial condition. If the heat flux from a simulation is _Q_ = 10 _[−]_ [12]

and a regression model predicts it to be 10 _[−]_ [4], the model is accurately predicting that
the system is stable (or nearly so), but scoring the model based on the error in ln _Q_
would treat the prediction error to be large. In some stable simulations where _|Q|_ has



_j_ [(] _[y]_ _[j]_ _[ −]_ _[f]_ _[j]_ [)] [2] [�] _/_ ��


12 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


very small magnitude, _Q_ may even be slightly negative, in which case ln _Q_ cannot even
be evaluated.

There are several possible approaches to account for these considerations. One approach is to consider a classification problem for stability vs instability separately from
the regression problem. In this case, the regression only needs to be evaluated if the
classifier has first predicted instability, i.e. in the unstable region of parameter space, so
the regression can be fit using only the subset of the data in which _Q_ exceeds some small
threshold. Here we adopt this approach with a threshold of 0.1, and our experience is that
results are insensitive to the exact choice of threshold. With this approach, the training
set does not include any points with _Q <_ 0 _._ 1 or negative _Q_, so it is straightforward to
use ln _Q_ as the regression target. The full dataset is still used for training the classifier. If
the classifier is interpretable, it directly provides insight into the factors that determine
the critical gradient.
Several other approaches are possible. As in van de Plassche _et al._ (2020), a regression
could be fit by minimizing a custom objective that penalizes errors in _Q_ (or ln _Q_ ) only
in the unstable region, while in the stable region, only penalizing positive values of _Q_,
to prevent spurious prediction of instability. However, not all regression methods allow
for a custom objective, e.g. nearest-neighbors. Or, regression could be performed on
the full dataset with a standard objective after all values of _Q_ below a threshold are
replaced by the threshold. While straightforward to implement, this method introduces
non-smoothness in the predicted _Q_ ; this is not a problem for decision tree models but it
may introduce inaccuracies with smooth models like neural networks. A fourth option is
to perform regression on the full dataset using the target quantity


ˆ
_Q_ = ln(1 + _Q_ ) _._ (3.1)


For _Q ≫_ 1, the quantity _Q_ [ˆ] behaves like ln _Q_, while for _Q ≪_ 1, _Q_ [ˆ] varies approximately
linearly with _Q_ . Therefore a regression model that is fit by minimizing the mean squared
error in _Q_ [ˆ], or _R_ [2] computed from _Q_ [ˆ], prediction errors will effectively be based on relative
error in _Q_ for large _Q_, but based on absolute error for small _Q_, as desired. We have tried
the first, third, and fourth of these methods, and our experience is that they give very
similar results. For the rest of the discussion we use the first method.


**4. Convolutional neural network models**


We develop neural network surrogates to predict heat flux values from the simulations
described above. Our approach involves two key strategies: (i) designing a neural network
that remains invariant to cyclic permutations and (ii) ensuring reliable predictions
through an ensemble of the top-k models selected via hyperparameter optimization.


4.1. _Cyclic invariant neural network_


Our goal is to develop a surrogate model based on a neural network that maintains
invariance to cyclic permutations inherent to the gyrokinetic system. An analogy exists
with computer vision research, where translation invariance is important as well: if
a cat is present in an image, it should be recognized as a cat even if its location
within a bitmap is shifted. A standard approach to achieving approximate translationinvariance in computer vision is through convolutional (as opposed to fully-connected)
neural networks. This type of neural network contains convolutional layers, in which the
spatial data are convolved with a kernel, which is a translation-equivariant operation.
Between convolutional layers, pooling layers then reduce the spatial resolution, typically
by a factor of two, and a sufficient number of alternating convolutional and pooling


_How does ITG turbulence depend on magnetic geometry?_ 13


layers converts the spatial data to approximately translation-invariant features. While
computer vision applications use two-dimensional convolution and pooling operations,
for the turbulence application here we will use one-dimensional convolution and pooling.
During training, we further reinforce the translation-invariance by augmenting the
dataset with a sufficient number of sequences that are randomly permuted (cyclically) in
_z_, allowing the network to learn patterns that are independent of any particular alignment
with respect to _z_ . This strategy prevents the model from developing biases toward specific
alignments, ultimately improving generalization and stability.
Another key aspect of our surrogate model development is the use of ensemble learning,
a powerful machine-learning technique that aggregates predictions from multiple base
models to improve overall performance. Ensemble methods have proven to be highly
effective in reducing prediction variance, mitigating model biases, and improving generalization, making them well-suited for applications involving complex, high-dimensional
data such as ours. By leveraging an ensemble of multiple models, we aim to construct
a predictive framework that is not only more accurate but also more stable when
encountering unseen data. The core advantage of ensemble learning is its ability to
balance trade-offs between different models—some models may be more sensitive to
specific features, while others may capture different patterns. By combining them, we
create a more comprehensive representation of the underlying physical system.
To implement this strategy, we design our base model to be highly flexible, allowing
variations in neuron count, layer depth, kernel shape, activation functions, etc., also
known as hyperparameters. This flexibility is essential for tuning the model to achieve
optimal predictive performance across different configurations. However, selecting the
best architecture requires careful exploration of the hyperparameter space. To efficiently
search for the best hyperparameters, we employ DeepHyper (Balaprakash _et al._ 2018;
Egelé _et al._ 2023), an advanced hyperparameter optimization tool designed for deep
learning. DeepHyper allows us to automate the search for high-performing configurations,
reducing manual tuning efforts and accelerating model development. We will discuss the
details of this optimization process in subsequent sections.
With these considerations in mind, we design our surrogate neural network using a
structured approach that consists of three main components, shown in Figure 7:


(i) **Feature Extraction with Convolutional Layers** : The first component comprises
_n_ consecutive layers of neural network blocks, each containing 1D convolutional layers
(Conv1D). These layers are responsible for extracting spatial features from the input
sequences while preserving cyclic invariance. Each convolutional layer processes _x_
data channels and outputs _y_ number of transformed channels, which are subsequently
normalized using batch normalization to stabilize training and improve convergence. A
max-pooling layer follows each block to downsample the extracted features, reducing
computational complexity while retaining the most relevant information.
(ii) **Global Average Pooling (GAP) for Dimensionality Reduction** : To further
condense the extracted feature maps, we integrate global average pooling (GAP).
Unlike traditional pooling methods that operate on small local regions, GAP computes
the average activation value for each feature map across all spatial dimensions. This
not only reduces the number of parameters but also ensures that the model focuses on
high-level feature representations rather than localized details, making it particularly
effective for cyclic data.
(iii) **Fully Connected Layers for Prediction** : The final stage consists of _m_ fully
connected linear layers that process the compact feature representation and map it
to the target variable: predicted heat flux averages. These layers refine the extracted


14 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_



Convolutional



Fully-connected

Layers

x2



Layers

x5



Global

Average

Pooling











Figure 7. The surrogate model architecture to learn heat flux averages using a structured
neural network. It consists of three main components: i) Feature Extraction with Conv1D, ii)
Global Average Pooling, and iii) Fully Connected Layers.


Hyperparameter Count Range Description
`kernel_size` 5 (2, 16) Conv1D’s convolving kernel size
`conv_channel` 5 (4, 32) Conv1D’s number of output channels
`fc_dimension` 2 (4, 32) Fully-connected layer’s output feature size
`batch_size` 1 (16, 64) Batch size
`learning_rate` 1 (1e-5, 1e-1) Learning rate (sampled in log-uniform)
`scheduler_patience` 1 (5, 20) ReduceLROnPlateau scheduler’s patience parameter
`scheduler_factor` 1 (0.1, 1.0) ReduceLROnPlateau scheduler’s factor parameter


Table 1. List of hyperparameters and their search ranges explored using DeepHyper.


features and produce the final output by capturing complex, non-linear relationships
in the data. Since the temperature and density gradient are not functions of _z_, these
two inputs bypass the convolutional layers and feed directly to the first fully connected
layer.


4.2. _Hyper parameter optimizations and ensemble learning_


To enhance the predictive performance of our surrogate model, we employ ensemble
learning, which aggregates predictions from multiple base models. By combining different
models, we create a more robust and comprehensive representation of the underlying
physical system, improving accuracy and generalization.
In our model, we carefully parameterize several key hyperparameters that influence
performance. These include the kernel size of the 1D convolution layers, the number
of output channels in Conv1D layers, the number of neurons in fully connected layers,
batch size, learning rate, and scheduler patience for dynamically adjusting the learning
rate. A summary of these hyperparameters is provided in Table 1. We fix the number of
Conv1D layers at five, so the associated pooling layers reduce the number of spatial points
from 96 to 96 _/_ 2 [5] = 3, and include two fully connected layers. While these constraints
simplify the search space, the total number of possible hyperparameter configurations
remains extremely large, exceeding one hundred quadrillion (10 [17] ). Exploring this vast
space through brute-force methods is computationally infeasible.
To efficiently navigate this large hyperparameter space, we leverage DeepHyper (Balaprakash _et al._ 2018; Egelé _et al._ 2023), an advanced hyperparameter optimization
tool. DeepHyper systematically finds the best set of hyperparameters that maximize


_How does ITG turbulence depend on magnetic geometry?_ 15


model accuracy using different search strategies including Bayesian Optimization, Evolutionary Strategies, and Random Search. Bayesian optimization uses a probabilistic
approach to refining hyperparameters, while evolutionary strategies optimize parameters
through genetic algorithms. Random Search serves as a baseline method. DeepHyper is
designed for parallel execution in distributed computing environments such as clusters
and supercomputers, making it effective for hyperparameter optimization tasks at scale.
In DeepHyper, Bayesian optimization (BO) that we adopt follows a single-manager,
multiple-worker scheme to explore and exploit the search space. The manager maintains a
probabilistic surrogate model (e.g., Random Forest) to predict the performance of configurations and select promising candidates based on an acquisition function (e.g., Expected
Improvement or Upper Confidence Bound). The workers asynchronously evaluate these
candidates in parallel, returning results to update the surrogate model iteratively. To
improve robustness and generalization, DeepHyper generates an ensemble of models by
aggregating the top-performing configurations identified during the search.


In this study, we employ DeepHyper to explore the hyperparameter space of our base
model, aiming to identify and select the top-N best models for ensemble learning. DeepHyper systematically searches the hyperparameter space to optimize model performance.
To guide this optimization, we use the coefficient of determination _R_ [2], as the objective
function, ensuring the selected models achieve the highest predictive accuracy. The base
neural network model is implemented using pytorch.


Figure 8 presents the results of our hyperparameter search. Each point in the figure
represents a model explored during the optimization process. The x-axis denotes the
time of completion, while the y-axis shows the model’s performance measured by the
_R_ [2] score. Over a period of approximately nine hours, we utilized 64 GPUs to conduct
this search. DeepHyper evaluated 443 different models with varying hyperparameter
configurations, systematically assessing their performance. After completing the search,
we selected the top 100 models with the highest _R_ [2] scores to form an ensemble, ensuring
improved predictive accuracy and generalization. The bottom plot presents a histogram
of model sizes, represented by the number of parameters on the x-axis, for all 443 models
explored by DeepHyper and the top 100 high-performing selected models, illustrating
the distribution of model sizes before and after selection.


Figure 9 illustrates the prediction performance of this ensemble, which consists of
the 100 highest-performing models from the DeepHyper optimization, on the variedgradient data. Each red dot in the figure represents the mean prediction of the ensemble
at each target value in the test dataset, while the vertical bars indicate the range of _±_ 1 _σ_
(standard deviation) of predictions across the 100 models. We evaluated the ensemble
using a total of 9,785 held-out test samples, achieving an overall _R_ [2] score of 0.989,
computed by treating the ensemble mean as the prediction. Additionally, the neural
networks exhibited efficient inference speed, taking a total 1,031.0 seconds on a single
NVIDIA A100 GPU to process 9,785 test samples across the 100 models. To make a single
prediction of the heat flux, this time corresponds to an average of 0.001 seconds for a
single CNN and 0.1 seconds for the ensemble. These times represent a factor of _∼_ 4 _,_ 000
speed-up for evaluating the ensemble compared to one of the gyrokinetic simulations
used to generate the training data; for evaluating a single CNN, the speed-up factor over
a gyrokinetic simulation is 4 _×_ 10 [5] . These results demonstrate the effectiveness of our
ensemble-based approach in providing accurate and stable predictions across the dataset
while maintaining competitive inference performance.


16 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


|Col1|Col2|Col3|Col4|Col5|Col6|Col7|Col8|Col9|Col10|Col11|Col12|Col13|Col14|
|---|---|---|---|---|---|---|---|---|---|---|---|---|---|
|||||||||||||||
|||||||||||||||
|||||||||||||||
|||||||||||||||
|||||||||||||||
|||||||||||||||
|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|5000<br>10000<br>15000<br>20000<br>25000<br>30000<br>|






Figure 8. Results of the DeepHyper hyperparameter search. Each point represents a model with
a unique hyperparameter configuration explored by DeepHyper, plotted against its completion
time (x-axis) and performance score (y-axis). The search was conducted using 64 GPUs over
approximately nine hours, evaluating a total of 443 models. The top 100 highest-performing
models, selected for the final ensemble, are highlighted in red. The bottom plot shows the
histogram of model sizes (number of parameters on the x-axis) for all 443 models explored by
DeepHyper and the top 100 selected models.


**5. Manual feature engineering**


Complementary to the neural network approach discussed in the previous section, we
next present a method to identify patterns in the data using different machine learning
algorithms together with manual feature extraction. While these methods are not yet
able to achieve as close a fit to the data as the neural networks, they naturally provide
some level of interpretability. We proceed by first defining a combinatorial procedure to
compute a large number of derived features from the raw data that respect the spatial
translation invariance. The Spearman correlation between each feature and the heat flux
provides a first measure of each feature’s importance. Then we apply forward sequential
feature selection (FSFS) (Efroymson 1960; Whitney 1971), where the order in which
features are selected provides a second measure of feature importance. FSFS can be
applied using any regression method, and several methods will be compared for the fixedgradient and varied-gradient data, with the conclusion that there is general agreement.
Finally, a third measure of feature importance is provided by computing Shapley values
for the models that result from FSFS. We will find broad consistency between the three
measures of importance.


_How does ITG turbulence depend on magnetic geometry?_ 17








|Comparison of Ensem|Col2|mble Predictions with Actual Values|
|---|---|---|
|1<br>00<br>01<br>02<br>03<br>R2 = 0.989<br>Comparison of Ense|1<br>00<br>01<br>02<br>03<br>R2 = 0.989<br>Comparison of Ense|1<br>2<br>3<br>ble Predictions with Actual Values|
|1<br>00<br>01<br>02<br>03<br>R2 = 0.989<br>Comparison of Ense|R2 = 0.989|R2 = 0.989|
|1<br>00<br>01<br>02<br>03<br>R2 = 0.989<br>Comparison of Ense|||
|1<br>00<br>01<br>02<br>03<br>R2 = 0.989<br>Comparison of Ense|||
|1<br>00<br>01<br>02<br>03<br>R2 = 0.989<br>Comparison of Ense|||
|1<br>0<br>|1<br>0<br>|1<br>0<br>|


Figure 9. Prediction performance of an ensemble of the top 100 models selected from
DeepHyper for the varied-gradient dataset. After exploring 443 models by DeepHyper, the
top 100 were chosen based on their performance and evaluated against a test dataset of 9,785
samples. Each dot represents the mean prediction of the ensemble, while the vertical bars indicate
±1 standard deviation. The ensemble achieved an overall _R_ [2] score of 0.989, demonstrating strong
predictive accuracy and stability.


5.1. _Feature extraction_


Since the heat flux from the gyrokinetic model is invariant under periodic translation
in _z_, as discussed in section 2, a regression or classification model should preserve this
invariance. However, this invariance would generally be broken if we use the raw features
on grid points as inputs to regression or classification methods (other than CNNs)
directly. For example, a regression could in principle find that the heat flux depends
specifically on _|∇x|_ [2] at _z_ = 0 _._ 3, which is not a translation-invariant quantity. Instead,
the inputs to the regression or classification should be translation-invariant features that
are derived from the raw _z_ -dependent geometric features. To ensure this invariance in the
extracted features, we consider features that are the composition of equivariant operations
with translation-invariant reductions. To explain this method, let _P_ denote the set of
periodic real-valued functions on the interval [0 _,_ 1), representing the _z_ domain. Each
of the seven original raw features can be considered as an element of the set _P_ . An
equivariant operation _E_ is a function from _P →_ _P_, such that translating the input and
then applying _E_ gives the same result as first applying _E_ and then translating. More
formally, let _f_ be any element of _P_, and let _g_ : _P →_ _P_ indicate a periodic shift by
some distance _∆_, so _g_ ( _f_ )( _x_ ) = _f_ ( _x_ + _∆_ mod 1). Then the equivariance of _E_ means that
_E_ ( _g_ ( _f_ )) = _g_ ( _E_ ( _f_ )) for all _f_ and _∆_ . A reduction is a map from _P →_ R. A reduction _A_ is
translation-invariant if _A_ ( _f_ ( _x_ + _∆_ mod 1)) = _A_ ( _f_ ( _x_ )) for all _x_ and any shift _∆_ .
For the results here, we consider 23 possible translation-invariant reductions: max; min;
range (max _−_ min); mean; median; mean of the square; variance; skewness; _L_ 1 norm;
quantiles 0.1, 0.25, 0.75, and 0.9; count above -2, -1, 0, 1, and 2; the absolute amplitudes of


18 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


the three longest-wavelength Fourier modes; the expected _k_ _||_ ; and the largest amplitude
_k_ _||_ . The last two quantities are defined as follows: letting [�] _[N]_ _j_ = _−N_ _[f]_ [ˆ] _[j]_ [ exp(] _[ik]_ _[j]_ _[z]_ [)][ denote]

the Fourier transform of a raw feature _f_ ( _z_ ), the expected _k_ _||_ is [�] _[N]_ _j_ =1 _[k]_ _[j]_ _[|][f]_ [ ˆ] _[j]_ _[|][/]_ [ �] _[N]_ _j_ =1 _[|][f]_ [ ˆ] _[j]_ _[|]_ [,]
while the largest amplitude _k_ _||_ is _k_ _j_ where _j_ is the solution of arg max _j_ _|f_ [ˆ] _j_ _|_ . These last two
reductions were included due to the importance of parallel length scales in critical-balance
models of turbulence (Barnes _et al._ 2011). We indicate the set of these 23 reductions by
_R_ .

For the equivariant operations, we consider combinations of unary operations and
products. The unary operations, each an equivariant map _P →_ _P_, includes 11 operations on an input function _f_ : the identity _f_, _|f_ _|_, _df/dz_, Heaviside( _f_ ), Heaviside( _−f_ ),
ReLU( _f_ ) = max( _f,_ 0), ReLU( _−f_ ), 1 _/f_, _f_ [2], _fB_, and _f/B_ . The last two operations,
multiplying or dividing by the field strength _B_, were included since the coordinate
Jacobian is 1 _/B_ .
We can now state the full set of features that are considered. Let _F_ denote a set of

eight features, given by the original seven raw features together with the local shear
_S_ = ( _d/dz_ )( _∇x · ∇y/∇x · ∇x_ ). The local shear (Greene & Johnson 1968) is added here
since it is plausible that it could play a role in determining the turbulence intensity.
Then the set of features _U_ ( _F_ ) is obtained by applying each possible unary operation to
each of the eight elements of _F_ . We let _C_ ( _U_ ( _F_ )) denote the set of all possible pairwise
products of functions in _U_ ( _F_ ), supplemented with _U_ ( _F_ ). Then _U_ ( _C_ ( _U_ ( _F_ ))) indicates
all possible unary operations applied to all elements of _C_ ( _U_ ( _F_ )). The full set of features
is finally _R_ ( _U_ ( _C_ ( _U_ ( _F_ )))), obtained by applying all of the reductions, for a total of just
over 1 million extracted features. This set includes a few features that are duplicated,
improper due to division by 0, or that include unnecessary operations (e.g. ReLU of a
positive-definite function), but a suitably large fraction are distinct and finite. Of course
larger feature sets could be considered by including more operations and combinations,
but the set here is suitably rich to find accurate regressions of the data.


5.2. _Spearman correlation_


One approach to measuring the potential importance of an isolated feature in a
regression problem is to compute its Spearman correlation with the target quantity.
Spearman correlation is defined by the Pearson correlation between the sorted rank of
the target with the sorted rank of the feature. The absolute magnitude of the Spearman
correlation has the appealing properties of being fast to compute and invariant to
any monotonic nonlinear function, e.g. for any sequence of points _{x_ _j_ _}_, the Spearman
correlation of _{x_ _j_ _}_ with _{_ exp( _x_ _j_ ) _}_ is 1. We can evaluate the Spearman correlation
between each feature from the previous subsection and the heat flux. Note that no
regression or classification model is used. The most highly correlated features for the
fixed-gradient dataset are listed in table 2. All these top features include the factor
_Θ_ ( **B** _× κ · ∇y_ ) where _Θ_ is the Heaviside function. In our sign convention, this quantity
is 1 in regions of bad curvature. The most correlated features all have a similar form,
indicating the heat flux is highest when the flux surface compression _|∇x|_ is large in
regions of bad curvature. For the features listed, the sign of the correlations is positive,
so greater flux surface compression is associated with a higher heat flux, as expected
physically. The features also include an inverse weighting with _B_, which perhaps reflects
the Jacobian _∝_ 1 _/B_ . The exact powers of _|∇x|_ and _B_ vary among the top features, but
a consistent pattern is evident.
As mentioned in the introduction, these features with highest Spearman correlation to
the heat flux are consistent with ideas by Mynick _et al._ (2010), Xanthopoulos _et al._ (2014),


_How does ITG turbulence depend on magnetic geometry?_ 19


Feature Correlation


variance( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [2] _/B_ ) 0.775
mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [8] _/B_ [2] ) 0.774
mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [4] _/B_ ) 0.772
variance( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [4] _/B_ ) 0.769
mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [4] _/B_ [2] ) 0.769


Table 2. Geometric features from section 5.1 with highest absolute magnitude of Spearman
correlation to the nonlinear heat flux at fixed temperature and density gradient. Here, _Θ_ denotes
the Heaviside function.


Stroteich _et al._ (2022), and Goodman _et al._ (2024). In these earlier works, stellarator
configurations were sought with smaller _|∇x|_ in regions of bad curvature, motivated by
the following physical intuition. At fixed _dT/dx_, reducing _|∇x|_ reduces the real-space
temperature gradient _|∇T_ _|_ = ( _dT/dx_ ) _|∇x|_ . Reducing _|∇T_ _|_ reduces the source of free
energy for instabilities and the associated turbulence. This is particularly true if done in
the regions where instabilities and turbulence are localized due to bad curvature. Positive
correlation between _|∇x|_ and quasilinear heat flux estimates was also noted by Jorge _et al._
(2024).
Kendall’s _τ_ is another correlation coefficient with many similarities to Spearman’s
correlation. For all results in this paper involving Spearman correlation, essentially the
same findings are obtained in comparable computational time if Kendall correlation is
used instead, though numerical values of Kendall correlation are smaller.
Spearman and Kendall correlation cannot account for dependence of the target on
multiple features that may interact, so we now proceed to more sophisticated methods.


5.3. _Sequential feature selection_


In forward sequential feature selection (FSFS) (Efroymson 1960; Whitney 1971),
regression or classification is first performed using one feature at a time. In other words,
if there are _n_ features, we fit _n_ distinct models, each with one feature. Any regression or
classification method can be used. The feature that yields the best model fit to the data
is selected to progress to the next step. Then, the data are fit using _n −_ 1 independent
models that each use two features, the one selected in the first step plus all possible
second features. Of these _n −_ 1 models, the one with closest fit is selected to progress
to the next step, and so forth. Thus, FSFS results in a parsimonious set of features,
which are effectively ranked from most to least important by the order in which they are
selected.

For the regression and classification models to use in FSFS, we primarily rely on the
gradient boosted decision tree package XGBoost (Chen & Guestrin 2016). This choice is
due to its speed with datasets of this size. Speed is a priority since _O_ (10 [6] ) independent
models must be fit at each step. Like other decision tree methods, XGBoost fits a
piecewise-constant function to the data, with the location and number of discontinuities
chosen to balance accuracy of fitting the data against complexity of the surrogate. At each
step of FSFS we use an average score from five-fold cross-validation. When applying FSFS
to the varied-gradient dataset, the temperature and density gradients are also included
among the features that can be selected. Other scalar features such as _ι_, _dι/dx_, _dp/dx_,
and _n_ _fp_ can be included, but these features are not selected by the procedure, which
makes sense because they do not appear in the gyrokinetic equation and hence have only
a more indirect relation to the heat flux.


20 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_










|Regressions on the heat flux|Col2|Col3|
|---|---|---|
|Varied gradients, XGBoost<br>Fixed gradients, XGBoost<br>Varied gradients, nearest~~-~~neighbors(10)|Varied gradients, XGBoost<br>Fixed gradients, XGBoost<br>Varied gradients, nearest~~-~~neighbors(10)|Varied gradients, XGBoost<br>Fixed gradients, XGBoost<br>Varied gradients, nearest~~-~~neighbors(10)|
|Varied gradients, XGBoost<br>Fixed gradients, XGBoost<br>Varied gradients, nearest~~-~~neighbors(10)|6<br>8<br>|0<br>1|

|Classifier for stability vs instability|Col2|Col3|
|---|---|---|
|ROC AUC<br>Accuracy<br>log loss (cross~~-~~entropy)|ROC AUC<br>Accuracy<br>log loss (cross~~-~~entropy)|ROC AUC<br>Accuracy<br>log loss (cross~~-~~entropy)|
|ROC AUC<br>Accuracy<br>log loss (cross~~-~~entropy)|4<br>6<br>8|10<br>|


Figure 10. Scores for regression (left) and classification (right) in forward sequential feature
selection, showing improvement as the first few features are added. Each point shows the mean
score on held-out data using 5-fold cross-validation.


Figure 10 shows the results of FSFS for regression on both the fixed-gradient and
varied-gradient datasets, as well as for stable vs. unstable classification on the variedgradient dataset. For regression, we assess the performance using the coefficient of
determination _R_ [2] . For classification, we choose features in FSFS using the log-loss
measure (also known as cross-entropy; lower is better), while reporting also the accuracy
and ROC-AUC scores (receiver operating characteristic area under the curve; higher is
better) in figure 10.b. It can be seen that the prediction accuracy rapidly improves with
the first few features, then levels off. With three features, the heat flux for the variedgradient dataset can be predicted with _R_ [2] = 0 _._ 88; adding nine more features results in
a marginal improvement to _R_ [2] = 0 _._ 92. Qualitatively similar results are obtained using
other regression or classification models. As an example, figure 10 also shows FSFS results
for 10-nearest-neighbors regression; the behavior is similar to the XGBoost regression but
with slightly lower _R_ [2] .
Another view on FSFS is provided by figure 11. Each panel shows, for a given number
of features, how the predictions with that feature subset compare to the actual heat flux.
In each panel, the regression was fit using 80% of the data, and the figure shows the
performance on the held-out 20% of the data. A perfect prediction would correspond to
all the points lying on the gray dotted line. As more features are added, the regression
models more accurately predict the heat flux. There is a trade-off in that the models with
more features are more complicated and harder to interpret due to possible interactions
between the features.

For each of the FSFS curves in figure 10, the first five selected features are listed in
table 3. In the table, absFFTCoeff1 indicates the absolute magnitude of the longestwavelength (but not constant) Fourier mode in _z_ . In the varied-gradient dataset, for
both regression and classification, the first selected feature is the temperature gradient,
and the second selected feature is the density gradient. These findings are consistent
with expectations from linear theory that the temperature gradient is the primary drive
for the instability, and the density gradient can significantly affect stability. In both the
varied-gradient and fixed-gradient cases, the first geometric feature selected again reflects
the flux surface compression in regions of bad curvature. While the top geometric feature
for the classifier involves unfavorable _∇B_ drift rather than curvature drift, the feature
mean( _Θ_ ( **B** _×_ _κ_ _·∇y_ ) _|∇x|_ [2] _/B_ ) has almost an identical score, log-loss=0.123 as opposed to
0.122, so there is little distinction between the two drifts in this case. Hence, the results


_How does ITG turbulence depend on magnetic geometry?_ 21












|Model using only a/LT and a/Ln|Col2|Col3|Col4|Col5|n|
|---|---|---|---|---|---|
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn|R2 =|0.714||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn||||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn||||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.714<br>Tn||||||

|103 T<br>R2 = 0.876<br>102<br>101<br>100<br>10 1|Col2|Col3|n|Col5|
|---|---|---|---|---|
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.876<br>T|R2 =|0.876|||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.876<br>T|||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.876<br>T|||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.876<br>T|||||

|odel using a/L, a/L,<br>103 T n<br>R2 = 0.901<br>102<br>101<br>100<br>10 1|Col2|Col3|and 2 geometric fea|Col5|
|---|---|---|---|---|
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.901<br>odel usinga/LT, a/Ln,|R2 =|0.901|||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.901<br>odel usinga/LT, a/Ln,|||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.901<br>odel usinga/LT, a/Ln,|||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.901<br>odel usinga/LT, a/Ln,|||||

|odel using a/L, a/L<br>103 T<br>R2 = 0.946<br>102<br>101<br>100<br>10 1|Col2|Col3|, and 10 geometric fea<br>n|Col5|
|---|---|---|---|---|
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.946<br>delusinga/LT, a/L|R2 =|0.946|||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.946<br>delusinga/LT, a/L|||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.946<br>delusinga/LT, a/L|||||
|10<br>1<br>100<br>101<br>102<br>103<br>R2 = 0.946<br>delusinga/LT, a/L|||||


Figure 11. The accuracy of regression models improves to a point as more features are included
from sequential feature selection. Each panel shows the performance of the XGBoost regression
on 20% held-out test data from the varied-gradient dataset.


are quite consistent with the Spearman correlation analysis of section 5.2, and support
the physical intuition from Mynick _et al._ (2010), Xanthopoulos _et al._ (2014), Stroteich
_et al._ (2022), and Goodman _et al._ (2024).
For each of the four tables within table 3, the second geometric feature again includes
the flux surface compression _|∇x|_, but this time involving the radial rather than binormal
component of the _∇B_ drift, **B** _× ∇B · ∇x_ . Note that there is no distinction between the
_∇B_ drift and curvature drift in the radial direction: **B** _× ∇B · ∇x_ = _B_ **B** _× κ · ∇x_

for any MHD equilibrium at any _β_ . So, the quantity **B** _× ∇B · ∇x_ appearing in the
second geometric features is the geodesic curvature (times _B|_ **B** _× ∇x|_ ). As mentioned
in the introduction, the geodesic curvature has been discussed recently as a correlate of
turbulence (Xanthopoulos _et al._ 2011; Nakata & Matsuoka 2022), motivated by the fact
that geodesic curvature plays a prominent role in the gyrokinetic equation for zonal flow
modes (Rosenbluth & Hinton 1998). More work would be needed to confirm that the
high significance of geodesic curvature in our analysis is due to the effect of zonal flows
on the turbulence, but the connection is at least suggestive.
At each step of FSFS, there are typically many features which are variations on a theme


22 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


_Classification, varied gradients, XGBoost_ _Regression, varied gradients, XGBoost_

Feature log-loss Feature _R_ [2]

_a/L_ _T_ 0.361 _a/L_ _T_ 0.524
_a/L_ _n_ 0.189 _a/L_ _n_ 0.714
mean( _Θ_ ( **B** _× ∇B · ∇y_ ) _|∇x|_ [2] _/B_ ) 0.122 mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [4] _/B_ [2] ) 0.876
mean( _Θ_ ( _−_ **B** _× ∇B · ∇x_ ) _|∇x|_ [2] _B_ ) 0.105 median(( **B** _× ∇B · ∇x_ ) [2] _|∇x|_ [8] _/B_ [8] ) 0.901
mean(( **B** _× κ · ∇y_ ) _/B_ ) 0.094 absFFTCoeff1(ReLU( **B** _× ∇B · ∇x_ ) _/B_ [5] ) 0.917


_Regression, fixed gradients, XGBoost_ _Regression, varied gradients, 10NN_


Feature _R_ [2] Feature _R_ [2]


mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [4] _/B_ ) 0.669 _a/L_ _T_ 0.479
quantile0.75(( **B** _× ∇B · ∇x_ ) _|∇x|_ [4] _/B_ [5] ) 0.775 _a/L_ _n_ 0.696
mean( _|∇x|_ [4] _/B_ [6] ) 0.834 quantile0.9( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [2] _/B_ ) 0.863
quantile0.9(( **B** _× ∇B · ∇y_ ) _/B_ [5] ) 0.861 mean(ReLU( **B** _× ∇B · ∇x_ ) _|∇x|_ [2] _/B_ [4] ) 0.884
absFFTCoeff1(( **B** _× ∇B · ∇x_ ) _/B_ [3] ) 0.879 median(( **B** _× ∇B · ∇y_ ) _|∇y|_ [2] _/B_ [6] ) 0.895


Table 3. First five features from section 5.1 selected with forward sequential feature selection.
Results are shown both for classification of stability vs instability, and for regression on the
logarithm of the heat flux _Q_ . Results are also shown for both the gradient-boosted decision tree
package XGBoost and for 10-nearest-neighbors (10NN). Here, _Θ_ denotes the Heaviside function.


_Sequential feature selection step 3_ _Sequential feature selection step 4_


Feature _R_ [2] Feature _R_ [2]


mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [4] _/B_ [2] ) 0.876 median(( **B** _× ∇B · ∇x_ ) [2] _|∇x|_ [8] _/B_ [8] ) 0.901
mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [4] _/B_ ) 0.874 quantile0.75(ReLU( _−_ **B** _× ∇B · ∇x_ ) [2] _|∇x|_ [8] _/B_ [6] ) 0.901
variance( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [2] _/B_ ) 0.871 median(( **B** _× ∇B · ∇x_ ) [2] _|∇x|_ [8] _/B_ [6] ) 0.901
quantile0.9( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [2] _/B_ ) 0.870 median( _|_ **B** _× ∇B · ∇x||∇x|_ [4] _/B_ [4] ) 0.901
mean( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [8] _/B_ [4] ) 0.869 quantile0.75(ReLU( _−_ **B** _× ∇B · ∇x_ ) _|∇x|_ [4] _/B_ [3] ) 0.901


Table 4. Top-scoring features from steps 3-4 of forward sequential feature selection, for
regression on the heat flux using the varied-gradient dataset with XGBoost. At each step, there
are many features which are variations on a theme that have nearly identical _R_ [2] score. Here, _Θ_
denotes the Heaviside function.


and which would give nearly the same score, similar to table 2. For instance, table 4 shows
the top five features in steps three and four of FSFS for regressions on the varied-gradient
dataset. At step 3, the top features are all based on the flux surface compression _|∇x|_ in
regions of bad curvature, weighted by various powers of the Jacobian. At step 4, the top
features all involve the radial magnetic drift, weighted by the flux surface compression
and powers of the Jacobian. Since the _R_ [2] score is so similar between the various options
at each step, we should not ascribe too much importance to the details that vary, such
as the power of _B_ at step 3. However aspects that are consistent among the top features,
such as the consistent appearance of the radial magnetic drift (i.e. geodesic curvature)
at step 4, are more likely to be physically meaningful.
Other regression and classification models besides XGBoost can achieve a reasonable fit
to the data. Figure 12 shows a comparison of several regression methods for the heat flux,
all using the same set of 12 features with the varied-gradient dataset ( _a/L_ _T_, _a/L_ _n_, and


_How does ITG turbulence depend on magnetic geometry?_ 23







Figure 12. Comparison of regression methods for the heat flux in the varied-gradient dataset.
In all cases the feature set is _a/L_ _T_, _a/L_ _n_, and the top 10 geometric features from FSFS with
XGBoost.


the top 10 geometric features from FSFS). Besides XGBoost and 10-nearest-neighbors
(10NN), performance is also shown for three other models. One is the gradient-boosted
decision tree package LightGBM (Ke _et al._ 2017). Another is random forest regression.
Lastly is linear regression after the features are transformed with the Yeo-Johnson power
transform (Yeo & Johnson 2000). Models other than XGBoost and LightGBM use the
implementations from scikit-learn (Pedregosa _et al._ 2011). All models use the default
hyperparameters from the relevant python package, and the performance shown is the
average score from 5-fold cross-validation. While the prediction accuracy is highest for
the decision-tree methods, it is meaningfully high for the other methods as well.


5.4. _Shapley values_


Another way to measure the importance of the features in regression and classification
models is via Shapley values. A concept originating from game theory, Shapley values
are a fair way to divide value among the input features, based on how the model
performance degrades when that feature is removed, and considering all subsets of
features (Shapley 1953; Lipovetsky & Conklin 2001). Here we specifically use the Shapley
Additive exPlanation (SHAP) formulation by Lundberg & Lee (2017). Shapley values
naturally provide the average sign of correlation between each feature and the target.
For calculations here we use the SHAP python package (Lundberg & Lee 2017; Lundberg
_et al._ 2020), which allows for efficient computations with decision tree models.
Figure 13 shows the distribution of Shapley values for regression on the varied-gradient
dataset, using the first 12 features from FSFS. Within each row, corresponding to one of
the features, a histogram of the Shapley values is shown. The horizontal dimension gives
the contribution to ln _Q_ from that feature. Wider distributions therefore indicate more
important features. The features are sorted in decreasing order of the average absolute
Shapley value, i.e. decreasing importance. Each point is colored by the value of the
feature for that flux tube, scaled to the range of that feature over the dataset. So, if the
distribution is purple/dark on the left and yellow/light on the right, larger values of that


24 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_







|Col1|Col2|
|---|---|
|||
|||
|||
|||
|||
|||
|||
|||
|||
|||
|||
|||
|4<br>2<br>0<br>2<br>4|4<br>2<br>0<br>2<br>4|


Figure 13. Distribution of Shapley values for regression with the varied-gradient dataset, using
an XGBoost fit with top 12 features from FSFS. Features are listed in decreasing importance
as measured by mean magnitude of the Shapley values.


feature increase the predicted _Q_ . Conversely if the distribution is yellow/light on the left
and purple/dark on the right, increasing values of the feature decrease _Q_ .
The order of feature importance as measured by Shapley values in figure 13 is not
exactly the same as the order in which features were selected in FSFS, but the first
three features are the same, and the pattern is broadly similar. Unsurprisingly, the most
important feature is _a/L_ _T_, which is found to increase _Q_ . The next most important
feature is _a/L_ _n_, which decreases _Q_, as expected from linear theory. Consistent with the
findings from Spearman correlation and FSFS, the most important geometric feature
is an average of _|∇x|_ in regions of bad curvature. Here, the next most important
feature, mean( _|∇x|_ [4] _/B_ [6] ), also reflects the average flux surface compression, but now
independent of bad curvature. As the distributions for these two features are blue on
the left and red on the right, both of these features increase _Q_, consistent with physical
intuition. The next most important features, median(( **B** _× ∇B · ∇x_ ) [2] _|∇x|_ [8] _/B_ [8] ) and
absFFTCoeff1(ReLU( **B** _×∇B ·∇x_ ) _/B_ [5] ), both involve the geodesic curvature, consistent
with the pattern in table 3. The colors indicate that larger average magnitude of geodesic
curvature increases _Q_, coinciding with the theoretical prediction of Xanthopoulos _et al._
(2011); Nakata & Matsuoka (2022). Physically, larger geodesic curvature means greater
neoclassical damping of zonal flows, hence smaller average zonal flow magnitude, and
therefore higher turbulence intensity.
The second-most-important geometric feature according to Shapely values, mean( _|∇x|_ [4] _/B_ [6] ),
was the fifth most important geometric feature according to FSFS order. Other differences
appear in the ranking of feature importance between Shapley values and FSFS after
the two geodesic curvature features. Since Shapely values and FSFS order are different
measures of importance, there is no guarantee that they will rank the features in the
same order, particularly farther down in the list where the effect sizes become smaller.


_How does ITG turbulence depend on magnetic geometry?_ 25


Figure 14. Comparing the true heat flux and the single geometric feature _f_ _Q_ in eq (5.1) for
fixed gradients, it is clear that there is significant correlation. No regression model is used here.


5.5. _Fine-tuning the top feature_


From the subsections above, there is a consistent and robust finding that the most
important geometric feature is the flux surface compression in regions of bad curvature.
With this in mind, we can repeat the analyses of the previous subsections with a new set
of extracted features that focuses on this general combination of quantities, giving more
variations on this theme. Optimization can also be used to tune constants and exponents
appearing within a proposed functional form. For example, considering features of the
form mean([ _Θ_ ( **B** _× κ · ∇y_ ) + _α_ ] _|∇x|_ _[β]_ _/B_ _[γ]_ ), the parameters _{α, β, γ}_ can be optimized to
maximize _R_ [2] . Both approaches – trying a set of variations on a theme and optimization
– result in broadly similar conclusions: slightly improved prediction of _Q_ is found if a
shift is added to the Heaviside function and the exponent on _|∇x|_ is modified, yielding
the feature


_f_ _Q_ = mean([ _Θ_ ( **B** _× κ · ∇y_ ) + 0 _._ 2] _|∇x|_ [3] _/B_ ) _._ (5.1)


The shift of 0.2 to the Heaviside function effectively combines the top two geometric
features according to the Shapley values in figure 13 (though with different powers of
_B_ .) For this single feature with the fixed-gradient dataset, the Spearman correlation
is 0.788, and XGBoost regression on ln _Q_ yields _R_ [2] = 0.737. These values are slightly
increased from 0.775 and 0.669 respectively without the shift to the Heaviside function.
For the varied-gradient dataset, using models with the three features _{a/L_ _T_ _, a/L_ _n_ _, f_ _Q_ _}_,
regression on ln _Q_ gives _R_ [2] = 0 _._ 887, slightly improved from _R_ [2] = 0 _._ 876 from table 3.
Figure 14 shows a comparison of the single feature _f_ _Q_ and the GX heat flux for the
fixed-gradient dataset. Note that there is no regression model applied here. While eq
(5.1) does not explain the full variation in the heat flux, it clearly does explain some. It
is possible that with additional work, a single geometric feature of comparable complexity
could be found with even higher predictive accuracy.
The set of three features _{a/L_ _T_ _, a/L_ _n_ _, f_ _Q_ _}_ does reasonably well in the classifier for


26 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


predicting stability: log-loss=0.128, accuracy=0.944, ROC-AUC=0.989. However, the
geometric feature that best predicts the stiffness of the heat flux above marginal stability
is not necessarily the best feature for predicting the stability boundary. Using the same
methods described earlier in this subsection, a single geometric feature can be fine-tuned
to marginally improve the stability classifier’s accuracy. Again adding a shift to the
Heaviside function and modifying the exponents, we arrive at



_f_ stab = mean([ _Θ_ ( **B** _× ∇B · ∇y_ ) + 0 _._ 4] _|∇x|/√_



_B_ ) _._ (5.2)



Using XGBoost with the three features _{a/L_ _T_ _, a/L_ _n_ _, f_ stab _}_, the classifier achieves logloss=0.111, accuracy=0.953, and ROC-AUC=0.991.


**6. Testing other proposed surrogates**


A natural application of this dataset is to test objective functions for reduced ITG
transport that have been proposed previously. Several such objectives are compared in
figure 15. Each quantity is rated by three scores: Spearman correlation with _Q_ for the
fixed-gradient dataset, accuracy for classification with the varied-gradient dataset, and _R_ [2]

for regression on the varied-gradient dataset. For the latter two scores, an XGBoost model
is fit using 3 features: the geometric feature in question along with _a/L_ _T_ and _a/L_ _n_ . The
classification and regression scores are averages from 5-fold cross-validation. A control is
also shown, in which XGBoost is fit using only the two features _{a/L_ _T_ _, a/L_ _n_ _}_ with no
geometric features, since the accuracy using only these gradients is already significant.
One set of proposed objectives in figure 15 comes from Mynick _et al._ (2014): _Q_ _pr_ 1 _b_  _Q_ _pr_ 1 _f_ . The definitions can be found in figure 15, in terms of the flux tube average
_⟨. . .⟩_ = [� _. . . dz/B_ ] _/_ � _dz/B_ . In the earlier publication (Mynick _et al._ 2014), the average
was not defined, and it was stated that the component of curvature used was the radial
component, but we confirmed with the first two authors that the expressions in figure 15
are what was actually used. Another similar proposed objective in figure 15 is the one
from Xanthopoulos _et al._ (2014): _⟨_ ReLU( **b** _× κ · ∇y_ ) _|∇x|_ [4] _⟩_ . In that paper, the average
was not written, and again the component of curvature used was described as radial, but
we confirmed with the author that the expression in figure 15 is what was actually used.
Our sign convention for _y_ is reversed compared to these earlier papers, so the arguments
of Heaviside and ReLU functions have opposite sign.
One more previously proposed objective in figure 15 is the one from Stroteich _et al._
(2022), namely _|∇x|_ at a specific point **p** : the outboard midplane of the taller stellaratorsymmetric cross-section. This quantity is not well correlated with _Q_ in our dataset
because 3/4 of the flux tubes in our data do not include this point. Therefore, we also
include a modified objective which is usually similar for flux tubes that include **p** but
more meaningful in those that do not: the maximum _|∇x|_ in regions of bad curvature:
max( _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ ).
Another feature included in figure 15 is the estimated critical gradient from eq (6) of
Roberg-Clark _et al._ (2023). We use the curvature drift rather than _∇B_ drift to compute
this quantity as it results in slightly higher scores, though the differences are small.
A typical flux tube may have multiple intervals of bad curvature, in which case the
estimated critical gradient is computed for each interval, and the minimum over all
intervals is used as the feature. We note here that the critical gradient estimate is not
intended to correlate inversely with heat fluxes, but rather to predict the gradient where
heat fluxes become significant. Any inverse correlation of the feature with heat fluxes
above the critical gradient, perhaps through the physical connection between _|∇α|_ and
finite Larmor radius damping of ITG modes, is incidental.


_How does ITG turbulence depend on magnetic geometry?_ 27








|No geometric information,<br>gradients only (control)<br>Mynick et al. PPCF (2014), Qpr1b<br>b × y (B × y)<br>Mynick et al. PPCF (2014), Qpr1c<br>b × y (B × y)| x|2/| y|2<br>Mynick et al. PPCF (2014), Qpr1d<br>b × y (B × y)| x|2<br>Mynick et al. PPCF (2014), Qpr1e<br>b × y (B × y)/| y|2<br>Mynick et al. PPCF (2014), Qpr1f<br>b × y (B × y) / | y|2<br>Xanthopoulos et al. PRL (2014)<br>ReLU(b × y)| x|4<br>Stroteich et al. JPP (2020)<br>| x|( = 0, = 0)<br>Stroteich, modified<br>max( (B × y)| x|)<br>Roberg-Clark et al. PRR (2023)<br>Critical gradient estimate<br>Goodman et al. PRX (2024)<br>mean( ( 95 )), = (B × y)| x|2<br>This work, fQ<br>mean([ (B × y) + 0.2]| x|3/B)<br>This work, fstab<br>mean([ (B × B y) + 0.4]| x|/ B)|Col2|Col3|Col4|
|---|---|---|---|
|No geometric information,<br>gradients only (control)<br>Mynicket al. PPCF(2014),Qpr1b<br>~~b ×~~<br>~~y~~<br>(B ×<br>y)<br>Mynick et al. PPCF (2014),Qpr1c<br>~~b ×~~<br>~~y~~<br>(B ×<br>y)| x|2/| y|2<br>Mynick et al. PPCF (2014),Qpr1d<br>~~b ×~~<br>~~y~~<br>(B ×<br>y)| x|2<br>Mynick et al.PPCF (2014),Qpr1e<br>~~b ×~~<br>~~y~~<br>(B ×<br>y)/| y|2<br>Mynick et al. PPCF (2014),Qpr1f<br>~~b ×~~<br>~~y~~<br>(B ×<br>y) / | y|2<br>Xanthopoulos et al. PRL (2014)<br>ReLU(b ×<br>y)| x|4<br>Stroteich et al. JPP (2020)<br>| x|(<br>= 0,<br>= 0)<br>Stroteich, modified<br>max( (B ×<br>y)| x|)<br>Roberg~~-~~Clark et al. PRR (2023)<br>Critical gradient estimate<br>Goodman et al. PRX (2024)<br>mean(<br>( 95<br>)),  =<br>(B ×<br>y)| x|2<br>This work,fQ<br>mean([ (B ×<br>y) + 0.2]| x|3/B)<br>This work,fstab<br>mean([ (B ×<br>B<br>y) + 0.4]| x|/~~ B)~~||||

|Col1|Col2|Col3|Col4|
|---|---|---|---|
|||||


Figure 15. Comparing several proposed ITG objectives using three scores. The classification
and regression scores are computed using XGBoost with three features: the single geometric
feature, _a/L_ _T_, and _a/L_ _n_ .


Finally, the comparison in figure 15 includes the ITG objective from Goodman _et al._
(2024). In that work an integral over a full flux surface was used; here we modify the
expression to integrate only over a flux tube. The specific expression we consider is
mean( _ξΘ_ ( _ξ_ 95 _−_ _ξ_ )), where _ξ_ = _Θ_ ( **B** _× κ · ∇y_ ) _|∇x|_ [2], and _ξ_ 95 is the 0.95 quantile of _ξ_ over
the flux tube.
Figure 15 shows that with the exception of _|∇x|_ ( _θ_ = 0 _, ζ_ = 0), all of these proposed
objectives have significant predictive power for both the stability boundary and heat flux.
This is perhaps not surprising as these objectives are similar to each other, all measures
of the flux surface compression, bad curvature, or both. Their performance is nearly as
good as for our optimized features _f_ _Q_ and _f_ _stab_, and is significantly better than the
control with no geometric information.


**7. Discussion and future work**


In this work, we have presented a large new dataset of nonlinear gyrokinetic turbulence
simulations covering a wide and diverse range of magnetic geometries. Applied to the
dataset, a variety of machine learning methods can accurately predict the nonlinear heat


28 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


flux, and classify stable versus unstable conditions. It was important that these classification and regression methods be applied in such a way as to respect the translationinvariance of the gyrokinetic system, as can be done using convolutional neural networks,
or translation-invariant reductions of transation-equivariant operations. Beyond providing these fast surrogates, machine learning methods can also extract insights that can
stimulate theory. Thus, machine learning can be more than a black-box interpolation:
it can provide understanding and feed back into more traditional physics calculations.
In order to extract insights in this case, we have demonstrated a variety of methods
– Spearman correlation, sequential feature selection, and Shapley values – which can
measure the importance of geometric features in the data. While some details differ
between the conclusions of these methods, such as the exponent of _B_ in the most
important features, certain patterns are quite robust.


Multiple lines of evidence point to the flux surface compression in regions of bad curvature as the most important geometric feature, with more surface compression yielding
higher heat flux _Q_ . This feature is identified from its high Spearman correlation, from its
early choice in sequential feature selection, and by its large Shapley values. It arises in
FSFS using multiple regression algorithms (decision trees and nearest-neighbors), using
both regression and classification, and both with fixed or varied temperature and density
gradients. These findings provide evidence supporting the physical arguments regarding
this feature by Mynick _et al._ (2010), Xanthopoulos _et al._ (2014), Stroteich _et al._ (2022),
and Goodman _et al._ (2024). It is not obvious that the importance of this feature can be
explained purely in terms of linear growth rates, as _|∇x|_ does not appear in the linear
gyrokinetic equation for _k_ _x_ = 0 modes, which are typically the most unstable.


Another robust finding is that the next most important feature is the geodesic curvature, with larger magnitudes giving higher _Q_ . These conclusions are supported by both
FSFS and Shapley values. Our findings support the discussion of this feature’s importance
by Xanthopoulos _et al._ (2011) and Nakata & Matsuoka (2022), and are suggestive of the
effect of zonal flow dynamics. Further analysis of the existing dataset could be done to
elucidate the role of zonal flows.


Another theoretical framework for turbulence that has been discussed recently is
critical balance (Barnes _et al._ 2011), in which the parallel wavenumber _k_ _||_ plays an
important role. Although thousands of features involving _k_ _||_ were included in the set
of features that could have been selected, these features were not selected in FSFS,
indicating lower importance than the surface compression or geodesic curvature. It would
be valuable to better understand these findings theoretically in the future.


There are many directions in which this research can be extended in the areas of
data generation, fitting the data with surrogate models, physics understanding, and
applications. Regarding data generation, the set of equilibria could be expanded with
more quasi-isodynamic configurations. New datasets of nonlinear gyrokinetic simulations
could be generated with kinetic electrons and electromagnetic effects. The physics model
would then include additional instabilities such as trapped electron modes and kinetic
ballooning modes. Similar analysis methods to the ones here could then be applied to
such data, including also regression on the particle flux. For both future data and the
present data, the feature engineering methods here could be applied with larger sets of
possible features beyond the set from section 5.1, and alternative regression methods
could be tried. Of particular interest would be symbolic regression and Kolmogorov
Arnold networks (Liu _et al._ 2024) due to their advantages for interpretability. It would
also be valuable to use saliency maps and related methods to understand the features
learned by the neural networks. If these saliency maps can be understood, the results


_How does ITG turbulence depend on magnetic geometry?_ 29


may suggest new features that could be checked directly for correlation with the true
heat flux and to include in the FSFS.
In the area of physics understanding, researchers can aim to derive relationships
between the top geometric features here and the nonlinear heat flux using traditional
analytic methods. This should be done first for the most important feature (and variations
thereof) related to flux surface compression, but could also be attempted for the next
most important features. Other quantities inspired by plasma theory could be checked
for correlations against the heat flux, and added to the menu of possible features for
sequential feature selection. It would be natural for instance to check quantities from
linear zonal flow dynamics in this way.
The surrogate models developed in this paper could be applied in multiple ways. One
application is for predicting the radial profiles of temperature, using the surrogate as a
fast model for the gradient-flux relationship inside a solver of the transport equations.
(Prediction of the density profile would require a dataset of nonlinear simulations with
kinetic electrons.) Such profile prediction using surrogate models is already available for
tokamaks (Citrin _et al._ 2015; Meneghini _et al._ 2017), but this could now be extended
to stellarators. The other evident application would be for turbulence optimization of
stellarators. While optimization of a geometric feature similar to the top feature here
is already being done (Goodman _et al._ 2024), the results of this paper allow several
improvements. First, this turbulence objective can now be justified through validation
on this data, and modified slightly as in section 5.5 for better correlation to nonlinear
simulations. Second, the surrogates here provide better correlation to the true heat flux
by incorporating more geometric information, either via multiple features in the FSFS
method, or through holistic use of all the geometric information in the neural networks.
Lastly, since the surrogates here could allow information from all flux surfaces and the
gradients to be combined in a transport solver to rapidly predict the fusion power, this
enables the fusion power to be used directly as an optimization objective.


**Acknowledgements**


We gratefully acknowledge suggestions related to this work from Ian Abel, Gonçalo
Abreu, David Bindel, Bill Dorland, Alan Goodman, Greg Hammett, Siena Hurwitz,
Byoungchan Jang, Rogerio Jorge, Alan Kaptanoglu, Emily Kendall, Ralf Mackenbach,
Maikel Morren, Harry Mynick, Eduardo Rodriguez, and Pavlos Xanthopoulos.


**Funding**


This work was supported by the US Department of Energy under DE-AC02-09CH11466
(High-fidelity Digital Models for Fusion Pilot Plant Design, StellFoundry). R. C. was
supported by Greg Hammett’s DOE Distinguished Scientist Fellow award. This research
used resources of the National Energy Research Scientific Computing Center (NERSC),
a Department of Energy Office of Science User Facility using NERSC awards FES-mp217
and FES-m4505 for 2024.


**Declaration of interests**


M. L. is a consultant for Type One Energy Group.


30 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


**Data availability statement**


Data associated with this study can be downloaded from `[https://doi.org/10.5281/](https://doi.org/10.5281/zenodo.14867776)`
`[zenodo.14867776](https://doi.org/10.5281/zenodo.14867776)` (Landreman 2025).


**Appendix A. Details of equilibrium generation**


As discussed in section 3.1, the equilibria in this study consist of three classes. Here
we give additional details of how the equilibria in each class were generated. In all cases,
the equilibria were computed using DESC (Dudt & Kolemen 2020) release v0.12.0.
For the group of rotating-ellipse equilibria, the number of field periods was sampled
randomly from the interval [2 _,_ 8], the aspect ratio was chosen randomly from [6, 10], and
the elongation (ratio of major to minor axis of the cross-section in a constant- _ϕ_ plane) was
chosen randomly from [1 _,_ 4]. For half of the rotating-ellipse configurations, the ellipses
were centered on a constant-major-radius circle. For the other half, the ellipses were
centered on a curve with torsion, by setting the _m_ = 0, _n_ = _n_ _fp_ Fourier mode of _R_ and
_Z_ on the boundary to a random number between 0 and the minor radius, with sign chosen
to increase iota. A pressure profile with fixed shape _p_ ( _s_ ) = 1 _−_ 1 _._ 8 _s_ + 0 _._ 8 _s_ [2] is chosen,
where _s_ is the normalized toroidal flux, reflecting a plausible level of peaking, with random
magnitude chosen for a uniform distribution of volume-averaged _β ∈_ [0 _,_ 0 _._ 05]. Equilibrium
calculations were then run, assuming no toroidal current for simplicity. Configurations
with _|ι| <_ 0 _._ 2 were dropped.
Another group of equilibria were derived from the QUASR database (Giuliani 2024;
Giuliani _et al._ 2024). This database includes coils in addition to plasma shapes, and
many entries in QUASR differ primarily in coil geometry while having similar plasma
parameters. Also, some configurations in QUASR have much better quasisymmetry
than others, and we wish to focus on the ones with better quasisymmetry (since the
other equilibrium groups in our study contain many non-quasisymmetric geometries.)
Therefore a subset of QUASR was selected as follows. First, all configurations with
high quasisymmetry error, _ι <_ 0 _._ 2, or aspect ratio _>_ 10 were excluded. Then for each
symmetry class (QA vs QH) and _n_ _fp_, for each interval in aspect ratio (1-2, 2-3, 3-4,
.., 9-10) and _ι_, the two configurations in QUASR with lowest QS error were chosen.
DESC was run for these boundary shapes assuming a vacuum field, and also with the
aforementioned pressure profile for multiple pressure magnitudes spanning _⟨β⟩∈_ [0 _,_ 5%].
For some strongly shaped geometries or high _⟨β⟩_ values, the resulting force residual was
high, indicating the equilibrium was not well converged, so these cases were dropped.
The third group of equilibria were generated by randomly sampling Fourier modes
from distributions that have been fit to a dataset of previous stellarator shapes. Consider
the common representation of toroidal boundary shapes as a double Fourier series:



_R_ ( _θ, ϕ_ ) = �



� _R_ _m,n_ cos( _mθ −_ _n_ fp _nϕ_ ) _,_ _Z_ ( _θ, ϕ_ ) = �


_m,n_ _m,n_



� _Z_ _m,n_ sin( _mθ −_ _n_ fp _nϕ_ ) _,_ (A 1)


_m,n_



where ( _R, ϕ, Z_ ) are cylindrical coordinates, _n_ fp is the number of field periods, _θ_ is some
poloidal angle, and stellarator symmetry has been assumed. The sums are considered to
include only non-negative _m_, with both positive and negative _n_ for _m >_ 0, but only nonnegative _n_ for _m_ = 0. To randomly generate boundary shapes, we sample the _R_ _m,n_ and
_Z_ _m,n_ coefficients from independent normal distributions for each ( _m, n_ ) (and independent
for _R_ and _Z_ ). The mean and standard deviation of each distribution are taken from
the dataset of 44 stellarators collected by Kappel _et al._ (2024). This set includes both
built experiments (W7-X, LHD, HSX, CFQS, TJ-II, etc.) and theoretical configurations.


_How does ITG turbulence depend on magnetic geometry?_ 31


Before extracting the sample mean and standard deviation, all configurations were scaled
to the same minor radius. To further standardize the data, _ϕ →−ϕ_ reflections were
applied to configurations with _ι <_ 0 so all configurations have rotational transform of the
same sign, and toroidal rotations by half a field period were applied to any configurations
in which the cross-section at _ϕ_ = _π/n_ fp is not as tall as at _ϕ_ = 0. After this data cleaning,
the sample mean and sample standard deviation are computed over the 44 configurations
for each _R_ _m,n_ and _Z_ _m,n_ . Configurations with all values of _n_ fp are included together in this
calculation. Only modes with _m_ ⩽ 4 and _|n|_ ⩽ 4 are considered, since some theoretical
stellarators in Kappel’s dataset resulting from optimization do not include boundary
modes with higher mode number. The resulting mean and standard deviation values are
used to define normal distributions which can then be sampled.
To generate a new random equilibrium, new values of _R_ _m,n_ and _Z_ _m,n_ are first sampled
from the distributions determined above, after which _R_ 0 _,_ 0 is computed by root-finding to
give the desired aspect ratio. To ensure that the same gyro-Bohm normalization is used
in every turbulence simulation, each configuration is scaled slightly to the same minor
radius, and the toroidal flux is set to the same value. As with the other equilibrium
groups, a pressure profile with fixed shape _p_ ( _s_ ) = 1 _−_ 1 _._ 8 _s_ +0 _._ 8 _s_ [2] is chosen, with random
magnitude chosen for a uniform distribution of volume-averaged _β ∈_ [0 _,_ 0 _._ 05]. The current
profile is taken to be zero for simplicity. Next, a fast and low-resolution equilibrium
calculation is run using the code VMEC (Hirshman & Whitson 1983). If this calculation
does not converge to a threshold value of force residual in a given number of iterations, the
configuration is rejected, ensuring that self-intersecting boundaries are excluded quickly.
A potential issue with the procedure above is that most resulting configurations in
the third group have larger values of mirror ratio _B_ _max_ _/B_ _min_ than typical stellarators.
For this reason, configurations with _B_ _max_ _/B_ _min_ _>_ 5 are immediately rejected. Also, a
subset of the random configurations is selected to bias the distribution towards smaller
mirror ratios. For the selected configurations, higher-resolution equilibrium calculations
are then run using DESC.
The final set of 23,577 equilibria included 3,200 rotating-ellipse configurations centered
on a circle, 3,200 rotating-ellipse configurations centered on a curve with torsion, 413
QUASR vacuum configurations, 3,964 QUASR finite-beta configurations, and 3,200
random boundaries for each of four values of _n_ _fp_ . More flux tubes were drawn from
the QUASR vacuum fields to increase the representation of this class. The final set of
100,705 flux tubes included 12,795 tubes from rotating-ellipse configurations centered
on a circle, 12,791 tubes from rotating-ellipse configurations centered on a curve with
torsion, 8,235 tubes from QUASR vacuum configurations, 15,809 tubes from QUASR
finite-beta configurations, and 51,075 tubes from random-boundary equilibria.


**Appendix B. Details of turbulence simulations**


Here, more details are given of the nonlinear turbulence simulations. Calculations were
performed using the version of GX from git commit b88d763.
For the dataset with varied gradients, the gradients were sampled randomly in each
simulation using the following procedure. Since _a/L_ _T i_ typically increases with radius,
we choose it to be _ρ_ times a random number with mean 4 and standard deviation 3,
resampling the latter until the result is ⩾ 1 _._ 5. Similarly, _a/L_ _n_ is chosen to be _ρ_ times a
random number with mean 1 and standard deviation 2, resampling until the number is
⩾ _−_ 0 _._ 5. This procedure results in 70% of the simulations yielding instability, 30% stable.
In all simulations, physical collisions were included with magnitude _ν_ _ii_ _a_ minor _/v_ _i_ = 0 _._ 01,


32 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


Figure 16. Dependence of _Q_ on the resolution parameter `nz` for a selection of flux tubes
with associated gradients from the varied-gradient dataset. The seven tubes, shown by different
colors, all have the highest value of _n_ _fp_ in the dataset (8) to give short scales in _z_ . The vertical
dotted line shows the value of `nz` used for the main dataset (96). Variation of _Q_ with increasing
resolution is small compared to the differences between geometries and gradients, indicating
sufficient convergence.


and we take _T_ _i_ _/T_ _e_ = 1. The transient behavior for _tv_ _i_ _/a_ minor _<_ 150 was ignored, and a
mean of the heat flux was computed over the remaining simulation time.
Resolution parameters for the simulations were as follows: box size `x0` = `y0` =10 *
2 _π_, perpendicular spatial resolution `nx` = `ny` =64, (so the dealiased _k_ _x_ and _k_ _y_ grids
were 2 _._ 1 _, −_ 2 _._ 0 _, . . ., −_ 0 _._ 1 _,_ 0 _,_ 0 _._ 1 _, . . .,_ 2 _._ 0 _,_ 2 _._ 1), number of grid points along the field line
`nz` =96, parallel velocity resolution `nhermite` =8, perpendicular velocity resolution
`nlaguerre` =4, simulation time _t_ max _v_ _i_ _/a_ minor = 800, and time step given by 0.9 times
the Courant–Friedrichs–Lewy condition. To arrive at these values, first each of these
parameters was scanned individually for a selection of flux tubes and gradients. An
example is shown in figure 16, in which `nz` is varied for several configurations with
_n_ _fp_ = 8, the highest value of _n_ _fp_ included in the dataset, resulting in the shortest
parallel length scales among the flux tubes in the collection. For each parameter, a value
was adopted at which _Q_ had approximately reached an asymptote. For changes to the
box size in _x_ or _y_, `nx` or `ny` was varied proportionally to keep the highest wavenumber
fixed. Flux tube length was not considered to be a resolution parameter like the others
mentioned above, since longer tubes do sample different regions of the flux surface
geometry, so changes to _Q_ are physical rather than numerical. Then to confirm that the
selected resolution parameters would be sufficient for most simulations in the dataset,
100 random flux tubes and gradients were selected from the varied-gradient data. Every
resolution parameter was varied by a factor of two or more for each flux tube and
GX was re-run. The results are displayed in figure 17. The coefficient of determination
between the original-resolution data and modified-resolution data is _R_ [2] = 0 _._ 993 for the
unstable cases, or including both stable and unstable cases _R_ [2] = 0 _._ 995 using eq (3.1).
The accuracy score for predicting the stability at high resolution from the stability at
standard resolution is 0.994. These values are greater than the values for any of the
surrogate fits discussed in this paper, meaning scatter due to discretization error is
smaller than imperfection in the fits. We therefore deem the resolution parameters to be
adequate.
Periodic boundary conditions were employed in all three spatial coordinates. For


_How does ITG turbulence depend on magnetic geometry?_ 33







|2x nx<br>2x nx and x0<br>2x ny<br>2x ny and y0<br>2x nhermite<br>2x nlaguerre<br>1/2 dt<br>2x tmax<br>1/10 hyperdiffusion<br>2x nz|Col2|Col3|
|---|---|---|
||1<br>0<br>1|2<br>|


Figure 17. Evidence of sufficient convergence with respect to numerical resolution parameters.
For 100 randomly sampled entries in the varied-gradient dataset, every resolution parameter is
varied by a factor of 2 or 10. The box sizes in _x_ and _y_ are denoted _x_ 0 and _y_ 0 in the legend.


the _z_ coordinate, the twist-and-shift boundary condition (Beer _et al._ 1995) and its
generalization to stellarators (Martin _et al._ 2018), while well-motivated physically, are
inconvenient when the integrated local magnetic shear is small. In this case the box size
in _x_ is required to be very large, necessitating large `nx` in order to resolve adequately high
_k_ _x_, increasing computation time. Were we to use the alternative boundary conditions by
Martin _et al._ (2018) that constrain the tube length to certain specific values, it would
no longer be possible to use the same tube length for all configurations, complicating
the analysis. Martin _et al._ (2018) found that the heat flux is insensitive to the choice
of boundary conditions as long as enough Fourier modes in _x_ are included to resolve
sufficiently high _k_ _x_ . We find the same to be true for the simulations here. Figure 18 shows
a comparison of periodic vs. twist-and-shift boundary conditions (using eq (24)-(25) of
Martin _et al._ (2018)) for a random sample of 100 flux tubes and associated gradients
from the varied-gradient dataset. For the twist-and-shift calculations, the box size in _x_ is
set by the quantization condition, and `nx` is increased as needed for each tube to match
the same maximum _k_ _x_ as in the periodic case ( _k_ _x_ = 2 _._ 1). The heat fluxes for the two
choices of boundary conditions are highly correlated. The _R_ [2] for predicting ln( _Q_ _linked_ )
from ln( _Q_ _periodic_ ) is 0.97, and the accuracy score for predicting stability for the twistand-shift case based on stability for the periodic case is 0.95. These values are deemed
sufficiently high that the periodic boundary condition was adopted for the study, given
the computational savings it allows.
At the resolution parameters given above, the mean simulation wallclock time was _∼_ 8
minutes on one Nvidia A100 GPU. The _∼_ 2 _×_ 10 [5] nonlinear simulations took _<_ 7000
node-hours, equivalent to _<_ 28 _,_ 000 gpu-hours (4 gpus/node).


34 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


Figure 18. Comparison of boundary conditions in _z_ for 100 randomly sampled flux tubes from
the varied-gradient dataset. The heat flux is insensitive to the choice of boundary condition if
the number of Fourier modes in _x_ is increased in each twist-and-shift calculation to match the
same maximum _k_ _x_ as the periodic calculations, as is done here.


In terms of normalized variables, the heat flux returned directly by GX is _Q/⟨|∇ρ|⟩_
where _Q_ = _⟨_ � _d_ [3] _v f_ ( _v_ [2] _/_ 2) **v** _d_ _·∇ρ⟩_ and _⟨. . .⟩_ = (� _dz/B_ ) _[−]_ [1] [ �] _dz_ ( _. . ._ ) _/B_ . For results in this
paper, we multiply through by _⟨|∇ρ|⟩_ to focus on _Q_ itself.
Simulations with _Q >_ 10 [3] are dropped from the dataset, since longer simulation times
and larger box sizes are likely needed for adequate resolution of these cases.


REFERENCES


Abbate, Joseph, Conlin, Rory & Kolemen, Egemen 2021 Data-driven profile prediction
for DIII-D. _Nuclear Fusion_ **61** (4), 046027.
Balaprakash, Prasanna, Salim, Michael, Uram, Thomas D, Vishwanath, Venkat &
Wild, Stefan M 2018 Deephyper: Asynchronous hyperparameter search for deep neural
networks. In _2018 IEEE 25th international conference on high performance computing_
_(HiPC)_, pp. 42–51. IEEE.
Barnes, M, Parra, FI & Schekochihin, AA 2011 Critically balanced ion temperature
gradient turbulence in fusion plasmas. _Physical Review Letters_ **107** (11), 115003.
Beer, Michael Alan, Cowley, SC & Hammett, GW 1995 Field-aligned coordinates for
nonlinear simulations of tokamak turbulence. _Physics of Plasmas_ **2** (7), 2687–2700.
Beurskens, Marc NA, Bozhenkov, Sergey A, Ford, O, Xanthopoulos, Pavlos,
Zocco, Alessandro, Turkin, Yuri, Alonso, A, Beidler, Craig, Calvo, I,
Carralero, Daniel & others 2021 Ion temperature clamping in wendelstein 7-x
electron cyclotron heated plasmas. _Nuclear Fusion_ **61** (11), 116072.
Boyer, Mark D & Chadwick, Jason 2021 Prediction of electron density and pressure profile
shapes on nstx-u using neural networks. _Nuclear Fusion_ **61** (4), 046024.
Brunton, Steven L, Proctor, Joshua L & Kutz, J Nathan 2016 Discovering governing
equations from data by sparse identification of nonlinear dynamical systems. _Proceedings_
_of the national academy of sciences_ **113** (15), 3932–3937.
Chen, Tianqi & Guestrin, Carlos 2016 Xgboost: A scalable tree boosting system. In
_Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and_
_data mining_, pp. 785–794.


_How does ITG turbulence depend on magnetic geometry?_ 35


Chen, Y, Parker, SE, Cohen, BI, Dimits, AM, Nevins, WM, Shumaker, D, Decyk,
VK & Leboeuf, JN 2003 Simulations of turbulent transport with kinetic electrons and
electromagnetic effects. _Nuclear fusion_ **43** (10), 1121.
Citrin, Jonathan, Breton, Sarah, Felici, Federico, Imbeaux, Frederic, Aniel, T,
Artaud, JF, Baiocchi, B, Bourdelle, C, Camenen, Y & Garcia, J 2015 Real-time
capable first principle based modelling of tokamak turbulent transport. _Nuclear Fusion_
**55** (9), 092001.
Curvo, P, Ferreira, DR & Jorge, R 2024 Using deep learning to design high aspect ratio
fusion devices. _arXiv preprint arXiv:2409.00564_ .
Dudt, DW & Kolemen, E 2020 Desc: A stellarator equilibrium solver. _Physics of Plasmas_
**27** (10).
Efroymson, Michael Alin 1960 Multiple regression analysis. _Mathematical methods for digital_
_computers_ pp. 191–203.
Egelé, Romain, Guyon, Isabelle, Vishwanath, Venkatram & Balaprakash,
Prasanna 2023 Asynchronous decentralized bayesian optimization for large scale
hyperparameter optimization. In _2023 IEEE 19th International Conference on e-Science_
_(e-Science)_, pp. 1–10. IEEE.
Frieman, EA & Chen, Liu 1982 Nonlinear gyrokinetic equations for low-frequency
electromagnetic waves in general plasma equilibria. _The Physics of Fluids_ **25** (3), 502–508.
Giuliani, Andrew 2024 Direct stellarator coil design using global optimization: application
to a comprehensive exploration of quasi-axisymmetric devices. _Journal of Plasma Physics_
**90** (3), 905900303.
Giuliani, Andrew, Rodríguez, Eduardo & Spivak, Marina 2024 A comprehensive
exploration of quasisymmetric stellarators and their coil sets. _arXiv_ _preprint_
_arXiv:2409.04826_ .
Goodman, Alan G, Xanthopoulos, Pavlos, Plunk, Gabriel G, Smith, Håkan,
Nührenberg, Carolin, Beidler, Craig D, Henneberg, Sophia A, Roberg-Clark,
Gareth, Drevlak, Michael & Helander, Per 2024 Quasi-isodynamic stellarators
with low turbulence as fusion reactor candidates. _PRX Energy_ **3** (2), 023010.
Greene, John M & Johnson, John L 1968 Interchange instabilities in ideal hydromagnetic
theory. _Plasma Physics_ **10** (8), 729.
Hegna, Chris C, Terry, Paul W & Faber, Ben J 2018 Theory of itg turbulent saturation
in stellarators: identifying mechanisms to reduce turbulent transport. _Physics of Plasmas_
**25** (2).
Hirshman, SP & Whitson, JC 1983 Steepest-descent moment method for three-dimensional
magnetohydrodynamic equilibria. _The Physics of Fluids_ **26** (12), 3553–3568.
Honda, M & Narita, E 2019 Machine-learning assisted steady-state profile predictions using
global optimization techniques. _Physics of Plasmas_ **26** (10).
Jorge, R, Dorland, W, Kim, P, Landreman, M, Mandell, N R, Merlo, G & Qian,
T 2024 Direct microstability optimization of stellarator devices. _Physical Review E_ **110**,
035201.
Jorge, Rogerio & Landreman, Matt 2020 The use of near-axis magnetic fields for stellarator
turbulence simulations. _Plasma Physics and Controlled Fusion_ **63** (1), 014001.
Kappel, John, Landreman, Matt & Malhotra, Dhairya 2024 The magnetic gradient
scale length explains why certain plasmas require close external magnetic coils. _Plasma_
_Physics and Controlled Fusion_ **66** (2), 025018.
Ke, Guolin, Meng, Qi, Finley, Thomas, Wang, Taifeng, Chen, Wei, Ma, Weidong,
Ye, Qiwei & Liu, Tie-Yan 2017 Lightgbm: A highly efficient gradient boosting decision
tree. _Advances in neural information processing systems_ **30** .
Koza, John R 1994 Genetic programming as a means for programming computers by natural
selection. _Statistics and computing_ **4**, 87–112.
Kruskal, MD & Kulsrud, RM 1958 Equilibrium of a magnetically confined plasma in a
toroid. _Physics of Fluids_ **1** (4), 265–274.
Landreman, M. 2025 _`[https: // doi. org/ 10. 5281/ zenodo. 14867776](https://doi.org/10.5281/zenodo.14867776)`_ .
Li, H, Wang, L, Fu, YL, Wang, ZX, Wang, TB & Li, JQ 2024 Surrogate model of turbulent
transport in fusion plasmas using machine learning. _Nuclear Fusion_ **65** (1), 016015.


36 _M Landreman, J Choi, C Alves, P Balaprakash, R Churchill, R Conlin, G Roberg-Clark_


Lipovetsky, Stan & Conklin, Michael 2001 Analysis of regression in game theory approach.
_Applied stochastic models in business and industry_ **17** (4), 319–330.
Liu, Ziming, Wang, Yixuan, Vaidya, Sachin, Ruehle, Fabian, Halverson, James,
Soljačić, Marin, Hou, Thomas Y & Tegmark, Max 2024 Kan: Kolmogorov-arnold
networks. _arXiv preprint arXiv:2404.19756_ .
Lundberg, Scott M., Erion, Gabriel, Chen, Hugh, DeGrave, Alex, Prutkin,
Jordan M., Nair, Bala, Katz, Ronit, Himmelfarb, Jonathan, Bansal, Nisha
& Lee, Su-In 2020 From local explanations to global understanding with explainable ai
for trees. _Nature Machine Intelligence_ **2** (1), 2522–5839.
Lundberg, Scott M & Lee, Su-In 2017 A unified approach to interpreting model predictions.
In _Advances in Neural Information Processing Systems 30_ (ed. I. Guyon, U. V. Luxburg,
S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan & R. Garnett), pp. 4765–4774. Curran
Associates, Inc.
Lunsford, R, Killer, C, Nagy, A, Gates, DA, Klinger, T, Dinklage, A,
Satheeswaran, G, Kocsis, G, Lazerson, SA, Nespoli, F & others 2021
Characterization of injection and confinement improvement through impurity induced
profile modifications on the wendelstein 7-x stellarator. _Physics of Plasmas_ **28** (8).
Mackenbach, RJJ, Proll, Josefine HE & Helander, P 2022 Available energy of trapped
electrons and its relation to turbulent transport. _Physical Review Letters_ **128** (17), 175001.
Mandell, NR, Dorland, William, Abel, Ian, Gaur, R, Kim, P, Martin, M & Qian,
T 2024 Gx: a gpu-native gyrokinetic turbulence code for tokamak and stellarator design.
_Journal of Plasma Physics_ **90** (4), 905900402.
Martin, Mike F, Landreman, Matt, Xanthopoulos, Pavlos, Mandell, Noah R &
Dorland, William 2018 The parallel boundary condition for turbulence simulations in
low magnetic shear devices. _Plasma Physics and Controlled Fusion_ **60** (9), 095008.
McKinney, IJ, Pueschel, MJ, Faber, BJ, Hegna, CC, Talmadge, JN, Anderson,
DT, Mynick, HE & Xanthopoulos, P 2019 A comparison of turbulent transport in
a quasi-helical and a quasi-axisymmetric stellarator. _Journal of Plasma Physics_ **85** (5),
905850503.

Meneghini, Orso, Luna, Christopher J, Smith, Sterling P & Lao, Lang L 2014
Modeling of transport phenomena in tokamak plasmas with neural networks. _Physics_
_of Plasmas_ **21** (6).
Meneghini, Orso, Smith, Sterling P, Snyder, Philip B, Staebler, Gary M, Candy,
Jeffrey, Belli, E, Lao, L, Kostuk, Mark, Luce, T, Luda, Teobaldo & others
2017 Self-consistent core-pedestal transport simulations with neural network accelerated
models. _Nuclear Fusion_ **57** (8), 086034.
Merlo, Andrea, Böckenhoff, Daniel, Schilling, Jonathan, Höfel, Udo, Kwak,
Sehyun, Svensson, Jakob, Pavone, Andrea, Lazerson, Samuel Aaron,
Pedersen, Thomas Sunn & others 2021 Proof of concept of a fast surrogate model of
the vmec code via neural networks in wendelstein 7-x scenarios. _Nuclear Fusion_ **61** (9),
096039.

Mynick, HE, Pomphrey, N & Xanthopoulos, P 2010 Optimizing stellarators for turbulent
transport. _Physical review letters_ **105** (9), 095004.
Mynick, H, Xanthopoulos, P, Faber, B, Lucia, M, Rorvig, M & Talmadge, JN 2014
Turbulent optimization of toroidal configurations. _Plasma Physics and Controlled Fusion_
**56** (9), 094001.
Nakata, Motoki & Matsuoka, Seikichi 2022 Impact of geodesic curvature on zonal flow
generation in magnetically conned plasmas. _Plasma and Fusion Research_ **17**, 1203077–
1203077.

Nakayama, Tomonari, Nakata, Motoki, Honda, Mitsuru, Narita, Emi, Nunami,
Masanori & Matsuoka, Seikichi 2023 A simplified model to estimate nonlinear
turbulent transport by linear dynamics in plasma turbulence. _Scientific Reports_ **13** (1),
2319.

Narita, E, Honda, M, Nakata, M, Yoshida, M, Hayashi, N & Takenaga, H 2019
Neural-network-based semi-empirical turbulent particle transport modelling founded on
gyrokinetic analyses of jt-60u plasmas. _Nuclear Fusion_ **59** (10), 106018.
Pedregosa, F., Varoquaux, G., Gramfort, A., Michel, V., Thirion, B., Grisel,
O., Blondel, M., Prettenhofer, P., Weiss, R., Dubourg, V., Vanderplas, J.,


_How does ITG turbulence depend on magnetic geometry?_ 37


Passos, A., Cournapeau, D., Brucher, M., Perrot, M. & Duchesnay, E. 2011
Scikit-learn: Machine learning in Python. _Journal of Machine Learning Research_ **12**, 2825–
2830.

van de Plassche, Karel Lucas, Citrin, Jonathan, Bourdelle, Clarisse, Camenen,
Yann, Casson, Francis J, Dagnelie, Victor I, Felici, Federico, Ho, Aaron,
Van Mulders, Simon & Contributors, JET 2020 Fast modeling of turbulent
transport in fusion plasmas using neural networks. _Physics of Plasmas_ **27** (2).
Proll, JHE, Mynick, HE, Xanthopoulos, P, Lazerson, SA & Faber, BJ 2015 Tem
turbulence optimisation in stellarators. _Plasma Physics and Controlled Fusion_ **58** (1),
014006.

Roberg-Clark, GT, Plunk, GG, Xanthopoulos, P, Nührenberg, C, Henneberg,
SA & Smith, HM 2023 Critical gradient turbulence optimization toward a compact
stellarator reactor concept. _Physical Review Research_ **5** (3), L032030.
Rosenbluth, MN & Hinton, FL 1998 Poloidal flow driven by ion-temperature-gradient
turbulence in tokamaks. _Physical review letters_ **80** (4), 724.
Shapley, Lloyd S 1953 A value for n-person games. _Contribution to the Theory of Games_ **2** .
Stroteich, Sven, Xanthopoulos, Pavlos, Plunk, Gabriel & Schneider, Ralf 2022
Seeking turbulence optimized configurations for the wendelstein 7-x stellarator: ion
temperature gradient and electron temperature gradient turbulence. _Journal of Plasma_
_Physics_ **88** (5), 175880501.
Wakasa, Arimitsu, Murakami, Sadayoshi, Itagaki, Masafumi & Oikawa, Shun-ichi
2007 Construction of neoclassical transport database for large helical device plasma
applying neural network method. _Japanese journal of applied physics_ **46** (3R), 1157.
Whitney, A Wayne 1971 A direct method of nonparametric measurement selection. _IEEE_
_transactions on computers_ **100** (9), 1100–1103.
Xanthopoulos, P, Mischchenko, A, Helander, P, Sugama, H & Watanabe, T-H 2011
Zonal flow dynamics and control of turbulent transport in stellarators. _Physical review_
_letters_ **107** (24), 245002.
Xanthopoulos, P, Mynick, HE, Helander, P, Turkin, Yu, Plunk, GG, Jenko, F,
Görler, T, Told, D, Bird, T & Proll, JHE 2014 Controlling turbulence in present
and future stellarators. _Physical review letters_ **113** (15), 155001.
Yeo, In-Kwon & Johnson, Richard A 2000 A new family of power transformations to
improve normality or symmetry. _Biometrika_ **87** (4), 954–959.
Zhang, Daihong, Buttenschön, B, Jablonski, S, Kubkowska, M, Ford, O, Alcusón,
JA, Beidler, CD, Burhenn, R, Beurskens, MNA, Langenberg, A & others 2023
Observation of impurity accumulation and its compatibility with high plasma performance
in w7-x. _Plasma Physics and Controlled Fusion_ **65** (10), 105006.


