## Feasibility-Driven Trust Region Bayesian Optimization

[Paolo Ascia](mailto:paolo.ascia@tum.de) [1] [Elena Raponi](mailto:e.raponi@liacs.leidenuniv.nl) [2] [Thomas B√§ck](mailto:t.h.w.baeck@liacs.leidenuniv.nl) [2] [Fabian Duddeck](mailto:duddeck@tum.de) [1]


1 Technical University of Munich, Arcisstr. 21, 80333 Munich, Germany
2 LIACS, Leiden University, Einsteinweg 55, 2333 CC Leiden, The Netherlands


Abstract Bayesian optimization is a powerful tool for solving real-world optimization tasks under
tight evaluation budgets, making it well-suited for applications involving costly simulations
or experiments. However, many of these tasks are also characterized by the presence of
expensive constraints whose analytical formulation is unknown and often defined in highdimensional spaces where feasible regions are small, irregular, and difficult to identify. In
such cases, a substantial portion of the optimization budget may be spent just trying to locate
the first feasible solution, limiting the effectiveness of existing methods. In this work, we
present a Feasibility-Driven Trust Region Bayesian Optimization (FuRBO) algorithm. FuRBO
iteratively defines a trust region from which the next candidate solution is selected, using
information from both the objective and constraint surrogate models. Our adaptive strategy
allows the trust region to shift and resize significantly between iterations, enabling the
optimizer to rapidly refocus its search and consistently accelerate the discovery of feasible
and good-quality solutions. We empirically demonstrate the effectiveness of FuRBO through
extensive testing on the full BBOB-constrained COCO benchmark suite and other physicsinspired benchmarks, comparing it against state-of-the-art baselines for constrained blackbox optimization across varying levels of constraint severity and problem dimensionalities
ranging from 2 to 60.


1 Introduction


The global optimization of black-box objective functions under expensive, black-box constraints‚Äî
where both are only accessible via costly point-wise evaluations‚Äîis a fundamental problem in fields
such as machine learning (ML), engineering design, robotics, and natural sciences. For instance,
in automated machine learning [Hutter et al., 2019], black-box optimization techniques, and in
particular Bayesian optimization (BO) [Garnett, 2023], are commonly used to tune hyperparameters
of ML models to maximize predictive performance under strict constraints on model inference time,
memory footprint, or energy consumption. This setup is common in frameworks like Auto-sklearn

[Feurer et al., 2022], AutoKeras [Jin et al., 2023], or custom pipelines for neural architecture search
under deployment constraints [Cai et al., 2019]. Constrained BO is also widely used in crashworthiness optimization [Raponi et al., 2019, Du et al., 2023] to efficiently tune design parameters for
objectives like weight or energy absorption, under constraints such as intrusion depth or peak
acceleration. In these settings, evaluating either the objective or constraints can be costly and
time-consuming, often relying on physical experiments or computationally intensive simulations.
The challenge of efficiently addressing black-box constrained problems is further amplified
in high-dimensional settings [Powell, 2019], meaning problem settings with dozens of decision
variables in the context of BO. In fact, as the volume of the search space increases, sampling
becomes sparse, surrogate models like Gaussian process regression models become harder to fit due
to the reduced correlation between points, optimization landscapes become more complex, with
many local optima and constraint boundaries that are trickier to approximate, and feasible regions
become narrow and non-convex islands in a vast space. A large portion of evaluations may land in
infeasible zones, and even identifying a single feasible point may consume a large portion‚Äîor even
all‚Äîof the available evaluation budget. This renders many existing BO methods ineffective.


AutoML 2025 [¬© 2025 the authors, released under CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)


Our contribution. Our work builds directly upon the Scalable Constrained Bayesian Optimization (SCBO) algorithm [Eriksson and Poloczek, 2021], which introduced a scalable trust-region-based
framework for constrained BO in high-dimensional settings. SCBO demonstrated that localizing the
search using dynamically-adapted trust regions, rather than relying on global surrogate optimization, offers both scalability and performance benefits. However, the trust regions defined by SCBO
make only partial use of the information deriving from the modeling of the problem constraints,
specifically to center the trust region and select the next candidate solutions, demonstrating particular effectiveness in the case where feasible regions are relatively easy to find‚Äîa condition
that often does not hold in the most challenging constrained problems. We hence propose the
_Feasibility-Driven Trust Region Bayesian Optimization_ (FuRBO) algorithm, specifically designed to
tackle high-dimensional constrained optimization problems where finding any feasible point is itself
difficult. FuRBO retains the core idea of adaptive trust regions but shifts the focus to feasibility-first
exploration relying on the constraint isocontour predicted by the surrogate model. To construct
the trust region, FuRBO leverages both the objective and constraint surrogate models. At each
iteration, FuRBO samples a set of points‚Äîreferred to as _inspectors_ ‚Äîuniformly distributed within a
ball of radius _ùëÖ_ centered at the best candidate found so far. These inspectors are evaluated over the
constraint landscape and used to estimate the likely location and shape of the feasible region. The
most promising inspectors, ranked using both the objective and constraint models, determine the
position, shape, and size of the trust region for the next search step. Within this feasibility-guided
trust region, it then applies Thompson sampling on the objective and constraint models to identify
new promising points to query. Through a series of comprehensive experiments on the full BBOBconstrained COCO benchmark suite [Dufoss√© et al., 2022] and other physics-inspired benchmarks,
both containing problems with increasing constraint complexity, we show that FuRBO, thanks to
its landscape-aware mechanism that uses inspector sampling to guide the search toward promising
feasible regions, either ties or outperforms other state-of-the-art alternatives for constrained BO,
with evident superiority in settings in which feasibility is rare and hence difficult to locate.
Reproducibility: The code for reproducing our experiments, along with the whole set of figures,
is available on GitHub [1] .


2 Related work


Bayesian optimization (BO) [Garnett, 2023] is a sample-efficient, model-based optimization framework for solving expensive black-box problems where function evaluations are costly or timeconsuming. On continuous search spaces, a Gaussian Process (GP) is commonly used in BO to
define a prior distribution over the unknown objective function, capturing assumptions about its
smoothness and variability. The process begins with an initial set of evaluated points (also known
as Design of Experiments [Forrester et al., 2008]) typically selected through random sampling or
space-filling designs. Once data from the initial evaluations is available, the GP is conditioned
on these observations to yield a posterior distribution, which provides an approximation of the
unknown objective function along with uncertainty estimates. An acquisition function (AF) is
then used to decide where to evaluate next by balancing exploration (sampling in regions of high
uncertainty) and exploitation (sampling where high objective values are likely). This iterative
process continues until the evaluation budget is exhausted or convergence is reached.
Constrained BO extends the classical BO framework to settings where one must optimize an
objective function subject to one or more unknown or expensive-to-evaluate constraints. This is
common in real-world scenarios, such as engineering design or hyperparameter tuning, where
feasible solutions must satisfy safety, performance, or resource limits. Despite most work on BO
has focused on unconstrained scenarios, some extensions to constrained optimization problems
have been introduced in the last years. The constrained expected improvement (CEI), introduced


1 [https://github.com/paoloascia/FuRBO](https://github.com/paoloascia/FuRBO)


2


by Schonlau et al. [1998] and popularized by Gardner et al. [2014], is the earliest and most widely
used technique for handling constraints in BO. It extends the standard Expected Improvement (EI)
AF to handle constraints by multiplying the improvement with the probability that a candidate
solution is feasible. This allows the algorithm to prioritize sampling in regions that are not only
promising in terms of objective value but also likely to satisfy the given constraints.
The Predictive Entropy Search with Constraints (PESC) AF by Hern√°ndez-Lobato et al. [2016]
focuses in particular on problems with decoupled constraints, in which subsets of the objective and
constraint functions may be evaluated independently. It extends the entropy search AF by not only
reducing uncertainty about the location of the global optimum, but doing so under the constraint
that the solution must also be feasible.

Picheny et al. [2016] proposed SLACK, which augments the standard constrained Bayesian
optimization framework with slack variables to reformulate equality constraints as inequalities.
By combining this with an augmented Lagrangian approach and EI, they demonstrated improved
performance in problems with equality constraints.

Ariafar et al. [2019] advanced the augmented Lagrangian framework by integrating the Alternating Direction Method of Multipliers (ADMM), allowing a more scalable and structured
optimization of constrained black-box problems. Their method also uses EI to select query points
and is particularly suited to problems with multiple and decoupled constraints.

Ungredda and Branke [2024] proposed a variant of the Knowledge Gradient (KG) AF‚Äîcalled
the constrained Knowledge Gradient (cKG)‚Äîto handle constrained optimization problems. In cKG,
feasibility is incorporated into the Bayesian lookahead by weighting the expected utility from the
objective GP with the estimated probability of feasibility from the constraint GPs, guiding the
search toward points that are both promising and likely to be feasible.
All of these methods were not designed with high-dimensional problems in mind and often
struggle with scalability. This limitation was instead addressed in the design of the Scalable
Constrained Bayesian Optimization (SCBO) framework by Eriksson et al. [2019], which introduced
a surrogate-based framework that models the objective and each constraint separately, allowing
for greater flexibility and modularity in the modeling process. It uses trust regions as a core
component, using them to search for new candidate solutions locally, in regions with predicted
high feasibility and optimality, allowing for robust scalability to high-dimensional constrained
spaces. Despite the introduction of new methods in recent years (see the survey by Amini et al.

[2025] for a comprehensive overview), SCBO remains a state-of-the-art approach for constrained
high-dimensional BO. Unlike most methods reviewed, despite SCBO being developed in response
to practical challenges, its performance has been rigorously benchmarked also on standard test
problems. This has contributed to its robustness, establishing SCBO as a standalone optimization
framework that is also accessible through the well-known BoTorch [Balandat et al., 2020] package.
For this reason, we developed our method, FuRBO, building on SCBO as a foundation, but redefining
the trust region design procedure to more effectively address problems with narrow, hard-to-find
feasible regions.


3 Problem definition


We consider the problem of minimizing a black-box objective function _ùëì_ : Œ© ‚Üí R subject to
multiple constraints. The goal is to identify an optimal design point _ùë•_ [‚àó] ‚àà Œ© ‚äÇ R _[ùê∑]_ that maximizes
the objective while satisfying all constraints:


_ùë•_ [‚àó] = arg min _ùëì_ ( _ùë•_ )
_ùë•_ ‚ààŒ© (1)

subject to _ùëê_ _ùëò_ ( _ùë•_ ) ‚â§ 0 _,_ ‚àÄ _ùëò_ ‚àà{1 _, . . ., ùêæ_ }


3


Alongside the objective, the constraint functions _ùëê_ _ùëò_ : Œ© ‚Üí R return a vector c ( _ùë•_ ) =

[ _ùëê_ 1 ( _ùë•_ ) _, . . .,ùëê_ _ùêæ_ ( _ùë•_ )] that quantifies the feasibility of a sample. A point is considered to be feasible if it belongs to the set Œ© feas = { _ùë•_ ‚àà Œ© | _ùëê_ _ùëò_ ( _ùë•_ ) ‚â§ 0 ‚àÄ _ùëò_ ‚àà{1 _, . . ., ùêæ_ }}.
We assume a limited evaluation budget of 10 _ùê∑_ function evaluations, reflecting the practical
setting of real-world applications where each evaluation is costly and only a small number of queries
is affordable. This low-budget scenario is precisely where BO methods are most effective. After
using the total evaluation budget, the algorithm recommends a solution _ùë•_ best ‚àà Œ© . If _ùë•_ best ‚àà _F_, we
measure the quality of a recommendation by loss, i.e., the simple regret, under feasibility conditions:
_ùëô_ ( _ùë•_ best ) = _ùëì_ ( _ùë•_ best ) ‚àí _ùëì_ ( _ùë•_ [‚àó] ), where _ùë•_ [‚àó] is the global optimum of the problem. If _ùë•_ _ùëü_ ‚àâ _F_, the solution is
considered infeasible and its maximum constraint violation ( _ùëâ_ max ( _ùë•_ ) = max _ùëñ_ =1 _,...,ùêæ_ max{ 0 _,ùëê_ _ùëò_ ( _ùë•_ )} )
is returned instead.


4 Feasibility-Driven Trust Region Bayesian Optimization


To overcome some of the limitations of optimizing highly constrained problems, we propose a
new algorithm: FuRBO. Our method shares the idea of using trust regions for BO introduced by
Eriksson et al. [2019]. However, instead of using the best-evaluate sample to define only the center
of the trust region, we identify its position and extension using the information available from
the approximation models of both the objective and constraint functions. What distinguishes our
approach from SCBO is the formulation of the trust region. We therefore begin by outlining the
SCBO framework, followed by a detailed explanation of how the trust region is defined in FuRBO.


4.1 SCBO algorithm


The SCBO framework extends the TuRBO algorithm [Eriksson et al., 2019] to address problems
with black-box constraints, by preserving most of the algorithm structure. It begins by evaluating
an initial design and fitting Gaussian Process (GP) models to the objective _ùëì_ ( _ùë•_ ) and constraints
_ùëê_ _ùëò_ ( _ùë•_ ) for _ùëò_ = 1 _, . . ., ùêæ_ . A trust region (TR) is initialized around the best feasible point; if none is
found, it is centered at the point with the smallest constraint violation.
The algorithm then iteratively proceeds until the evaluation budget is exhausted. In each
iteration, a batch of _ùëû_ candidate points is identified within the current trust region using a Thompson
Sampling (TS) [Thompson, 1933] AF: to return each of the _ùëû_ points, after sampling a large set of
_ùëü_ candidate solutions within the TR, a realization {( _ùëì_ [ÀÜ] ( _ùë•_ _ùëñ_ ) _,_ ÀÜ _ùëê_ 1 ( _ùë•_ _ùëñ_ ) _, ...,_ ÀÜ _ùëê_ _ùêæ_ ( _ùë•_ _ùëñ_ ))| 1 ‚â§ _ùëñ_ ‚â§ _ùëü_ } from the
posterior of both objective and constraints is sampled, and the candidate with maximum utility
among those that are predicted to be feasible is added to the batch.
Once the batch of _ùëû_ points is selected, the algorithm evaluates both the objective and constraint
functions at these locations. The TR is then updated: its center is moved to the best feasible point
found so far, some success/failure counters ( _ùëõ_ _ùë†_, _ùëõ_ _ùëì_ ) are updated, and the TR size _ùêø_ (same for all
dimensions) is adjusted if either _ùëõ_ _ùë†_ or _ùëõ_ _ùëì_ reach some threshold for the update, _ùúè_ _ùë†_ and _ùúè_ _ùëì_, respectively.
If _ùêø_ becomes smaller than a predefined threshold _ùêø_ min, the whole procedure is reinitialized.
At the end of the optimization, SCBO recommends the best feasible point found, i.e., the point
with the smallest objective value among those satisfying all constraints _ùëê_ _ùëò_ ( _ùë•_ ) ‚â§ 0 _,_ for _ùëò_ = 1 _, . . ., ùêæ_ .
We point the reader to the original paper by Eriksson and Poloczek [2021] for more details.


4.2 FuRBO algorithm


The main novelty of FuRBO is the definition of the TR. The other optimization steps are shared
with SCBO [Eriksson and Poloczek, 2021]. Nevertheless, for the sake of completeness, we present
in this section the entire optimization flow. We provide an illustration of the update procedure for
the TR in Figure 1 and the pseudocode of the entire FuRBO framework in Algorithm 1, with the
lines that differ from SCBO highlighted in yellow for clarity.
As shown in line 1 of Algorithm 1, FuRBO begins by sampling the entire search space Œ©,
following the standard initialization procedure of vanilla BO. It then evaluates the sample points


4


Figure 1: One iteration of FuRBO. The leftmost panel shows the true objective and constraint isocontours, with the global optimum in red. The next two panels show surrogate models of the
objective (top) and aggregated constraint (bottom), built from evaluated points (black dots);
the current best solution is marked in red. Inspectors (white crosses) are sampled around this
point and ranked by feasibility and objective value. The top _ùëÉ_ % (orange crosses) define the
TR (red square), using both objective and constraint models. A new candidate (orange dot) is
proposed within the TR, and the model are updated after evaluation (rightmost panel).


on the true objective and constraint functions, hence generating a set _S_ = {( _ùë•_ _ùëñ_ _, ùëì_ ( _ùë•_ _ùëñ_ ) _,_ c ( _ùë•_ _ùëñ_ ))} _ùëñ_ _[ùëÅ]_ =1 [of]
evaluated points. Here, c ( _ùë•_ _ùëñ_ ) = [ _ùëê_ 1 ( _ùë•_ _ùëñ_ ) _, . . .,ùëê_ _ùêæ_ ( _ùë•_ _ùëñ_ )] is a vector with as many components as the
number of constraints defining the problem. Let _F_ = { _ùë•_ _ùëñ_ ‚àà _S_ | _ùëê_ _ùëò_ ( _ùë•_ _ùëñ_ ) ‚â§ 0 _,_ ‚àÄ _ùëò_ = 1 _, . . ., ùêæ_ } be the
feasible set, i.e., the subset of feasible points in _S_ according to all the constraints. Let _F_ [¬Ø] = _S_ \ _F_
be its complement. At each iteration of the optimization procedure, until the evaluation budget is
exhausted, the following steps are performed.
Rank samples. For all feasible samples _ùë•_ _ùëñ_ ‚àà _F_, define the ranking by the true objective value _ùëì_ ( _ùë•_ _ùëñ_ ) (lower is better for minimization). Let the feasible samples be sorted such
that _ùëì_ ( _ùë•_ 1 [feas] ) ‚â§ _ùëì_ ( _ùë•_ 2 [feas] ) ‚â§¬∑ ¬∑ ¬∑ ‚â§ _ùëì_ ( _ùë•_ [feas] | _F_ | [)] [.] For the infeasible samples, we first normalize

each constraint dimension over all infeasible points: Àú _ùëê_ _ùëò_ ( _ùë•_ _ùëñ_ ) = max _ùëê_ _ùëò_ | _ùëê_ ( _ùëò_ _ùë•_ _ùëñ_ ( _ùë•_ ) _ùëñ_ ) | [for] _[ ùë•]_ _[ùëñ]_ [‚àà] _F_ ¬Ø _, ùëò_ =
1 _, . . ., ùêæ_ . We adopt this definition of normalization to preserve the boundary between feasibility and infeasibility. We then define the maximum normalized constraint violation per sample

Àú
_ùë£_ ( _ùë•_ _ùëñ_ ) = max _ùëò_ =1 _,...,ùêæ_ _ùëê_ _ùëò_ ( _ùë•_ _ùëñ_ ), and rank infeasible samples by ascending _ùë£_ ( _ùë•_ _ùëñ_ ) (smallest violation first):
_ùë£_ ( _ùë•_ 1 [infeas] ) ‚â§ _ùë£_ ( _ùë•_ 2 [infeas] ) ‚â§¬∑ ¬∑ ¬∑ ‚â§ _ùë£_ ( _ùë•_ [infeas] | _F_ [¬Ø] | [)] [. Finally we concatenate the ordered feasible and infeasible]

samples in _S_ ranked = ÔøΩ _ùë•_ 1 [feas] _, . . .,ùë•_ [feas] | _F_ | _[, ùë•]_ 1 [infeas] _, . . .,ùë•_ [infeas] | _F_ [¬Ø] | ÔøΩ . The procedure described in this step is

what defines the ranking metric _ùëü_ in Algorithm 1.
Generate the inspectors. We select the top-ranked point as the best candidate solution _ùë•_ _ùëèùëíùë†ùë°_ so
far (line 2). Around this point, we sample a set of inspector points _I_ = { _ùë•_ 1 _, . . .,ùë•_ _ùëÅ_ } by first drawing
from a multivariate normal distribution _N_ ( 0 _, ùúé_ [2] _ùêº_ _ùê∑_ ), normalizing each sample to lie on the unit
hypersphere, then scaling by a random factor in [ 0 _, ùëÖ_ ] and finally translating by _ùë•_ best, ensuring the
inspectors are uniformly distributed within a ball _B_ ( _ùë•_ best _, ùëÖ_ ) of radius _ùëÖ_ centered at _ùë•_ best (line 4).

Definition of the TR. The inspector population in _I_ is ranked as described in Step (1), but based
on the evaluated models _M_ and { _C_ _ùëò_ _,_ ‚àÄ _ùëò_ = 1 _, . . ., ùêæ_ } of the objective and _ùêæ_ constraints. We hence
define the ranked list _R_ over _I_ as _R_ = rank ( _I_ ; _M, C_ _ùëñ_ ) = sorted ( _I,_ by increasing _ùëü_ ( _ùë•_ )) (line 5).
Then, we select the top _ùëÉ_ % inspectors: _I_ best = { _ùë•_ ‚àà _R_ | rank( _ùë•_ ) ‚â§‚åà _ùëÉ_ - _ùëÅ_ ‚åâ} (line 6) and define the


5


Algorithm 1 FuRBO algorithm


Require: Success threshold _ùúè_ _ùë†_, failure threshold _ùúè_ _ùëì_, success counter _ùëõ_ _ùë†_, failure counter _ùëõ_ _ùëì_, batch size
_ùëû_, inspector percentage _ùëÉ_ %, sample set _S_ = ‚àÖ, surrogate model of the objective _M_, surrogate
model of the constraints _C_ _ùëò_, sampling radius _ùëÖ_, search space Œ©, initial trust region TR = Œ©,
Thompson sampling AF TS, function to optimize _ùëì_, constraint functions _ùëê_ _ùëò_, ranking metric _ùëü_
1: Evaluate initial design, update _S_ and train surrogate models ( _M, C_ _ùëò_ )
2: _ùë•_ best ‚Üê arg min _ùë•_ ‚àà _ùëã_ _ùëü_ ( _ùë•_ ; _ùëì,ùëê_ _ùëò_ ) _‚ä≤_ Update best candidate solution
3: while Optimization Budget Not Exhausted do
4: _I_ ‚Üê UniformBallSamples ( _ùë•_ best _, ùëÖ_ ) _‚ä≤_ Sample inspectors uniformly within _B_ ( _ùë•_ best _, ùëÖ_ )
5: _R_ ‚Üê rank ( _I_ ; _M, C_ _ùëò_ ) _‚ä≤_ Rank inspectors based on ( _M, C_ _ùëò_ )
6: _I_ best ‚Üê Top _ùëÉ_ % of sorted _I_ _‚ä≤_ Select the best inspectors ranked according to _R_
7: TR ‚Üê define_TR ( _I_ best ) _‚ä≤_ Define TR as the smallest hyperrectangle containing _I_ best
8: _ùëã_ next ‚Üê _ùëáùëÜ_ (( _M, C_ _ùëò_ ) _,_ TR _,ùëû_ ) _‚ä≤_ Propose next _ùëû_ configurations to evaluate within the TR
9: _ùëå_ ‚Üê _ùëì_ ( _ùëã_ next ) _‚ä≤_ Evaluate objective function on the new points
10: _ùê∂_ _ùëò_ ‚Üê _ùëê_ _ùëò_ ( _ùëã_ next ) _‚ä≤_ Evaluate constraint functions on the new points
11: _S_ ‚Üê _S_ ‚à™{( _ùëã_ next _,ùëå,ùê∂_ _ùëò_ )} _‚ä≤_ Update sample set
12: Fit surrogate models ( _M, C_ _ùëò_ ) over Œ©
13: Update _ùëõ_ _ùë†_ and _ùëõ_ _ùëì_
14: if _ùëõ_ _ùë†_ = _ùúè_ _ùë†_ or _ùëõ_ _ùëì_ = _ùúè_ _ùëì_ then _‚ä≤_ Check if thresholds for radius update is reached
15: _ùëÖ_ ‚Üê adjust ( _ùëÖ_ ) _‚ä≤_ Double/halve the variance of the distribution
16: end if
17: _ùë•_ best ‚Üê arg min _ùë•_ ‚àà _ùëã_ _ùëü_ ( _ùë•_ ; _ùëì,ùëê_ _ùëò_ ) _‚ä≤_ Update best candidate solution
18: end while

19: Return _ùë•_ best _‚ä≤_ Return best solution


TR as the smallest hyperrectangle that contains all points in _I_ best . Let _ùë•_ [min] _ùëó_ = min _ùë•_ ‚àà _I_ best _ùë•_ _ùëó_ and
_ùë•_ [max] _ùëó_ = max _ùë•_ ‚àà _I_ best _ùë•_ _ùëó_ _,_ for _ùëó_ = 1 _, . . .,ùëë_, then TR = [ÔøΩ] _[ùëë]_ _ùëó_ =1 [[] _[ùë•]_ [min] _ùëó_ _,ùë•_ [max] _ùëó_ ] (line 7).
Find new candidate solutions, update sample set and posterior distributions. Following the
SCBO algorithm, we use TS over the surrogate models ( _M, C_ _ùëò_ ), restricted to the current TR, to
propose a batch of _ùëû_ new points to evaluate (line 8). We then evaluate both the objective function _ùëì_
and the constraint functions _ùëê_ _ùëò_ at the proposed batch points _ùëã_ next (lines 9-10). We update the set
of evaluated samples _S_ (line 11) and we refit the surrogate models _M_ and _C_ _ùëò_ over the full search
space Œ© using the updated sample set _S_ (line 12).
We use the radius _ùëÖ_ of the uniform distribution to dynamically adjust the scale of the search
around _ùë•_ best . In the distribution _I_ ‚àº Uniform( _ùë•_ best _, ùëÖ_ ), we initialize _ùëÖ_ = 1. Given that the domain Œ©
is normalized to [ 0 _,_ 1 ] _[ùê∑]_ in our implementation, the initial distribution of samples covers the entire
domain, regardless of the exact position of _ùë•_ best . Similarly to SCBO, two counters are maintained
to track optimization progress (line 13): _ùëõ_ _ùë†_, the number of successes (iterations where the best
solution improves), and _ùëõ_ _ùëì_, the number of failures (iterations without improvement). At each
iteration, the radius is updated based on the following rules (lines 14-15): it is doubled if _ùëõ_ _ùë†_ = _ùúè_ _ùë†_ it
is halved if _ùëõ_ _ùëì_ = _ùúè_ _ùëì_, it remains unchanged otherwise. After each update, both counters are reset
( _ùëõ_ _ùë†_ ‚Üê 0 _,ùëõ_ _ùëì_ ‚Üê 0). The thresholds _ùúè_ _ùë†_ and _ùúè_ _ùëì_ are user-defined hyperparameters controlling the
frequency of zoom-in/zoom-out behavior. A very small radius indicates stagnation or convergence.
Optimization will be stopped or restarted when _ùëÖ_ ‚â§ _ùúÄ_, with _ùúÄ_ chosen by the user.


6


5 Experiments


5.1 Experimental setup


We evaluate the performance of FuRBO against the following state-of-the-art methods: Scalable
Constrained Bayesian Optimization (SCBO) by Eriksson and Poloczek [2021], constrained Expected
Improvement (cEI) introduced by Schonlau et al. [1998], Constrained Optimization by Linear Approximation (COBYLA) from Powell [1994], constrained Covariance Matrix Adaptation Evolution
Strategy (CMA-ES) by Hansen [2006], and a Random Search (for the URLs of the used implementations, see the References; our code is available on GitHub [2] ). We compare these algorithms on
the constrained black-box optimization benchmarking (BBOB-constrained) suite from the COCO
package [Hansen et al., 2021]. The results of the constrained BBOB benchmark for FuRBO and
SCBO are discussed in Sec. 5.2.1. The results comparing FuRBO to multiple baselines are discussed
in Sec. 5.2.2. In Appendix F, we extend our comparison between FuRBO and SCBO to include the
30-dimensional Keane bump synthetic benchmark, as well as several physics-inspired problems
with dimensionalities ranging from 3 to 60.
Constrained BBOB. We use the COCO/BBOB-constrained benchmark [Hansen et al., 2021],
comprising 4,860 constrained black-box functions generated by combining 9 base functions, 6 constraint sets of increasing severity, 6 dimensions, and 15 instances [Dufoss√© and Atamna, 2022]. The
functions are defined on a continuous search space and present different landscape characteristics
(separable, ill-conditioned, multi-modal functions). For our evaluation, we use the full suite to
compare FuRBO with its closest relative, SCBO. We consider 3 instances and 10 repetitions with
different random seed per function-constraint combination in dimensions 2, 10, and 40.
For comparisons against all the mentioned baselines, we select three representative functions
from the suite: Sphere (separable), Bent Cigar (ill-conditioned), and Rotated Rastrigin (multimodal) in 10 dimensions, each with medium-complex constraint structures. The same experimental
setup (initial design size 3D for the BO-based algorithms and initial sample 30D) is applied to all
algorithms.
Baselines Setup. FuRBO and SCBO are evaluated on these functions, each repeated 10 times
with different initial designs and random seeds. The initial design size is 3D, the batch size is
3D, and the total evaluation budget is 30D, where D is the problem dimension. FuRBO uses a TR
defined from the top 10% of inspectors sampled around the current best solution. The sampling
radius for the inspectors _ùëÖ_ is initialized to 1, doubled when the success counter reaches _ùúè_ _ùë†_ = 2, and
halved when the failure counter reaches _ùúè_ _ùëì_ = 3. Optimization restarts if _ùëÖ_ reaches a minimum
threshold _ùúÄ_ = 5 √ó 10 [‚àí][8] . CMA-ES and COBYLA are initialized using the default hyperparameter
settings recommended by their respective implementations [Hansen et al., 2019, Virtanen et al.,
2020]. For random sampling, we use a uniform distribution over the search space.
Performance metrics. We evaluate performance in terms of loss (simple regret), averaging over
30 runs with one standard error, and CPU time. Any feasible solution is preferred over infeasible
ones, which are assigned the worst observed objective value for a specific problem setting across
all compared methods [Hern√°ndez-Lobato et al., 2017]. CMA-ES and COBYLA are initialized from
the best point from the initial sample set generated for the BO methods.
Hardware and Runtime. All experiments are conducted on an Intel i9-12900K 3.20GHz CPU. To
provide an example of FuRBO runtime, the compute time for the constrained BBOB 10D functions
spanned from 5 _._ 2 sec to 250 sec on CPU, depending on the complexity of the function landscape
and the severity of the constraint. This gave a total of 33 h on CPU.


5.2 Results


5.2.1 Constrained BBOB in 10D. Figure 2 presents the loss (simple regret) convergence curves for
FuRBO and SCBO across the full constrained BBOB suite in 10 dimensions. Both algorithms are


2 [https://github.com/paoloascia/FuRBO](https://github.com/paoloascia/FuRBO)


7


Figure 2: Loss convergence curve on the full constrained BBOB suite at 10D. Results are averaged
across 3 instances with 10 repetitions each. The plot shows the mean loss with shaded areas
indicating one standard error. FuRBO consistently outperforms SCBO on more severely
constrained problems and performs comparably on easier ones.


run with a batch size _ùëû_ = 3 _ùê∑_, and total evaluation budget of 30 _ùê∑_ to mimic real-world scenarios
where function evaluations rely on very expensive procedures that can be run on parallel nodes (in
Appendix E.4 we provide an ablation study on the batch size _ùëû_ ).
Overall, FuRBO consistently outperforms SCBO on problems with a higher number of constraints and active constraints (rightmost columns), indicating its superior performance in severely
constrained scenarios. Notably, for configurations with 17 or more constraints, FuRBO achieves
faster convergence and lower final regret. For simpler problems (leftmost columns with 1‚Äì3 constraints), FuRBO performs comparably to SCBO, and in some cases the two methods are nearly
indistinguishable in terms of convergence speed and final performance. The exact final performances of FuRBO and SCBO are reported in Table 2 in Appendix A, where we also assess statistical
significance using the Wilcoxon rank-sum test. The analysis confirms that FuRBO achieves signifi

8


Figure 3: Convergence comparison of FuRBO against SCBO, CEI, COBYLA, CMA-ES, and random
sampling on _ùëì_ sphere, _ùëì_ bent_cigar, and _ùëì_ rast_rot in 10D. Curves show the mean loss over 10 repetitions of the same instance, with shaded regions indicating one standard error.


cantly better performance on the majority of the 10D problems. Similar figures to Figure 2, but
for 2 and 40 dimensions are available in Appendix C. While FuRBO and SCBO perform similarly
in 2D, FuRBO shows clear superiority in 40D, where it succeeds in finding feasible solutions in
cases where SCBO fails within the given evaluation budget. However, in the most strongly constrained scenarios, FuRBO also struggles to identify feasible regions, suggesting that the chosen
hyperparameter settings may be not optimal for such cases. We will further investigate this.
The improvement observed in highly constrained cases highlights the effectiveness of FuRBO‚Äôs
feasibility-aware TR strategy. Unlike SCBO, FuRBO defines its TR based on the area predicted to
be most promising, considering both feasibility and optimality predicted by the surrogate models
over the entire domain, rather than relying solely on the best evaluated sample. This allows the
TR to shift more freely across the domain and adapt its size dynamically: it contracts or expands
according to the predicted distribution of high-quality, feasible regions. As a result, FuRBO is better
able to zoom in on narrow feasible areas and escape local minima, offering faster convergence and
more robust performance in complex, constrained landscapes.


5.2.2 Comparison to SOTA baselines. Figure 3 shows the convergence of FuRBO compared to SCBO,
CEI, COBYLA, CMA-ES, and random sampling on three representative BBOB-constrained functions
in 10 dimensions: Sphere, Bent Cigar, and Rotated Rastrigin. In order to have a comparable setup for
all methods, we consider a batch size _ùëû_ = 1 for the BO methods (FuRBO, SCBO, and CEI), meaning
that only one candidate solution is returned by the AF and evaluated at each iteration.
FuRBO consistently achieves the lowest final loss and fastest convergence across all cases,
closely followed by SCBO. This highlights that the new definition of the TR introduced in FuRBO
is more beneficial when multiple solutions, potentially spread within the TR, are returned at each
iteration. On the ill-conditioned _ùëì_ bent_cigar problem, CEI converges to low-loss regions faster than
all baselines, however, FuRBO demonstrates greater exploitation capabilities by converging to a
solution with a statistically significant lower value of the objective function. For the multimodal
_ùëì_ rast_rot, FuRBO again outperforms the rest, directly followed by SCBO. CMA-ES and random
sampling perform poorly across all functions, highlighting the benefit of using surrogate models in
severely constrained and expensive settings. These results are confirmed in Table 4 in Appendix A.


6 Conclusions


We introduced FuRBO, a trust-region-based BO algorithm for severely constrained black-box
problems. Building on the SCBO framework, it redefines the trust region using a feasibility-aware


9


ranking of samples drawn uniformly from a ball centered around the current best point. This
allows FuRBO to dynamically adapt the location and size of the trust region based on global
surrogate information about both the objective and constraint functions, accelerating convergence
and improving exploitation of narrow feasible regions.
Our experiments on the BBOB-constrained benchmark suite demonstrate that FuRBO consistently outperforms or matches the performance of existing state-of-the-art methods, particularly in
scenarios involving tight or complex constraints.
However, FuRBO also comes with a few limitations and directions for future work. First, the
inspector-based ranking and trust region construction introduce additional model evaluations,
making the algorithm computationally more expensive than other baselines, thus most appropriate
when function evaluations are costly and dominate the runtime. Second, FuRBO still faces challenges
in high-dimensional, heavily constrained problems, where it sometimes fails to find feasible regions.
Third, our approach is still limited to a single axis-aligned trust region‚Äîa limitation we aim to
overcome in future work by exploring more flexible and potentially multiple trust regions with
adaptive orientations based on landscape characteristics. Finally, while we have evaluated our
method on several benchmark problems inspired by physics and real-world engineering applications
(e.g., spring design, pressure vessels, route planning), we will extend our validation to more complex
scenarios that originally motivated this work‚Äîspecifically, structural systems subject to crash
constraints, modeled using the solution space approach [Zimmermann and De Weck, 2021].


Acknowledgements. The project leading to this application has received funding from the European
Union‚Äôs Horizon 2020 research and innovation program under the Marie Sk≈Çodowska-Curie grant
agreement No 955393. The authors gratefully acknowledge the computational and data resources
provided by the Leibniz Supercomputing Centre ( www.lrz.de ).


References


S. Amini, I. Vannieuwenhuyse, and A. Morales-Hern√°ndez. Constrained Bayesian Optimization: A
Review. _IEEE Access_, 13:1581‚Äì1593, 2025. ISSN 2169-3536. doi: 10.1109/ACCESS.2024.3522876.


S. Ariafar, J. Coll-Font, D. Brooks, and J. Dy. ADMMBO: Bayesian Optimization with Unknown
Constraints using ADMM. _Journal of Machine Learning Research_, 20(123):1‚Äì26, 2019. ISSN

1533-7928.


M. Balandat, B. Karrer, D. R. Jiang, S. Daulton, B. Letham, A. G. Wilson, and E. Bakshy. BoTorch: A
Framework for Efficient Monte-Carlo Bayesian Optimization. In _Advances in Neural Information_
_Processing Systems 33_, 2020. URL [http://arxiv.org/abs/1910.06403](http://arxiv.org/abs/1910.06403) .


H. Cai, L. Zhu, and S. Han. ProxylessNAS: Direct Neural Architecture Search on Target Task and
Hardware, Feb. 2019.


X. Du, J. Liang, J. Lei, J. Xu, and P. Xie. A radial-basis function mesh morphing and Bayesian
Optimization framework for vehicle crashworthiness design. _Structural and Multidisciplinary_
_Optimization_, 66(3):64, Mar. 2023. ISSN 1615-1488. doi: 10.1007/s00158-023-03496-x.


P. Dufoss√© and A. Atamna. Benchmarking several strategies to update the penalty parameters in
AL-CMA-ES on the BBOB-constrained testbed. In _Proceedings of the Genetic and Evolutionary_
_Computation Conference Companion_, pages 1691‚Äì1699, 2022.


P. Dufoss√©, N. Hansen, D. Brockhoff, P. R. Sampaio, A. Atamna, and A. Auger. The BBOB-Constrained
COCO Test Suite. 2022.


D. Eriksson and M. Poloczek. Scalable constrained Bayesian optimization. In _International conference_
_on artificial intelligence and statistics_, pages 730‚Äì738. PMLR, 2021. doi: 10.48550/arXiv.2002.08526.


10


D. Eriksson, M. Pearce, J. Gardner, R. D. Turner, and M. Poloczek. Scalable global optimization via
local bayesian optimization. _Advances in neural information processing systems_, 32, 2019. doi: 10.
48550/arXiv.1910.01739. URL [https://github.com/pytorch/botorch/blob/main/tutorials/](https://github.com/pytorch/botorch/blob/main/tutorials/scalable_constrained_bo/scalable_constrained_bo.ipynb)
[scalable_constrained_bo/scalable_constrained_bo.ipynb](https://github.com/pytorch/botorch/blob/main/tutorials/scalable_constrained_bo/scalable_constrained_bo.ipynb) .


M. Feurer, K. Eggensperger, S. Falkner, M. Lindauer, and F. Hutter. Auto-Sklearn 2.0: Hands-free
AutoML via Meta-Learning, Oct. 2022.


A. I. J. Forrester, A. S√≥bester, and A. J. Keane. _Engineering Design via Surrogate Modelling - A_
_Practical Guide_ . John Wiley & Sons Ltd., 2008. ISBN 978-0-470-06068-1.


J. Gardner, M. Kusner, Zhixiang, K. Weinberger, and J. Cunningham. Bayesian Optimization with
Inequality Constraints. In _Proceedings of the 31st International Conference on Machine Learning_,
pages 937‚Äì945. PMLR, June 2014.


R. Garnett. _Bayesian Optimization_ . Cambridge University Press, 2023.


N. Hansen. The CMA evolution strategy: a comparing review. _Towards a new_
_evolutionary computation:_ _Advances in the estimation of distribution algorithms_, pages
75‚Äì102, 2006. URL [https://github.com/CMA-ES/pycma/blob/development/notebooks/](https://github.com/CMA-ES/pycma/blob/development/notebooks/notebook-usecases-constraints.ipynb)
[notebook-usecases-constraints.ipynb](https://github.com/CMA-ES/pycma/blob/development/notebooks/notebook-usecases-constraints.ipynb) .


N. Hansen, Y. Akimoto, and P. Baudis. CMA-ES/pycma on Github. Zenodo, Feb. 2019.


N. Hansen, A. Auger, R. Ros, O. Mersmann, T. Tu≈°ar, and D. B. and. COCO: a platform for comparing
continuous optimizers in a black-box setting. _Optimization Methods and Software_, 36(1):114‚Äì144,
2021. doi: 10.1080/10556788.2020.1808977.


J. M. Hern√°ndez-Lobato, M. A. Gelbart, R. P. Adams, M. W. Hoffman, and Z. Ghahramani. A General
Framework for Constrained Bayesian Optimization using Information-based Search, Sept. 2016.


J. M. Hern√°ndez-Lobato, J. Requeima, E. O. Pyzer-Knapp, and A. Aspuru-Guzik. Parallel and
Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space,
June 2017.


F. Hutter, L. Kotthoff, and J. Vanschoren. _Automated Machine Learning: Methods, Systems, Challenges_ .
Springer Nature, 2019.


H. Jin, F. Chollet, Q. Song, and X. Hu. Autokeras: An automl library for deep learning. _Journal of_
_Machine Learning Research_, 24(6):1‚Äì6, 2023. URL [http://jmlr.org/papers/v24/20-1355.html](http://jmlr.org/papers/v24/20-1355.html) .


A. Keane. Experiences with optimizers in structural design. In _Proceedings of the conference on_
_adaptive computing in engineering design and control_, volume 94, pages 14‚Äì27, 1994.


A. C. Lemonge, H. J. Barbosa, C. C. Borges, and F. B. Silva. Constrained optimization problems
in mechanical engineering design using a real-coded steady-state genetic algorithm. _Mec√°nica_
_Computacional_, 29(95):9287‚Äì9303, 2010.


V. Picheny, R. B. Gramacy, S. M. Wild, and S. L. Digabel. Bayesian optimization under mixed
constraints with a slack-variable augmented Lagrangian, May 2016.


M. J. Powell. _A direct search optimization method that models the objective and constraint functions_
_by linear interpolation_ . Springer, 1994. URL [https://docs.scipy.org/doc/scipy/reference/](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)
[generated/scipy.optimize.minimize.html#scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) .


11


W. B. Powell. A unified framework for stochastic optimization. _European Journal of Operational_
_Research_, 275(3):795‚Äì821, June 2019. ISSN 03772217. doi: 10.1016/j.ejor.2018.07.014.


E. Raponi, M. Bujny, M. Olhofer, N. Aulig, S. Boria, and F. Duddeck. Kriging-assisted topology
optimization of crash structures. _Computer Methods in Applied Mechanics and Engineering_, 348:
730‚Äì752, May 2019. ISSN 0045-7825. doi: 10.1016/j.cma.2019.02.002.


M. Schonlau, W. J. Welch, and D. R. Jones. Global versus local search in constrained optimization
of computer models. In _New Developments and Applications in Experimental Design_, volume 34,
pages 11‚Äì26. Institute of Mathematical Statistics, 1998. doi: 10.1214/lnms/1215456182.


W. R. Thompson. On the Likelihood that One Unknown Probability Exceeds Another in View
of the Evidence of Two Samples. _Biometrika_, 25(3/4):285‚Äì294, 1933. ISSN 0006-3444. doi:
10.2307/2332286.


J. Ungredda and J. Branke. Bayesian Optimisation for Constrained Problems. _ACM Trans. Model._
_Comput. Simul._, 34(2):9:1‚Äì9:26, Apr. 2024. ISSN 1049-3301. doi: 10.1145/3641544.


P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cournapeau, E. Burovski,
P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wilson, K. J. Millman,
N. Mayorov, A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. J. Carey, ƒ∞. Polat, Y. Feng, E. W. Moore,
J. VanderPlas, D. Laxalde, J. Perktold, R. Cimrman, I. Henriksen, E. A. Quintero, C. R. Harris,
A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy 1.0 Contributors. SciPy
1.0: Fundamental Algorithms for Scientific Computing in Python. _Nature Methods_, 17:261‚Äì272,
2020. doi: 10.1038/s41592-019-0686-2.


Z. Wang, C. Gehring, P. Kohli, and S. Jegelka. Batched large-scale bayesian optimization in highdimensional spaces. In _International Conference on Artificial Intelligence and Statistics_, pages
745‚Äì754. PMLR, 2018. doi: 10.48550/arXiv.1706.01445.


M. Zimmermann and O. De Weck. Formulating Engineering Systems Requirements. In
A. Maier, J. Oehmen, and P. E. Vermaas, editors, _Handbook of Engineering Systems Design_,
pages 1‚Äì52. Springer International Publishing, Cham, 2021. ISBN 978-3-030-46054-9. doi:
10.1007/978-3-030-46054-9_33-1.


12


A Statistical evaluation


Here, we show the exact loss values reached by the algorithms at the end of the evaluation budget.
Table 1 presents the mean and standard error of the final objective values achieved by FuRBO
and SCBO across constrained BBOB problems in 2D. Table 2 and Table 3 show similar results for
dimensions 10 and 40, respectively. The results span increasing levels of constraint severity‚Äîranging
from 1 to 9 + ‚åä 9 _ùê∑_ / 2 ‚åã constraints with varying numbers of active constraints and diverse problem
landscapes (e.g., separable, ill-conditioned, multimodal). The best performance per setting is
highlighted in bold, and statistical significance (via the Wilcoxon rank-sum test) is indicated in
gray shading.


Table 1: Mean and standard error of the final performance across constrained BBOB problems in
2D. Best result is highlighted in bold. Statistical significance is assessed using the Wilcoxon
rank-sum test. Results in gray indicate when one algorithm statistically outperforms the
other.

|Col1|Constraints: 1 (Active: 1)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 3 (Active: 2)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 9 (Active: 6)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|
|---|---|---|---|
|_ùëìùë†ùëù‚Ñéùëíùëüùëí_<br>_ùëìùëíùëôùëôùëñùëùùë†ùëúùëñùëë_<br>_ùëìùëôùëñùëõùëíùëéùëü_<br>_ùëìùëíùëôùëôùëñ_ùëüùëúùë°_<br>_ùëìùëëùëñùë†ùëêùë¢ùë†_<br>_ùëìùëèùëíùëõùë°_ùëêùëñùëîùëéùëü_<br>_ùëìùëëùëñùëìùëì_ùëùùëúùë§ùëíùëü_<br>_ùëìùëüùëéùë†ùë°ùëüùëñùëîùëñùëõ_<br>_ùëìùëüùëéùë†ùë°_ùëüùëúùë°_|0.210<br>0.040<br>0.527<br>0.079<br>0.210<br>0.038<br>0.249<br>0.054<br>0.018<br>0.003<br>0.040<br>0.006<br>1.213<br>0.242<br>1.723<br>0.339<br>0.645<br>0.169<br>0.550<br>0.086<br>1.270<br>0.555<br>1.196<br>0.226<br>2.828<br>1.185<br>3.306<br>1.054<br>93.082<br>16.884<br>93.329<br>11.818<br>73.645<br>9.311<br>82.339<br>9.907|2.218<br>0.231<br>4.000<br>0.561<br>8.843<br>1.067<br>16.295<br>2.378<br>1.615<br>0.255<br>2.711<br>0.397<br>11.792<br>2.008<br>18.158<br>3.125<br>6.643<br>0.688<br>13.904<br>0.971<br>1.052<br>0.212<br>1.844<br>0.329<br>10.584<br>3.024<br>7.576<br>1.116<br>57.056<br>10.020<br>71.572<br>12.851<br>46.497<br>10.778<br>73.251<br>11.686|4.181<br>0.721<br>6.794<br>0.987<br>19.783<br>2.363<br>49.156<br>7.773<br>2.748<br>0.261<br>4.518<br>0.413<br>16.756<br>1.427<br>50.838<br>4.230<br>20.132<br>4.756<br>46.491<br>8.410<br>55.458<br>11.197<br>123.389<br>14.978<br>14.498<br>2.651<br>16.235<br>2.274<br>76.061<br>17.027<br>88.406<br>12.570<br>56.962<br>11.597<br>54.464<br>5.800|
||Constraints: 9 + ‚åä3_ùê∑_/4‚åã(Active: 6 + ‚åä_ùê∑_/2‚åã)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + ‚åä3_ùê∑_/2‚åã(Active: 6 + D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + ‚åä9_ùê∑_/2‚åã(Active: 6 + 3D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|
|_ùëìùë†ùëù‚Ñéùëíùëüùëí_<br>_ùëìùëíùëôùëôùëñùëùùë†ùëúùëñùëë_<br>_ùëìùëôùëñùëõùëíùëéùëü_<br>_ùëìùëíùëôùëôùëñ_ùëüùëúùë°_<br>_ùëìùëëùëñùë†ùëêùë¢ùë†_<br>_ùëìùëèùëíùëõùë°_ùëêùëñùëîùëéùëü_<br>_ùëìùëëùëñùëìùëì_ùëùùëúùë§ùëíùëü_<br>_ùëìùëüùëéùë†ùë°ùëüùëñùëîùëñùëõ_<br>_ùëìùëüùëéùë†ùë°_ùëüùëúùë°_|5.744<br>1.631<br>14.549<br>2.023<br>12.433<br>1.263<br>22.620<br>2.009<br>3.328<br>0.307<br>8.648<br>0.772<br>33.862<br>4.473<br>63.640<br>7.423<br>182.689<br>53.678<br>346.352<br>111.304<br>60.131<br>5.471<br>94.093<br>16.005<br>28.864<br>4.662<br>20.930<br>2.344<br>120.532<br>16.204<br>102.261<br>14.164<br>111.154<br>12.988<br>92.853<br>11.593|6.572<br>1.152<br>14.143<br>2.994<br>24.394<br>2.351<br>42.980<br>3.945<br>5.537<br>0.470<br>8.703<br>0.829<br>23.085<br>3.515<br>46.577<br>8.061<br>24.937<br>1.916<br>83.970<br>10.258<br>89.175<br>18.078<br>104.077<br>10.872<br>12.032<br>1.548<br>23.973<br>3.615<br>46.561<br>7.852<br>65.294<br>6.302<br>82.750<br>16.000<br>136.416<br>12.411|6.274<br>0.804<br>7.488<br>0.928<br>39.976<br>7.470<br>67.786<br>9.901<br>5.183<br>0.622<br>17.188<br>1.581<br>19.182<br>2.509<br>49.176<br>6.168<br>20.889<br>3.112<br>56.955<br>7.429<br>94.550<br>28.501<br>427.606<br>341.950<br>16.172<br>4.186<br>20.328<br>2.068<br>113.930<br>16.120<br>194.695<br>12.615<br>52.617<br>10.019<br>81.268<br>8.328|



We observe that, nearly on all problems and across all levels of constraint severity, FuRBO
outperforms or matches SCBO, often by a statistically significant margin. Notably:


  The superiority of FuRBO becomes evident as the dimensionality of the problem and the severity
of the constraint increases.


  In dimension 2, despite the final loss values achieved by SCBO are sometimes better under mild
constraints, the performance is nevere statistically better than the one of FuRBO.


  In dimension 2 and 10, under the most stringent settings FuRBO demonstrates robust better
performance, significantly outperforming SCBO, where SCBO also exhibits a larger variance.


  In dimension 40, both FuRBO and SCBO fail to converge effectively for highly severe constraint
settings (9 + ‚åä 3 _ùê∑_ / 2 ‚åã and 9 + ‚åä 9 _ùê∑_ / 2 ‚åã constraints). However, FuRBO manages to find feasible
solutions for 9 + ‚åä3 _ùê∑_ /4‚åã constraints on nearly all benchmarks, while SCBO systematically fails.


These findings highlight FuRBO‚Äôs superior adaptability in severely constrained scenarios, thanks
to its feasibility-aware TR strategy. Also, the consistent performance across diverse problem types
and constraint severities suggest that the algorithm generalizes well, effectively balancing global
exploration with local refinement.


13


Table 2: Mean and standard error of the final performance across constrained BBOB problems in
10D. Best result is highlighted in bold. Statistical significance is assessed using the Wilcoxon
rank-sum test. Results in gray indicate when one algorithm statistically outperforms the other.
If a feasible solution is not returned, the results are marked as not available (n/a).

|Col1|Constraints: 1 (Active: 1)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 3 (Active: 2)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 9 (Active: 6)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|
|---|---|---|---|
|_ùëìùë†ùëù‚Ñéùëíùëüùëí_<br>_ùëìùëíùëôùëôùëñùëùùë†ùëúùëñùëë_<br>_ùëìùëôùëñùëõùëíùëéùëü_<br>_ùëìùëíùëôùëôùëñ_ùëüùëúùë°_<br>_ùëìùëëùëñùë†ùëêùë¢ùë†_<br>_ùëìùëèùëíùëõùë°_ùëêùëñùëîùëéùëü_<br>_ùëìùëëùëñùëìùëì_ùëùùëúùë§ùëíùëü_<br>_ùëìùëüùëéùë†ùë°ùëüùëñùëîùëñùëõ_<br>_ùëìùëüùëéùë†ùë°_ùëüùëúùë°_|21.964<br>1.388<br>138.804<br>10.956<br>5.831<br>0.481<br>19.519<br>1.359<br>0.122<br>0.022<br>0.087<br>0.017<br>13.956<br>1.076<br>22.265<br>1.618<br>0.523<br>0.098<br>0.638<br>0.087<br>156.625<br>11.214<br>1.011e+03<br>96.125<br>113.271<br>10.430<br>456.299<br>30.881<br>769.783<br>18.940<br>913.273<br>19.361<br>674.252<br>20.913<br>858.090<br>15.381|58.790<br>5.696<br>219.152<br>15.692<br>138.762<br>20.431<br>231.414<br>24.137<br>12.195<br>1.571<br>21.249<br>1.870<br>105.630<br>13.958<br>139.813<br>14.482<br>18.162<br>2.627<br>31.136<br>3.379<br>385.712<br>53.371<br>1.810e+03<br>142.890<br>121.649<br>9.565<br>470.231<br>29.952<br>887.369<br>32.102<br>1.209e+03<br>62.581<br>767.100<br>23.015<br>1.056e+03<br>33.444|198.514<br>18.634<br>585.673<br>39.943<br>512.837<br>34.019<br>1.083e+03<br>61.844<br>212.422<br>16.858<br>618.493<br>86.203<br>611.267<br>71.576<br>1.583e+03<br>142.554<br>288.711<br>17.185<br>765.207<br>71.978<br>1.453e+03<br>140.637<br>5.233e+03<br>480.111<br>196.147<br>13.799<br>693.546<br>72.736<br>1.128e+03<br>40.189<br>2.517e+03<br>379.334<br>958.011<br>34.706<br>2.033e+03<br>181.885|
||Constraints: 9 + ‚åä3_ùê∑_/4‚åã(Active: 6 + ‚åä_ùê∑_/2‚åã)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + ‚åä3_ùê∑_/2‚åã(Active: 6 + D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + ‚åä9_ùê∑_/2‚åã(Active: 6 + 3D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|
|_ùëìùë†ùëù‚Ñéùëíùëüùëí_<br>_ùëìùëíùëôùëôùëñùëùùë†ùëúùëñùëë_<br>_ùëìùëôùëñùëõùëíùëéùëü_<br>_ùëìùëíùëôùëôùëñ_ùëüùëúùë°_<br>_ùëìùëëùëñùë†ùëêùë¢ùë†_<br>_ùëìùëèùëíùëõùë°_ùëêùëñùëîùëéùëü_<br>_ùëìùëëùëñùëìùëì_ùëùùëúùë§ùëíùëü_<br>_ùëìùëüùëéùë†ùë°ùëüùëñùëîùëñùëõ_<br>_ùëìùëüùëéùë†ùë°_ùëüùëúùë°_|543.153<br>116.179<br>3.729e+03<br>114.165<br>1.534e+03<br>160.652<br>4.952e+03<br>630.699<br>258.470<br>29.091<br>809.796<br>103.165<br>1.056e+03<br>96.825<br>4.644e+03<br>601.538<br>424.307<br>31.046<br>5.358e+03<br>907.447<br>1.955e+03<br>164.335<br>8.968e+03<br>1.072e+03<br>282.976<br>22.572<br>885.045<br>86.379<br>1.797e+03<br>258.449<br>3.554e+03<br>321.989<br>1.086e+03<br>70.368<br>2.582e+03<br>210.997|369.019<br>15.963<br>1.805e+03<br>160.573<br>2.584e+03<br>395.692<br>3.967e+03<br>400.501<br>196.186<br>9.024<br>909.622<br>108.059<br>680.446<br>45.009<br>6.133e+03<br>566.422<br>3.337e+03<br>567.569<br>7.617e+03<br>239.395<br>2.753e+03<br>204.529<br>1.023e+04<br>618.958<br>310.649<br>15.017<br>1.783e+04<br>6.714e+03<br>1.171e+03<br>25.633<br>2.911e+03<br>295.358<br>1.245e+03<br>64.740<br>4.105e+03<br>252.273|2.976e+03<br>643.900<br>9.106e+03<br>215.199<br>3.446e+03<br>250.820<br>n/a<br>n/a<br>535.789<br>44.294<br>811.818<br>10.493<br>3.111e+03<br>587.884<br>1.347e+04<br>403.178<br>3.164e+03<br>243.911<br>n/a<br>n/a<br>1.092e+04<br>1.831e+03<br>2.640e+04<br>758.083<br>875.926<br>164.867<br>2.308e+03<br>59.269<br>1.650e+03<br>36.467<br>4.308e+03<br>164.089<br>1.840e+03<br>136.922<br>n/a<br>n/a|



Table 3: Mean and standard error of the final performance across constrained BBOB problems in
40D. Best result is highlighted in bold. Statistical significance is assessed using the Wilcoxon
rank-sum test. Results in gray indicate when one algorithm statistically outperforms the other.
If a feasible solution is not returned, the results are marked as not available (n/a).

|Col1|Constraints: 1 (Active: 1)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 3 (Active: 2)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 9 (Active: 6)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|
|---|---|---|---|
|_ùëìùë†ùëù‚Ñéùëíùëüùëí_<br>_ùëìùëíùëôùëôùëñùëùùë†ùëúùëñùëë_<br>_ùëìùëôùëñùëõùëíùëéùëü_<br>_ùëìùëíùëôùëôùëñ_ùëüùëúùë°_<br>_ùëìùëëùëñùë†ùëêùë¢ùë†_<br>_ùëìùëèùëíùëõùë°_ùëêùëñùëîùëéùëü_<br>_ùëìùëëùëñùëìùëì_ùëùùëúùë§ùëíùëü_<br>_ùëìùëüùëéùë†ùë°ùëüùëñùëîùëñùëõ_<br>_ùëìùëüùëéùë†ùë°_ùëüùëúùë°_|191.905<br>9.743<br>1.235e+03<br>74.848<br>72.660<br>4.706<br>199.098<br>15.666<br>0.120<br>0.026<br>0.063<br>0.019<br>83.392<br>7.957<br>249.737<br>23.016<br>0.181<br>0.046<br>0.284<br>0.043<br>1.770e+03<br>112.493<br>1.447e+04<br>720.873<br>1.510e+03<br>80.505<br>2.793e+03<br>133.038<br>3.804e+03<br>146.398<br>4.959e+03<br>101.575<br>4.318e+03<br>99.437<br>5.109e+03<br>161.808|891.213<br>56.888<br>2.195e+03<br>120.958<br>1.471e+03<br>251.414<br>1.594e+03<br>116.509<br>47.281<br>9.592<br>133.901<br>28.004<br>1.064e+03<br>67.244<br>1.602e+03<br>113.814<br>43.144<br>6.356<br>56.058<br>9.523<br>1.704e+04<br>1.369e+03<br>3.033e+04<br>1.906e+03<br>2.417e+03<br>200.116<br>6.807e+03<br>500.896<br>4.743e+03<br>138.682<br>6.602e+03<br>167.442<br>5.227e+03<br>174.590<br>6.311e+03<br>152.997|2.846e+03<br>187.348<br>4.947e+03<br>284.815<br>1.332e+03<br>135.523<br>4.121e+03<br>429.439<br>333.052<br>23.110<br>857.128<br>100.898<br>5.368e+03<br>424.582<br>1.046e+04<br>1.250e+03<br>265.416<br>35.171<br>666.984<br>77.161<br>5.530e+04<br>9.294e+03<br>1.130e+05<br>1.100e+04<br>5.250e+03<br>759.436<br>2.413e+04<br>3.647e+03<br>5.936e+03<br>197.260<br>8.826e+03<br>181.602<br>8.753e+03<br>447.437<br>1.484e+04<br>814.410|
||Constraints: 9 + ‚åä3_ùê∑_/4‚åã(Active: 6 + ‚åä_ùê∑_/2‚åã)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + ‚åä3_ùê∑_/2‚åã(Active: 6 + D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + ‚åä9_ùê∑_/2‚åã(Active: 6 + 3D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|
|_ùëìùë†ùëù‚Ñéùëíùëüùëí_<br>_ùëìùëíùëôùëôùëñùëùùë†ùëúùëñùëë_<br>_ùëìùëôùëñùëõùëíùëéùëü_<br>_ùëìùëíùëôùëôùëñ_ùëüùëúùë°_<br>_ùëìùëëùëñùë†ùëêùë¢ùë†_<br>_ùëìùëèùëíùëõùë°_ùëêùëñùëîùëéùëü_<br>_ùëìùëëùëñùëìùëì_ùëùùëúùë§ùëíùëü_<br>_ùëìùëüùëéùë†ùë°ùëüùëñùëîùëñùëõ_<br>_ùëìùëüùëéùë†ùë°_ùëüùëúùë°_|6.150e+03<br>539.698<br>n/a<br>n/a<br>1.307e+04<br>1.064e+03<br>n/a<br>n/a<br>2.413e+03<br>263.602<br>n/a<br>n/a<br>1.837e+04<br>1.347e+03<br>n/a<br>n/a<br>1.381e+04<br>524.696<br>n/a<br>n/a<br>7.508e+04<br>5.295e+03<br>n/a<br>n/a<br>8.737e+03<br>2.276e+03<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>1.191e+04<br>821.514<br>n/a<br>n/a|5.735e+03<br>238.843<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a|n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a|



Table 4 reports the final performance of FuRBO and four other SOTA baselines: SCBO, CEI,
COBYLA, and CMA-ES, on three representative benchmark functions in 10D: _ùëì_ sphere, _ùëì_ bent_cigar, and
_ùëì_ rast_rot . We omit random sampling because it never found a feasible solution in our comparison.
These chosen functions represent diverse landscape characteristics, from simple convex and separable functions, to ill-conditioned and multimodal. We highlight the best-performing algorithm
in bold, with statistical significance (via a pairwise Wilcoxon rank-sum test) indicated by gray
shading. This means that we highlight in gray a method only if it statistically outperformed all the
others in a problem setting.


14


On _ùëì_ sphere, a smooth, convex, and separable problem, FuRBO clearly outperforms SCBO and
dramatically outpaces CEI, COBYLA, and CMA-ES. On the ill-conditioned _ùëì_ bent_cigar function,
FuRBO again leads with a significantly lower final objective value than all baselines, highlighting
its capacity to exploit narrow feasible valleys. For the multimodal _ùëì_ rast_rot, FuRBO maintains its
lead, demonstrating superior exploration of complex feasible regions and local minima. However,
the final loss value significantly increases compared to the two simpler functions. These results
further highlight FuRBO‚Äôs strength, not only over its direct competitor SCBO, but also against
well-established baselines fro constrained optimization from the literature.


Table 4: Mean and standard error of the final performance on the class representative functions in 10D.
The best result for each function is highlighted in bold. Statistical significance is assessed
using the Wilcoxon rank-sum test. Results in gray indicate when one algorithm statistically
outperforms all the others.


_ùëì_ _ùë†ùëù‚Ñéùëíùëüùëí_ _ùëì_ _ùëèùëíùëõùë°_ _ _ùëêùëñùëîùëéùëü_ _ùëì_ _ùëüùëéùë†ùë°_ _ _ùëüùëúùë°_
Mean S.E. Mean S.E. Mean S.E.

FuRBO 7.286 0.580 68.944 5.132 760.095 38.507

SCBO 14.237 0.696 107.133 5.568 925.548 47.247

CEI 829.146 87.943 798.386 96.740 2093.581 270.394

COBYLA 126.358 86.315 5787.570 1536.906 1156.212 126.745

CMA-ES 1211.966 116.424 8874.131 1200.243 3331.974 350.704


B Scalability of FuRBO


Figure 4 illustrates the mean loss convergence of FuRBO and SCBO on three constrained BBOB
functions: _ùëì_ sphere, _ùëì_ bent_cigar, and _ùëì_ rast_rot, evaluated at a mid-severe constraint level (9 + ‚åä 3 _ùê∑_ / 4 ‚åã
constraints, out of which 6 + ‚åä _ùê∑_ / 2 ‚åã are active) in dimensions 2, 10, and 40. The results are averaged
across 3 problem instances and 10 repetitions each, with shaded areas representing one standard

error.

FuRBO demonstrates clear scalability advantages as dimensionality increases. In 2D, FuRBO and
SCBO perform similarly, with FuRBO showing slightly faster convergence in the early evaluations.
In 10D and 40D, FuRBO consistently outperforms SCBO, achieving lower final losses and faster

convergence.
We note that, particularly in higher dimensions, the convergence curves exhibit a step-wise
pattern. This behavior is due to the chosen batch size of _ùëû_ = 3 _ùê∑_ and the way solutions within each
batch are automatically ordered by objective value (from worst to best) by the BoTorch package,
from which we took the SCBO implementation and on which we also base our own. As a result,
early points in each batch tend to be of lower quality and are often outperformed by previously
found solutions, leading to flat segments in the convergence curves. Instead, the last solutions
returned in the batch, which are of higher quality, typically bring an improvement.


15


Figure 4: Loss convergence curve on _ùëì_ sphere, _ùëì_ bent_cigar, and _ùëì_ rast_rot constrained BBOB functions at 10D
and mid-severe constraint level, for varying dimensionality of the problems. Results are
averaged across 3 instances with 10 repetitions each. The plot shows the mean loss with
shaded areas indicating one standard error. FuRBO clearly outperforms SCBO in 10D and
40D, while it shows comparable performance to SCBO in 2D, with slightly faster convergence.



16


C Full results on Constrained BBOB


In this section, we show the comparison between FuRBO and SCBO on the full constrained BBOB
test suite for dimension 10.
In 2D (Figure 5), both FuRBO and SCBO perform similarly across most functions and constraint
levels.
In 40D (Figure 6), the difference becomes more pronounced. FuRBO outperforms SCBO under
moderate constraint counts. This is particularly evident on the 9 constraints (6 active) column.
As the constraint severity increases, SCBO stops finding any feasible solutions, as indicated by
the constant convergence trend, while FuRBO continues to make progress. In more extreme cases
(9 + ‚åä 3 _ùê∑_ / 2 ‚åã or 9 + ‚åä 9 _ùê∑_ / 2 ‚åã constraints), both methods struggle to find feasible improvements within
the available evaluation budget.


Figure 5: Loss convergence curve on the full constrained BBOB suite at 2D. Results are averaged
across 3 instances with 10 repetitions each. The plot shows the mean loss with shaded areas
indicating one standard error. FuRBO and SCBO have comparable convergence trends.


17


Figure 6: Loss convergence curve on the full constrained BBOB suite at 40D. Results are averaged
across 3 instances with 10 repetitions each. The plot shows the mean loss with shaded
areas indicating one standard error. FuRBO is on par or outperforms SCBO for mild and
medium-severe constraints, while both methods fail in finding feasible solutions for strongly
constrained scenarios.



18


D CPU time


Figure 7: Average CPU time (in seconds) of FuRBO and SCBO across 10D all the constrained BBOB
functions under increasing numbers of constraints. The two methods have comparable
runtime, which increases with constraint severity.



19


Figure 7 presents the average CPU time required by FuRBO and SCBO in 10D, as the number of
constraints and problem complexity increase. The batch size set for both algorithms is _ùëû_ = 3 _ùê∑_ .
Across all test functions, both methods show a similar scaling trend: runtime increases with
the number of constraints, as expected due to the additional computational burden of constraint
modeling and feasibility checking. FuRBO‚Äôs computational cost presents only marginal increases
compared to SCBO‚Äôs, as it performs additional calls to the objective and constraint approximation
models for the definition of the TR.
Figure 8 compares FuRBO and SCBO with other established baselines (CEI, COBYLA, and CMAES) on three representative functions in 10D and medium-high constraint severity (9 + ‚åä 3 _ùê∑_ / 4 ‚åã
constraints, 6 + ‚åä _ùê∑_ / 2 ‚åã active). As expected, the surrogate-based methods (CEI, SCBO, and FuRBO)
are by far the most expensive. COBYLA and CMA-ES are significantly faster, but at the cost of
substantially poorer optimization performance (as shown in Figure 3 and Table 4).
Please note that the runtime tracked for FuRBO and SCBO for these settings seem in contrast
with the one shown in Figure 8, for the same dimensionality. This is motivated by the fact that here,
for comparison purposes, we are running all the methods (except CMA-ES, due to its inherently
parallel design) in serial mode.
In summary, FuRBO offers a favorable balance between performance and runtime, finding
better solutions than baselines like SCBO and CEI, while keeping computational overhead well
within practical limits.


Figure 8: Average CPU time (log scale) of FuRBO against other four baselines (SCBO, CEI, COBYLA,
and CMA-ES) on three representative 10D functions: _ùëì_ sphere, _ùëì_ bent_cigar, and _ùëì_ rast_rot . FuRBO
and SCBO have similar runtimes, while CEI is slightly more expensive. COBYLA and CMA-ES
are much faster but at the cost of reduced solution quality (see Table 4).


E Ablation studies


In this section, we provide ablation studies on four influential hyperparameters of FuRBO. The size
of the initial sample, the initial radius _ùëÖ_ of the ball containing the uniformly distributed population
of inspectors, the percentage of investigators used to define the trust region, and the batch size
_ùëû_ . All the studies in this section are performed on the _ùëì_ bent_cigar function with 24 constraints in
dimension 10. We do not present a study on the effect of the number of investigators, as it did
not show any noticeable impact in our experiments. We also experimented with using the total
constraint violation, as done in SCBO [Eriksson et al., 2019], but observed no notable difference in


20


performance compared to our current ranking based on maximum normalized constraint violation.
The corresponding plots are available in the GitHub repository.


E.1 Initial sample size


Figure 9 presents a study on the impact of the size of the initial sample set, also referred to as
Design of Experiments (DoE), on the optimization performance of FuRBO. We compare four DoE
sizes proportional to the problem dimensionality, specifically, 1D, 3D, 5D, and 10D initial points.
The results show that larger DoE sizes (e.g., 10D) tend to delay early convergence, as more
evaluations are used upfront for model initialization before optimization begins. In contrast, smaller
DoE sizes (1D‚Äì5D) enable comparable (and faster compared to the 10D size) progress by allowing
the iterative procedure to start earlier, without noticeably compromising the accuracy of the
approximation models of the objective and constraints, and thus preserving the effectiveness of the
landscape-aware mechanism for TR definition.


Figure 9: Study on the impact of the initial sample size on FuRBO in dimension 10 on the _ùëì_ bent_cigar
BBOB function with 24 constraints. Initial sample sizes equal to 1D, 3D, 5D and 10D are
compared. Experiments run on _ùëì_ bent_cigar BBOB function with 24 constraints.


E.2 Sampling radius


Figure 10 shows the effects of changing the initial value of the sampling radius _ùëÖ_ for the population
of inspectors. We compare the performance of five different starting radii, _ùëÖ_ = { 1 _._ 0 _,_ 0 _._ 5 _,_ 0 _._ 2 _,_ 0 _._ 1 _,_ 0 _._ 05 },
on the constrained _ùëì_ bent_cigar function (with 24 constraints).

The results show that, when FuRBO is initialized with a radius smaller than 0 _._ 5, the algorithm‚Äôs
performance deteriorates due to overlocalization of the search from the very first iterations, limiting
its ability to search for feasible solutions and explore the landscape before convergence. No
difference in performance was observed for _ùëÖ_ = 1 _._ 0 and _ùëÖ_ = 0 _._ 5 as both these choices allowed for a
full coverage of the search space.


E.3 Inspector percentage


Figure 11 investigates the effect of the percentage _ùëÉ_ % of inspectors selected to define the TR in
FuRBO. Specifically, we compare the performance on the constrained _ùëì_ bent_cigar function (with 24
constraints) using selection rates of 1%, 5%, 10%, and 20%.


21


Figure 10: Study on the impact of the initial radius of the uniform distribution for the inspectors. The
following initial radii are compared on the _ùëì_ bent_cigar BBOB function with 24 constraints:
_ùëÖ_ = {1 _._ 0 _,_ 0 _._ 5 _,_ 0 _._ 2 _,_ 0 _._ 1 _,_ 0 _._ 05}.


The results show that the algorithm‚Äôs performance deteriorates as this percentage increases.
However, we believe that these results highly depend on the landscape of the problem at hand. Very
small percentages (e.g., 1%) enable faster initial progress by quickly narrowing down to promising
regions, but they may limit the algorithm‚Äôs ability to explore diverse feasible areas. Conversely,
larger values (e.g., 20%) lead to slower progress, as the TR is influenced by a broader sample set,
which may dilute the effect of high-quality candidates. Given this sensitivity, it would be beneficial
to perform a dedicated hyperparameter optimization for this selection percentage to adapt it to the
problem at hand.


Figure 11: Study on the impact of the percentage _ùëÉ_ % of inspectors selected to define the position
and extension of the TR. The following percentages are compared: 1%, 5%, 10%, and 20%.
Experiments run on _ùëì_ bent_cigar BBOB function with 24 constraints.


22


(a) Loss. (b) CPU time.


Figure 12: Study on the impact of the batch size _ùëû_ on the performance of FuRBO. The following
configurations are compared: 1 (sequential), 1D, 2D, 3D, 4D, and 5D samples per batch.
Experiments run on _ùëì_ bent_cigar BBOB function with 24 constraints.


E.4 Batch size


Figure 12 examines the impact of batch size _ùëû_ on FuRBO‚Äôs performance and computational cost.
We compare six batch configurations: sequential (1 sample per iteration), and parallel batches of
size 1D, 2D, 3D, 4D, and 5D.
Figure 12a shows that larger batch sizes generally lead to slower convergence as many samples
are evaluated per iteration without the model being updated. The sequential setting (batch size = 1)
achieves the fastest convergence in terms of evaluations, but as seen in Figure 12b, it incurs the
highest computational cost due to frequent model updates and definitions of the TR.
Conversely, increasing the batch size significantly reduces CPU time, with a 5D batch being
about 20 times faster than the sequential setup, while maintaining competitive final performance.
Thus, intermediate batch sizes from 2D to 4D seem to provide a favorable trade-off, offering
both efficiency and robust convergence behavior. FuRBO is therefore well-suited for optimization
problems that require parallel evaluations of the objective and constraint functions, particularly
when wall-clock time is a critical factor and parallel computing nodes are available.


F Results on other benchmarks


In this section, we present additional comparisons between FuRBO and SCBO. We include the
minimization of the 30D Keane Bump function under two constraints, as well as several physicsinspired benchmark problems spanning dimensions from 3 to 60. For all problems, we independently
ran both algorithms and report the results obtained from our own experiments.


F.1 Keane bump function (30D)


We consider the Keane function [Keane, 1994] in 30 dimensions under two constraints over the
domain [0 _,_ 10] _[ùê∑]_ :


23


Ô∏É

ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ



min _ùëì_ ( _ùë•_ ) = ‚àí

Ô∏É



Ô∏É

ÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩÔøΩ



ÔøΩ _ùëñùê∑_ =1 [cos] [4] [(] _[ùë•]_ _[ùëñ]_ [) ‚àí] [2] [ÔøΩ] _ùëñ_ _[ùê∑]_ =1 [cos] [2] [(] _[ùë•]_ _[ùëñ]_ [)]

Ô∏É _ùê∑_
~~‚àöÔøΩ~~ _ùëñ_ =1 _[ùëñùë•]_ _ùëñ_ [2]



Ô∏É


(2)



Ô∏É


s _._ t _. ùëê_ 1 ( _ùë•_ ) = 0 _._ 75 ‚àí



Ô∏É


_ùê∑_


_ùë•_ _ùëñ_ ‚â§ 0 _,_

ÔøΩ

_ùëñ_ =1



Ô∏É


_ùëê_ 2 ( _ùë•_ ) =



Ô∏É


_ùê∑_


_ùë•_ _ùëñ_ ‚àí 7 _._ 5 _ùëë_ ‚â§ 0 _._

‚àëÔ∏Å

_ùëñ_ =1



Ô∏É


The algorithms are evaluated with an initial DoE of 3D, a batch size of 3D, and a total budget of
30D. More specifically, FuRBO starts with an initial radius of 1 _._ 0 for the inspector population, and
defines the TR by considering the top 10% of the investigators.

The results in Figure 13 indicate that FuRBO slightly outperforms SCBO on the 30D Keane
Bump function, particularly in the later stages of the optimization. This suggests that FuRBO‚Äôs trust
region mechanism can offer benefits in high-dimensional settings. However, since the problem is
only mildly constrained, the performance gap remains modest.

Ô∏É



Figure 13: Convergence of FuRBO and SCBO on the 30D Keane Bump function under two constraints
in the domain [ 0 _,_ 10 ] _[ùê∑]_ . Results are averaged over 10 independent runs for each algorithm.
The plot shows the mean objective value, with shaded areas representing one standard

error.


F.2 Spring volume minimization (3D)


The first physics-inspired benchmark we evaluate is the minimization of the volume of a spring
under four mechanical constraints [Lemonge et al., 2010]. The spring is described by three design
parameters: the number of active coils of the spring _ùëÅ_ ‚àà[ 2 _,_ 15 ], the winding diameter _ùê∑_ _ùë§_ ‚àà

[ 0 _._ 25 _,_ 1 _._ 3 ], and the wire diameter _ùëë_ _ùë§_ ‚àà[ 0 _._ 05 _,_ 2 ] . We compare the performance of FuRBO and SCBO
with an initial DoE of 3D, a batch size of 3D, and a total budget of 30D.

Figure 14 shows the convergence behavior of FuRBO and SCBO on the 3D Spring design
problem. Both methods steadily reduce the volume as the number of evaluations increases. While
SCBO converges faster in the early stages and maintains a performance advantage throughout most
of the optimization, the gap between the two methods is small. These results suggest that FuRBO


24


does not offer a significant benefit over SCBO in low-dimensional, lightly constrained problems,
where the added complexity of its feasibility-driven trust region mechanism may be less impactful.


Figure 14: Convergence of FuRBO and SCBO on the 3D Spring design problem with three design
variables, under four constraints. Results are averaged over 10 independent runs for each
algorithm. The plot shows the mean objective value (volume), with shaded areas representing one standard error.


F.3 Welded beam cost minimization (4D)


The second physics-inspired problem is the minimization of the welding costs for a beam under
five mechanical constraints [Lemonge et al., 2010]. The design space is described by the length
_ùëô_ ‚àà[ 0 _._ 1 _,_ 10 _._ 0 ] and the height _‚Ñé_ ‚àà[ 0 _._ 125 _,_ 10 _._ 0 ] of the welding, and the thickness _ùë°_ ‚àà[ 0 _._ 1 _,_ 10 _._ 0 ] and
the width _ùëè_ ‚àà[ 0 _._ 1 _,_ 10 _._ 0 ] of the beam. Both FuRBO and SCBO are initialized with an initial DoE 3D
samples, a batch size of 3D, and a total budget of 30D.

Figure 15 shows minimal difference between SCBO and FuRBO, which, as in the previous
benchmark, can be attributed to the problem‚Äôs low dimensionality and weak constraint structure.


Figure 15: Convergence of FuRBO and SCBO on the 4D welded beam cost minimization problem,
formulated with four design variables and five constraints. Results are averaged over 10
independent runs for each algorithm. The plot shows the mean objective value (cost), with
shaded areas representing one standard error.


25


F.4 Pressure vessel mass minimization (4D)


The third physics-inspired is the mass minimization of a pressure vessel [Lemonge et al., 2010].
The problem is described by four parameters ( _ùëá_ _ùë†_, _ùëá_ _‚Ñé_, _ùëÖ_, _ùêø_ ) and constrained by four functions. In
this case, the thickness of the walls of the pressure vessel _ùëá_ _ùë†_ and the thickness of the wall of the
head of the vessel _ùëá_ _‚Ñé_ vary in the range [ 0 _._ 0625 _,_ 5 ], in constant steps of 0 _._ 0625. Instead, the inner
radius of the vessel _ùëÖ_ and the length of the cylindrical component _ùêø_ are defined in the [ 10 _,_ 200 ]
interval and continuous. We compare the performance between FuRBO and SCBO with an initial
DoE size of 3D, a batch size of 3D, and a total budget of 30D. Because of the low dimensionality
and the weak constraints, the two algorithms show very similar performance (Figure 16).


Figure 16: Convergence of FuRBO and SCBO on the pressure vessel design problem with four design
parameters and four constraints. Results are averaged over 10 independent runs for each
algorithm. The plot shows the mean objective value (weight), with shaded areas representing
one standard error.


F.5 Speed reducer volume minimization (7D)


The speed reducer volume minimization [Lemonge et al., 2010] problem presents 7 parameters and
11 constraints. The parameters are the gear face width _ùëè_ ‚àà[ 2 _._ 6 _,_ 3 _._ 6 ], the teeth module _ùëö_ ‚àà[ 0 _._ 7 _,_ 0 _._ 8 ],
the number of teeth on the pinion _ùëõ_ ‚àà[ 17 _,_ 28 ], the length of the first shaft between the supporting
bearings _ùëô_ 1 ‚àà[ 7 _._ 3 _,_ 8 _._ 3 ], the length of the second shaft between the supporting bearings _ùëô_ 2 ‚àà[ 7 _._ 8 _,_ 8 _._ 3 ],
the diameter of the first shaft _ùëë_ 1 ‚àà[2 _._ 9 _,_ 3 _._ 9], and the diameter of the second shaft _ùëë_ 2 ‚àà[2 _._ 9 _,_ 3 _._ 9].

Although this problem has a low dimensionality, it is highly constrained. As the results in
Figure 17 show, FuRBO outperforms SCBO by a significant margin.


F.6 Rover trajectory planning (60D)


The last benchmark on which we compare SCBO and FuRBO is the problem of planning the route
of a rover over a terrain with different types of obstacles [Wang et al., 2018]. Similarly to Eriksson
et al. [2019], we modify the original unconstrained trajectory optimization problem to include 15
hard constraints. The optimization problem is defined over a decision vector _ùë•_ ‚àà[ 0 _,_ 1 ] [60], which
encodes the trajectory _ùõæ_ ( _ùë•_ ) of a rover navigating a grid environment. The environment contains
112 yellow obstacles, which the rover may cross at a cost, and 15 red obstacles, which must be
avoided. A visualization of the problem definition is provided in Figure 18a, where the yellow
squares represent the obstacles that the rover can overcome, while the red squares represent the
obstacles to be avoided.


26


Figure 17: Convergence of FuRBO and SCBO on the speed reducer design problem with seven design
parameters and eleven constraints. Results are averaged over 10 independent runs for
each algorithm. The plot shows the mean objective value (volume), with shaded areas
representing one standard error.


The objective function _ùëì_ ( _ùë•_ ) is defined as a reward function, which combines the trajectory cost
with penalties on initial and final positions and is given by:


_ùëì_ ( _ùë•_ ) = _ùëê_ ( _ùë•_ ) + _ùúÜ_ [ÔøΩ] ‚à• _ùë•_ 0 _,_ 1 ‚àí _ùë†_ ‚à• 1 + ‚à• _ùë•_ 59 _,_ 60 ‚àí _ùëî_ ‚à• 1 ÔøΩ + _ùëè,_


where _ùëê_ ( _ùë•_ ) is a trajectory cost that penalizes any collision with an object along the trajectory by
-20, _ùë†_ and _ùëî_ are the start and goal coordinates, _ùúÜ_ = ‚àí 10 is a weighting factor, and _ùëè_ = 5 is a bias term.
We redefine the hard constraint functions _ùëê_ _ùëñ_ ( _ùë•_ ), each associated with a red obstacle _ùëú_ _ùëñ_, as:



_ùëë_ ( _ùõº,_ center( _ùëú_ _ùëñ_ )) if _ùõæ_ ( _ùë•_ ) ‚à© _ùëú_ _ùëñ_ ‚â† ‚àÖ _,_

‚àëÔ∏Å

_ùõº_ ‚àà _ùõæ_ ( _ùë•_ )‚à© _ùëú_ _ùëñ_

‚àí min otherwise _,_
_ùõº_ ‚àà _ùõæ_ ( _ùë•_ ) _[ùëë]_ [(] _[ùõº,]_ [ center][(] _[ùëú]_ _[ùëñ]_ [))]



_ùëê_ _ùëñ_ ( _ùë•_ ) =



Ô£±Ô£¥Ô£¥Ô£¥Ô£≤

Ô£¥Ô£¥Ô£¥Ô£≥



where _ùëë_ (¬∑ _,_ - ) denotes the Euclidean distance.
This defines a maximization problem in which the rover is penalized for traversing yellow
obstacles and for deviating from the start and goal positions. The 15 red obstacles are enforced
as hard constraints: if the rover intersects a red square, the corresponding constraint returns the
total distance from the center to the intruding trajectory points; otherwise, it returns the negative
distance from the center to the closest trajectory point. The constraint _ùëê_ _ùëñ_ ( _ùë•_ ) ‚â§ 0 ensures that a
trajectory solution avoids the _ùëñ_ -th red obstacle.
For performance evaluation, both SCBO and FuRBO are initialized with 100 samples, use a
batch size of 100, and are run for a total budget of 2000 evaluations. As shown in Figure 18b, SCBO‚Äôs
convergence stagnates at a lower reward value compared to FuRBO.


27


(a) Trajectory planning problem. (b) Convergence.


Figure 18: Study on the trajectory-finding problem of a rover in dimension 60, under 15 constraints. (a)
Visualization of the design domain problem and a trajectory solution. The yellow squares
represent the obstacles the rover can overcome at a pre-fixed cost. The red squares represent
the obstacles the rover must avoid (hard constraints). The blue line is a trajectory solution
from the starting point (the white circle) to the goal point (the white cross). (b) Performance
comparison between SCBO and FuRBO, averaged over 10 independent runs per algorithm.



28


