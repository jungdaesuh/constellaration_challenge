## Feasibility-Driven Trust Region Bayesian Optimization

[Paolo Ascia](mailto:paolo.ascia@tum.de) [1] [Elena Raponi](mailto:e.raponi@liacs.leidenuniv.nl) [2] [Thomas BÃ¤ck](mailto:t.h.w.baeck@liacs.leidenuniv.nl) [2] [Fabian Duddeck](mailto:duddeck@tum.de) [1]


1 Technical University of Munich, Arcisstr. 21, 80333 Munich, Germany
2 LIACS, Leiden University, Einsteinweg 55, 2333 CC Leiden, The Netherlands


Abstract Bayesian optimization is a powerful tool for solving real-world optimization tasks under
tight evaluation budgets, making it well-suited for applications involving costly simulations
or experiments. However, many of these tasks are also characterized by the presence of
expensive constraints whose analytical formulation is unknown and often defined in highdimensional spaces where feasible regions are small, irregular, and difficult to identify. In
such cases, a substantial portion of the optimization budget may be spent just trying to locate
the first feasible solution, limiting the effectiveness of existing methods. In this work, we
present a Feasibility-Driven Trust Region Bayesian Optimization (FuRBO) algorithm. FuRBO
iteratively defines a trust region from which the next candidate solution is selected, using
information from both the objective and constraint surrogate models. Our adaptive strategy
allows the trust region to shift and resize significantly between iterations, enabling the
optimizer to rapidly refocus its search and consistently accelerate the discovery of feasible
and good-quality solutions. We empirically demonstrate the effectiveness of FuRBO through
extensive testing on the full BBOB-constrained COCO benchmark suite and other physicsinspired benchmarks, comparing it against state-of-the-art baselines for constrained blackbox optimization across varying levels of constraint severity and problem dimensionalities
ranging from 2 to 60.


1 Introduction


The global optimization of black-box objective functions under expensive, black-box constraintsâ€”
where both are only accessible via costly point-wise evaluationsâ€”is a fundamental problem in fields
such as machine learning (ML), engineering design, robotics, and natural sciences. For instance,
in automated machine learning [Hutter et al., 2019], black-box optimization techniques, and in
particular Bayesian optimization (BO) [Garnett, 2023], are commonly used to tune hyperparameters
of ML models to maximize predictive performance under strict constraints on model inference time,
memory footprint, or energy consumption. This setup is common in frameworks like Auto-sklearn

[Feurer et al., 2022], AutoKeras [Jin et al., 2023], or custom pipelines for neural architecture search
under deployment constraints [Cai et al., 2019]. Constrained BO is also widely used in crashworthiness optimization [Raponi et al., 2019, Du et al., 2023] to efficiently tune design parameters for
objectives like weight or energy absorption, under constraints such as intrusion depth or peak
acceleration. In these settings, evaluating either the objective or constraints can be costly and
time-consuming, often relying on physical experiments or computationally intensive simulations.
The challenge of efficiently addressing black-box constrained problems is further amplified
in high-dimensional settings [Powell, 2019], meaning problem settings with dozens of decision
variables in the context of BO. In fact, as the volume of the search space increases, sampling
becomes sparse, surrogate models like Gaussian process regression models become harder to fit due
to the reduced correlation between points, optimization landscapes become more complex, with
many local optima and constraint boundaries that are trickier to approximate, and feasible regions
become narrow and non-convex islands in a vast space. A large portion of evaluations may land in
infeasible zones, and even identifying a single feasible point may consume a large portionâ€”or even
allâ€”of the available evaluation budget. This renders many existing BO methods ineffective.


AutoML 2025 [Â© 2025 the authors, released under CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)


Our contribution. Our work builds directly upon the Scalable Constrained Bayesian Optimization (SCBO) algorithm [Eriksson and Poloczek, 2021], which introduced a scalable trust-region-based
framework for constrained BO in high-dimensional settings. SCBO demonstrated that localizing the
search using dynamically-adapted trust regions, rather than relying on global surrogate optimization, offers both scalability and performance benefits. However, the trust regions defined by SCBO
make only partial use of the information deriving from the modeling of the problem constraints,
specifically to center the trust region and select the next candidate solutions, demonstrating particular effectiveness in the case where feasible regions are relatively easy to findâ€”a condition
that often does not hold in the most challenging constrained problems. We hence propose the
_Feasibility-Driven Trust Region Bayesian Optimization_ (FuRBO) algorithm, specifically designed to
tackle high-dimensional constrained optimization problems where finding any feasible point is itself
difficult. FuRBO retains the core idea of adaptive trust regions but shifts the focus to feasibility-first
exploration relying on the constraint isocontour predicted by the surrogate model. To construct
the trust region, FuRBO leverages both the objective and constraint surrogate models. At each
iteration, FuRBO samples a set of pointsâ€”referred to as _inspectors_ â€”uniformly distributed within a
ball of radius _ğ‘…_ centered at the best candidate found so far. These inspectors are evaluated over the
constraint landscape and used to estimate the likely location and shape of the feasible region. The
most promising inspectors, ranked using both the objective and constraint models, determine the
position, shape, and size of the trust region for the next search step. Within this feasibility-guided
trust region, it then applies Thompson sampling on the objective and constraint models to identify
new promising points to query. Through a series of comprehensive experiments on the full BBOBconstrained COCO benchmark suite [DufossÃ© et al., 2022] and other physics-inspired benchmarks,
both containing problems with increasing constraint complexity, we show that FuRBO, thanks to
its landscape-aware mechanism that uses inspector sampling to guide the search toward promising
feasible regions, either ties or outperforms other state-of-the-art alternatives for constrained BO,
with evident superiority in settings in which feasibility is rare and hence difficult to locate.
Reproducibility: The code for reproducing our experiments, along with the whole set of figures,
is available on GitHub [1] .


2 Related work


Bayesian optimization (BO) [Garnett, 2023] is a sample-efficient, model-based optimization framework for solving expensive black-box problems where function evaluations are costly or timeconsuming. On continuous search spaces, a Gaussian Process (GP) is commonly used in BO to
define a prior distribution over the unknown objective function, capturing assumptions about its
smoothness and variability. The process begins with an initial set of evaluated points (also known
as Design of Experiments [Forrester et al., 2008]) typically selected through random sampling or
space-filling designs. Once data from the initial evaluations is available, the GP is conditioned
on these observations to yield a posterior distribution, which provides an approximation of the
unknown objective function along with uncertainty estimates. An acquisition function (AF) is
then used to decide where to evaluate next by balancing exploration (sampling in regions of high
uncertainty) and exploitation (sampling where high objective values are likely). This iterative
process continues until the evaluation budget is exhausted or convergence is reached.
Constrained BO extends the classical BO framework to settings where one must optimize an
objective function subject to one or more unknown or expensive-to-evaluate constraints. This is
common in real-world scenarios, such as engineering design or hyperparameter tuning, where
feasible solutions must satisfy safety, performance, or resource limits. Despite most work on BO
has focused on unconstrained scenarios, some extensions to constrained optimization problems
have been introduced in the last years. The constrained expected improvement (CEI), introduced


1 [https://github.com/paoloascia/FuRBO](https://github.com/paoloascia/FuRBO)


2


by Schonlau et al. [1998] and popularized by Gardner et al. [2014], is the earliest and most widely
used technique for handling constraints in BO. It extends the standard Expected Improvement (EI)
AF to handle constraints by multiplying the improvement with the probability that a candidate
solution is feasible. This allows the algorithm to prioritize sampling in regions that are not only
promising in terms of objective value but also likely to satisfy the given constraints.
The Predictive Entropy Search with Constraints (PESC) AF by HernÃ¡ndez-Lobato et al. [2016]
focuses in particular on problems with decoupled constraints, in which subsets of the objective and
constraint functions may be evaluated independently. It extends the entropy search AF by not only
reducing uncertainty about the location of the global optimum, but doing so under the constraint
that the solution must also be feasible.

Picheny et al. [2016] proposed SLACK, which augments the standard constrained Bayesian
optimization framework with slack variables to reformulate equality constraints as inequalities.
By combining this with an augmented Lagrangian approach and EI, they demonstrated improved
performance in problems with equality constraints.

Ariafar et al. [2019] advanced the augmented Lagrangian framework by integrating the Alternating Direction Method of Multipliers (ADMM), allowing a more scalable and structured
optimization of constrained black-box problems. Their method also uses EI to select query points
and is particularly suited to problems with multiple and decoupled constraints.

Ungredda and Branke [2024] proposed a variant of the Knowledge Gradient (KG) AFâ€”called
the constrained Knowledge Gradient (cKG)â€”to handle constrained optimization problems. In cKG,
feasibility is incorporated into the Bayesian lookahead by weighting the expected utility from the
objective GP with the estimated probability of feasibility from the constraint GPs, guiding the
search toward points that are both promising and likely to be feasible.
All of these methods were not designed with high-dimensional problems in mind and often
struggle with scalability. This limitation was instead addressed in the design of the Scalable
Constrained Bayesian Optimization (SCBO) framework by Eriksson et al. [2019], which introduced
a surrogate-based framework that models the objective and each constraint separately, allowing
for greater flexibility and modularity in the modeling process. It uses trust regions as a core
component, using them to search for new candidate solutions locally, in regions with predicted
high feasibility and optimality, allowing for robust scalability to high-dimensional constrained
spaces. Despite the introduction of new methods in recent years (see the survey by Amini et al.

[2025] for a comprehensive overview), SCBO remains a state-of-the-art approach for constrained
high-dimensional BO. Unlike most methods reviewed, despite SCBO being developed in response
to practical challenges, its performance has been rigorously benchmarked also on standard test
problems. This has contributed to its robustness, establishing SCBO as a standalone optimization
framework that is also accessible through the well-known BoTorch [Balandat et al., 2020] package.
For this reason, we developed our method, FuRBO, building on SCBO as a foundation, but redefining
the trust region design procedure to more effectively address problems with narrow, hard-to-find
feasible regions.


3 Problem definition


We consider the problem of minimizing a black-box objective function _ğ‘“_ : Î© â†’ R subject to
multiple constraints. The goal is to identify an optimal design point _ğ‘¥_ [âˆ—] âˆˆ Î© âŠ‚ R _[ğ·]_ that maximizes
the objective while satisfying all constraints:


_ğ‘¥_ [âˆ—] = arg min _ğ‘“_ ( _ğ‘¥_ )
_ğ‘¥_ âˆˆÎ© (1)

subject to _ğ‘_ _ğ‘˜_ ( _ğ‘¥_ ) â‰¤ 0 _,_ âˆ€ _ğ‘˜_ âˆˆ{1 _, . . ., ğ¾_ }


3


Alongside the objective, the constraint functions _ğ‘_ _ğ‘˜_ : Î© â†’ R return a vector c ( _ğ‘¥_ ) =

[ _ğ‘_ 1 ( _ğ‘¥_ ) _, . . .,ğ‘_ _ğ¾_ ( _ğ‘¥_ )] that quantifies the feasibility of a sample. A point is considered to be feasible if it belongs to the set Î© feas = { _ğ‘¥_ âˆˆ Î© | _ğ‘_ _ğ‘˜_ ( _ğ‘¥_ ) â‰¤ 0 âˆ€ _ğ‘˜_ âˆˆ{1 _, . . ., ğ¾_ }}.
We assume a limited evaluation budget of 10 _ğ·_ function evaluations, reflecting the practical
setting of real-world applications where each evaluation is costly and only a small number of queries
is affordable. This low-budget scenario is precisely where BO methods are most effective. After
using the total evaluation budget, the algorithm recommends a solution _ğ‘¥_ best âˆˆ Î© . If _ğ‘¥_ best âˆˆ _F_, we
measure the quality of a recommendation by loss, i.e., the simple regret, under feasibility conditions:
_ğ‘™_ ( _ğ‘¥_ best ) = _ğ‘“_ ( _ğ‘¥_ best ) âˆ’ _ğ‘“_ ( _ğ‘¥_ [âˆ—] ), where _ğ‘¥_ [âˆ—] is the global optimum of the problem. If _ğ‘¥_ _ğ‘Ÿ_ âˆ‰ _F_, the solution is
considered infeasible and its maximum constraint violation ( _ğ‘‰_ max ( _ğ‘¥_ ) = max _ğ‘–_ =1 _,...,ğ¾_ max{ 0 _,ğ‘_ _ğ‘˜_ ( _ğ‘¥_ )} )
is returned instead.


4 Feasibility-Driven Trust Region Bayesian Optimization


To overcome some of the limitations of optimizing highly constrained problems, we propose a
new algorithm: FuRBO. Our method shares the idea of using trust regions for BO introduced by
Eriksson et al. [2019]. However, instead of using the best-evaluate sample to define only the center
of the trust region, we identify its position and extension using the information available from
the approximation models of both the objective and constraint functions. What distinguishes our
approach from SCBO is the formulation of the trust region. We therefore begin by outlining the
SCBO framework, followed by a detailed explanation of how the trust region is defined in FuRBO.


4.1 SCBO algorithm


The SCBO framework extends the TuRBO algorithm [Eriksson et al., 2019] to address problems
with black-box constraints, by preserving most of the algorithm structure. It begins by evaluating
an initial design and fitting Gaussian Process (GP) models to the objective _ğ‘“_ ( _ğ‘¥_ ) and constraints
_ğ‘_ _ğ‘˜_ ( _ğ‘¥_ ) for _ğ‘˜_ = 1 _, . . ., ğ¾_ . A trust region (TR) is initialized around the best feasible point; if none is
found, it is centered at the point with the smallest constraint violation.
The algorithm then iteratively proceeds until the evaluation budget is exhausted. In each
iteration, a batch of _ğ‘_ candidate points is identified within the current trust region using a Thompson
Sampling (TS) [Thompson, 1933] AF: to return each of the _ğ‘_ points, after sampling a large set of
_ğ‘Ÿ_ candidate solutions within the TR, a realization {( _ğ‘“_ [Ë†] ( _ğ‘¥_ _ğ‘–_ ) _,_ Ë† _ğ‘_ 1 ( _ğ‘¥_ _ğ‘–_ ) _, ...,_ Ë† _ğ‘_ _ğ¾_ ( _ğ‘¥_ _ğ‘–_ ))| 1 â‰¤ _ğ‘–_ â‰¤ _ğ‘Ÿ_ } from the
posterior of both objective and constraints is sampled, and the candidate with maximum utility
among those that are predicted to be feasible is added to the batch.
Once the batch of _ğ‘_ points is selected, the algorithm evaluates both the objective and constraint
functions at these locations. The TR is then updated: its center is moved to the best feasible point
found so far, some success/failure counters ( _ğ‘›_ _ğ‘ _, _ğ‘›_ _ğ‘“_ ) are updated, and the TR size _ğ¿_ (same for all
dimensions) is adjusted if either _ğ‘›_ _ğ‘ _ or _ğ‘›_ _ğ‘“_ reach some threshold for the update, _ğœ_ _ğ‘ _ and _ğœ_ _ğ‘“_, respectively.
If _ğ¿_ becomes smaller than a predefined threshold _ğ¿_ min, the whole procedure is reinitialized.
At the end of the optimization, SCBO recommends the best feasible point found, i.e., the point
with the smallest objective value among those satisfying all constraints _ğ‘_ _ğ‘˜_ ( _ğ‘¥_ ) â‰¤ 0 _,_ for _ğ‘˜_ = 1 _, . . ., ğ¾_ .
We point the reader to the original paper by Eriksson and Poloczek [2021] for more details.


4.2 FuRBO algorithm


The main novelty of FuRBO is the definition of the TR. The other optimization steps are shared
with SCBO [Eriksson and Poloczek, 2021]. Nevertheless, for the sake of completeness, we present
in this section the entire optimization flow. We provide an illustration of the update procedure for
the TR in Figure 1 and the pseudocode of the entire FuRBO framework in Algorithm 1, with the
lines that differ from SCBO highlighted in yellow for clarity.
As shown in line 1 of Algorithm 1, FuRBO begins by sampling the entire search space Î©,
following the standard initialization procedure of vanilla BO. It then evaluates the sample points


4


Figure 1: One iteration of FuRBO. The leftmost panel shows the true objective and constraint isocontours, with the global optimum in red. The next two panels show surrogate models of the
objective (top) and aggregated constraint (bottom), built from evaluated points (black dots);
the current best solution is marked in red. Inspectors (white crosses) are sampled around this
point and ranked by feasibility and objective value. The top _ğ‘ƒ_ % (orange crosses) define the
TR (red square), using both objective and constraint models. A new candidate (orange dot) is
proposed within the TR, and the model are updated after evaluation (rightmost panel).


on the true objective and constraint functions, hence generating a set _S_ = {( _ğ‘¥_ _ğ‘–_ _, ğ‘“_ ( _ğ‘¥_ _ğ‘–_ ) _,_ c ( _ğ‘¥_ _ğ‘–_ ))} _ğ‘–_ _[ğ‘]_ =1 [of]
evaluated points. Here, c ( _ğ‘¥_ _ğ‘–_ ) = [ _ğ‘_ 1 ( _ğ‘¥_ _ğ‘–_ ) _, . . .,ğ‘_ _ğ¾_ ( _ğ‘¥_ _ğ‘–_ )] is a vector with as many components as the
number of constraints defining the problem. Let _F_ = { _ğ‘¥_ _ğ‘–_ âˆˆ _S_ | _ğ‘_ _ğ‘˜_ ( _ğ‘¥_ _ğ‘–_ ) â‰¤ 0 _,_ âˆ€ _ğ‘˜_ = 1 _, . . ., ğ¾_ } be the
feasible set, i.e., the subset of feasible points in _S_ according to all the constraints. Let _F_ [Â¯] = _S_ \ _F_
be its complement. At each iteration of the optimization procedure, until the evaluation budget is
exhausted, the following steps are performed.
Rank samples. For all feasible samples _ğ‘¥_ _ğ‘–_ âˆˆ _F_, define the ranking by the true objective value _ğ‘“_ ( _ğ‘¥_ _ğ‘–_ ) (lower is better for minimization). Let the feasible samples be sorted such
that _ğ‘“_ ( _ğ‘¥_ 1 [feas] ) â‰¤ _ğ‘“_ ( _ğ‘¥_ 2 [feas] ) â‰¤Â· Â· Â· â‰¤ _ğ‘“_ ( _ğ‘¥_ [feas] | _F_ | [)] [.] For the infeasible samples, we first normalize

each constraint dimension over all infeasible points: Ëœ _ğ‘_ _ğ‘˜_ ( _ğ‘¥_ _ğ‘–_ ) = max _ğ‘_ _ğ‘˜_ | _ğ‘_ ( _ğ‘˜_ _ğ‘¥_ _ğ‘–_ ( _ğ‘¥_ ) _ğ‘–_ ) | [for] _[ ğ‘¥]_ _[ğ‘–]_ [âˆˆ] _F_ Â¯ _, ğ‘˜_ =
1 _, . . ., ğ¾_ . We adopt this definition of normalization to preserve the boundary between feasibility and infeasibility. We then define the maximum normalized constraint violation per sample

Ëœ
_ğ‘£_ ( _ğ‘¥_ _ğ‘–_ ) = max _ğ‘˜_ =1 _,...,ğ¾_ _ğ‘_ _ğ‘˜_ ( _ğ‘¥_ _ğ‘–_ ), and rank infeasible samples by ascending _ğ‘£_ ( _ğ‘¥_ _ğ‘–_ ) (smallest violation first):
_ğ‘£_ ( _ğ‘¥_ 1 [infeas] ) â‰¤ _ğ‘£_ ( _ğ‘¥_ 2 [infeas] ) â‰¤Â· Â· Â· â‰¤ _ğ‘£_ ( _ğ‘¥_ [infeas] | _F_ [Â¯] | [)] [. Finally we concatenate the ordered feasible and infeasible]

samples in _S_ ranked = ï¿½ _ğ‘¥_ 1 [feas] _, . . .,ğ‘¥_ [feas] | _F_ | _[, ğ‘¥]_ 1 [infeas] _, . . .,ğ‘¥_ [infeas] | _F_ [Â¯] | ï¿½ . The procedure described in this step is

what defines the ranking metric _ğ‘Ÿ_ in Algorithm 1.
Generate the inspectors. We select the top-ranked point as the best candidate solution _ğ‘¥_ _ğ‘ğ‘’ğ‘ ğ‘¡_ so
far (line 2). Around this point, we sample a set of inspector points _I_ = { _ğ‘¥_ 1 _, . . .,ğ‘¥_ _ğ‘_ } by first drawing
from a multivariate normal distribution _N_ ( 0 _, ğœ_ [2] _ğ¼_ _ğ·_ ), normalizing each sample to lie on the unit
hypersphere, then scaling by a random factor in [ 0 _, ğ‘…_ ] and finally translating by _ğ‘¥_ best, ensuring the
inspectors are uniformly distributed within a ball _B_ ( _ğ‘¥_ best _, ğ‘…_ ) of radius _ğ‘…_ centered at _ğ‘¥_ best (line 4).

Definition of the TR. The inspector population in _I_ is ranked as described in Step (1), but based
on the evaluated models _M_ and { _C_ _ğ‘˜_ _,_ âˆ€ _ğ‘˜_ = 1 _, . . ., ğ¾_ } of the objective and _ğ¾_ constraints. We hence
define the ranked list _R_ over _I_ as _R_ = rank ( _I_ ; _M, C_ _ğ‘–_ ) = sorted ( _I,_ by increasing _ğ‘Ÿ_ ( _ğ‘¥_ )) (line 5).
Then, we select the top _ğ‘ƒ_ % inspectors: _I_ best = { _ğ‘¥_ âˆˆ _R_ | rank( _ğ‘¥_ ) â‰¤âŒˆ _ğ‘ƒ_ - _ğ‘_ âŒ‰} (line 6) and define the


5


Algorithm 1 FuRBO algorithm


Require: Success threshold _ğœ_ _ğ‘ _, failure threshold _ğœ_ _ğ‘“_, success counter _ğ‘›_ _ğ‘ _, failure counter _ğ‘›_ _ğ‘“_, batch size
_ğ‘_, inspector percentage _ğ‘ƒ_ %, sample set _S_ = âˆ…, surrogate model of the objective _M_, surrogate
model of the constraints _C_ _ğ‘˜_, sampling radius _ğ‘…_, search space Î©, initial trust region TR = Î©,
Thompson sampling AF TS, function to optimize _ğ‘“_, constraint functions _ğ‘_ _ğ‘˜_, ranking metric _ğ‘Ÿ_
1: Evaluate initial design, update _S_ and train surrogate models ( _M, C_ _ğ‘˜_ )
2: _ğ‘¥_ best â† arg min _ğ‘¥_ âˆˆ _ğ‘‹_ _ğ‘Ÿ_ ( _ğ‘¥_ ; _ğ‘“,ğ‘_ _ğ‘˜_ ) _âŠ²_ Update best candidate solution
3: while Optimization Budget Not Exhausted do
4: _I_ â† UniformBallSamples ( _ğ‘¥_ best _, ğ‘…_ ) _âŠ²_ Sample inspectors uniformly within _B_ ( _ğ‘¥_ best _, ğ‘…_ )
5: _R_ â† rank ( _I_ ; _M, C_ _ğ‘˜_ ) _âŠ²_ Rank inspectors based on ( _M, C_ _ğ‘˜_ )
6: _I_ best â† Top _ğ‘ƒ_ % of sorted _I_ _âŠ²_ Select the best inspectors ranked according to _R_
7: TR â† define_TR ( _I_ best ) _âŠ²_ Define TR as the smallest hyperrectangle containing _I_ best
8: _ğ‘‹_ next â† _ğ‘‡ğ‘†_ (( _M, C_ _ğ‘˜_ ) _,_ TR _,ğ‘_ ) _âŠ²_ Propose next _ğ‘_ configurations to evaluate within the TR
9: _ğ‘Œ_ â† _ğ‘“_ ( _ğ‘‹_ next ) _âŠ²_ Evaluate objective function on the new points
10: _ğ¶_ _ğ‘˜_ â† _ğ‘_ _ğ‘˜_ ( _ğ‘‹_ next ) _âŠ²_ Evaluate constraint functions on the new points
11: _S_ â† _S_ âˆª{( _ğ‘‹_ next _,ğ‘Œ,ğ¶_ _ğ‘˜_ )} _âŠ²_ Update sample set
12: Fit surrogate models ( _M, C_ _ğ‘˜_ ) over Î©
13: Update _ğ‘›_ _ğ‘ _ and _ğ‘›_ _ğ‘“_
14: if _ğ‘›_ _ğ‘ _ = _ğœ_ _ğ‘ _ or _ğ‘›_ _ğ‘“_ = _ğœ_ _ğ‘“_ then _âŠ²_ Check if thresholds for radius update is reached
15: _ğ‘…_ â† adjust ( _ğ‘…_ ) _âŠ²_ Double/halve the variance of the distribution
16: end if
17: _ğ‘¥_ best â† arg min _ğ‘¥_ âˆˆ _ğ‘‹_ _ğ‘Ÿ_ ( _ğ‘¥_ ; _ğ‘“,ğ‘_ _ğ‘˜_ ) _âŠ²_ Update best candidate solution
18: end while

19: Return _ğ‘¥_ best _âŠ²_ Return best solution


TR as the smallest hyperrectangle that contains all points in _I_ best . Let _ğ‘¥_ [min] _ğ‘—_ = min _ğ‘¥_ âˆˆ _I_ best _ğ‘¥_ _ğ‘—_ and
_ğ‘¥_ [max] _ğ‘—_ = max _ğ‘¥_ âˆˆ _I_ best _ğ‘¥_ _ğ‘—_ _,_ for _ğ‘—_ = 1 _, . . .,ğ‘‘_, then TR = [ï¿½] _[ğ‘‘]_ _ğ‘—_ =1 [[] _[ğ‘¥]_ [min] _ğ‘—_ _,ğ‘¥_ [max] _ğ‘—_ ] (line 7).
Find new candidate solutions, update sample set and posterior distributions. Following the
SCBO algorithm, we use TS over the surrogate models ( _M, C_ _ğ‘˜_ ), restricted to the current TR, to
propose a batch of _ğ‘_ new points to evaluate (line 8). We then evaluate both the objective function _ğ‘“_
and the constraint functions _ğ‘_ _ğ‘˜_ at the proposed batch points _ğ‘‹_ next (lines 9-10). We update the set
of evaluated samples _S_ (line 11) and we refit the surrogate models _M_ and _C_ _ğ‘˜_ over the full search
space Î© using the updated sample set _S_ (line 12).
We use the radius _ğ‘…_ of the uniform distribution to dynamically adjust the scale of the search
around _ğ‘¥_ best . In the distribution _I_ âˆ¼ Uniform( _ğ‘¥_ best _, ğ‘…_ ), we initialize _ğ‘…_ = 1. Given that the domain Î©
is normalized to [ 0 _,_ 1 ] _[ğ·]_ in our implementation, the initial distribution of samples covers the entire
domain, regardless of the exact position of _ğ‘¥_ best . Similarly to SCBO, two counters are maintained
to track optimization progress (line 13): _ğ‘›_ _ğ‘ _, the number of successes (iterations where the best
solution improves), and _ğ‘›_ _ğ‘“_, the number of failures (iterations without improvement). At each
iteration, the radius is updated based on the following rules (lines 14-15): it is doubled if _ğ‘›_ _ğ‘ _ = _ğœ_ _ğ‘ _ it
is halved if _ğ‘›_ _ğ‘“_ = _ğœ_ _ğ‘“_, it remains unchanged otherwise. After each update, both counters are reset
( _ğ‘›_ _ğ‘ _ â† 0 _,ğ‘›_ _ğ‘“_ â† 0). The thresholds _ğœ_ _ğ‘ _ and _ğœ_ _ğ‘“_ are user-defined hyperparameters controlling the
frequency of zoom-in/zoom-out behavior. A very small radius indicates stagnation or convergence.
Optimization will be stopped or restarted when _ğ‘…_ â‰¤ _ğœ€_, with _ğœ€_ chosen by the user.


6


5 Experiments


5.1 Experimental setup


We evaluate the performance of FuRBO against the following state-of-the-art methods: Scalable
Constrained Bayesian Optimization (SCBO) by Eriksson and Poloczek [2021], constrained Expected
Improvement (cEI) introduced by Schonlau et al. [1998], Constrained Optimization by Linear Approximation (COBYLA) from Powell [1994], constrained Covariance Matrix Adaptation Evolution
Strategy (CMA-ES) by Hansen [2006], and a Random Search (for the URLs of the used implementations, see the References; our code is available on GitHub [2] ). We compare these algorithms on
the constrained black-box optimization benchmarking (BBOB-constrained) suite from the COCO
package [Hansen et al., 2021]. The results of the constrained BBOB benchmark for FuRBO and
SCBO are discussed in Sec. 5.2.1. The results comparing FuRBO to multiple baselines are discussed
in Sec. 5.2.2. In Appendix F, we extend our comparison between FuRBO and SCBO to include the
30-dimensional Keane bump synthetic benchmark, as well as several physics-inspired problems
with dimensionalities ranging from 3 to 60.
Constrained BBOB. We use the COCO/BBOB-constrained benchmark [Hansen et al., 2021],
comprising 4,860 constrained black-box functions generated by combining 9 base functions, 6 constraint sets of increasing severity, 6 dimensions, and 15 instances [DufossÃ© and Atamna, 2022]. The
functions are defined on a continuous search space and present different landscape characteristics
(separable, ill-conditioned, multi-modal functions). For our evaluation, we use the full suite to
compare FuRBO with its closest relative, SCBO. We consider 3 instances and 10 repetitions with
different random seed per function-constraint combination in dimensions 2, 10, and 40.
For comparisons against all the mentioned baselines, we select three representative functions
from the suite: Sphere (separable), Bent Cigar (ill-conditioned), and Rotated Rastrigin (multimodal) in 10 dimensions, each with medium-complex constraint structures. The same experimental
setup (initial design size 3D for the BO-based algorithms and initial sample 30D) is applied to all
algorithms.
Baselines Setup. FuRBO and SCBO are evaluated on these functions, each repeated 10 times
with different initial designs and random seeds. The initial design size is 3D, the batch size is
3D, and the total evaluation budget is 30D, where D is the problem dimension. FuRBO uses a TR
defined from the top 10% of inspectors sampled around the current best solution. The sampling
radius for the inspectors _ğ‘…_ is initialized to 1, doubled when the success counter reaches _ğœ_ _ğ‘ _ = 2, and
halved when the failure counter reaches _ğœ_ _ğ‘“_ = 3. Optimization restarts if _ğ‘…_ reaches a minimum
threshold _ğœ€_ = 5 Ã— 10 [âˆ’][8] . CMA-ES and COBYLA are initialized using the default hyperparameter
settings recommended by their respective implementations [Hansen et al., 2019, Virtanen et al.,
2020]. For random sampling, we use a uniform distribution over the search space.
Performance metrics. We evaluate performance in terms of loss (simple regret), averaging over
30 runs with one standard error, and CPU time. Any feasible solution is preferred over infeasible
ones, which are assigned the worst observed objective value for a specific problem setting across
all compared methods [HernÃ¡ndez-Lobato et al., 2017]. CMA-ES and COBYLA are initialized from
the best point from the initial sample set generated for the BO methods.
Hardware and Runtime. All experiments are conducted on an Intel i9-12900K 3.20GHz CPU. To
provide an example of FuRBO runtime, the compute time for the constrained BBOB 10D functions
spanned from 5 _._ 2 sec to 250 sec on CPU, depending on the complexity of the function landscape
and the severity of the constraint. This gave a total of 33 h on CPU.


5.2 Results


5.2.1 Constrained BBOB in 10D. Figure 2 presents the loss (simple regret) convergence curves for
FuRBO and SCBO across the full constrained BBOB suite in 10 dimensions. Both algorithms are


2 [https://github.com/paoloascia/FuRBO](https://github.com/paoloascia/FuRBO)


7


Figure 2: Loss convergence curve on the full constrained BBOB suite at 10D. Results are averaged
across 3 instances with 10 repetitions each. The plot shows the mean loss with shaded areas
indicating one standard error. FuRBO consistently outperforms SCBO on more severely
constrained problems and performs comparably on easier ones.


run with a batch size _ğ‘_ = 3 _ğ·_, and total evaluation budget of 30 _ğ·_ to mimic real-world scenarios
where function evaluations rely on very expensive procedures that can be run on parallel nodes (in
Appendix E.4 we provide an ablation study on the batch size _ğ‘_ ).
Overall, FuRBO consistently outperforms SCBO on problems with a higher number of constraints and active constraints (rightmost columns), indicating its superior performance in severely
constrained scenarios. Notably, for configurations with 17 or more constraints, FuRBO achieves
faster convergence and lower final regret. For simpler problems (leftmost columns with 1â€“3 constraints), FuRBO performs comparably to SCBO, and in some cases the two methods are nearly
indistinguishable in terms of convergence speed and final performance. The exact final performances of FuRBO and SCBO are reported in Table 2 in Appendix A, where we also assess statistical
significance using the Wilcoxon rank-sum test. The analysis confirms that FuRBO achieves signifi

8


Figure 3: Convergence comparison of FuRBO against SCBO, CEI, COBYLA, CMA-ES, and random
sampling on _ğ‘“_ sphere, _ğ‘“_ bent_cigar, and _ğ‘“_ rast_rot in 10D. Curves show the mean loss over 10 repetitions of the same instance, with shaded regions indicating one standard error.


cantly better performance on the majority of the 10D problems. Similar figures to Figure 2, but
for 2 and 40 dimensions are available in Appendix C. While FuRBO and SCBO perform similarly
in 2D, FuRBO shows clear superiority in 40D, where it succeeds in finding feasible solutions in
cases where SCBO fails within the given evaluation budget. However, in the most strongly constrained scenarios, FuRBO also struggles to identify feasible regions, suggesting that the chosen
hyperparameter settings may be not optimal for such cases. We will further investigate this.
The improvement observed in highly constrained cases highlights the effectiveness of FuRBOâ€™s
feasibility-aware TR strategy. Unlike SCBO, FuRBO defines its TR based on the area predicted to
be most promising, considering both feasibility and optimality predicted by the surrogate models
over the entire domain, rather than relying solely on the best evaluated sample. This allows the
TR to shift more freely across the domain and adapt its size dynamically: it contracts or expands
according to the predicted distribution of high-quality, feasible regions. As a result, FuRBO is better
able to zoom in on narrow feasible areas and escape local minima, offering faster convergence and
more robust performance in complex, constrained landscapes.


5.2.2 Comparison to SOTA baselines. Figure 3 shows the convergence of FuRBO compared to SCBO,
CEI, COBYLA, CMA-ES, and random sampling on three representative BBOB-constrained functions
in 10 dimensions: Sphere, Bent Cigar, and Rotated Rastrigin. In order to have a comparable setup for
all methods, we consider a batch size _ğ‘_ = 1 for the BO methods (FuRBO, SCBO, and CEI), meaning
that only one candidate solution is returned by the AF and evaluated at each iteration.
FuRBO consistently achieves the lowest final loss and fastest convergence across all cases,
closely followed by SCBO. This highlights that the new definition of the TR introduced in FuRBO
is more beneficial when multiple solutions, potentially spread within the TR, are returned at each
iteration. On the ill-conditioned _ğ‘“_ bent_cigar problem, CEI converges to low-loss regions faster than
all baselines, however, FuRBO demonstrates greater exploitation capabilities by converging to a
solution with a statistically significant lower value of the objective function. For the multimodal
_ğ‘“_ rast_rot, FuRBO again outperforms the rest, directly followed by SCBO. CMA-ES and random
sampling perform poorly across all functions, highlighting the benefit of using surrogate models in
severely constrained and expensive settings. These results are confirmed in Table 4 in Appendix A.


6 Conclusions


We introduced FuRBO, a trust-region-based BO algorithm for severely constrained black-box
problems. Building on the SCBO framework, it redefines the trust region using a feasibility-aware


9


ranking of samples drawn uniformly from a ball centered around the current best point. This
allows FuRBO to dynamically adapt the location and size of the trust region based on global
surrogate information about both the objective and constraint functions, accelerating convergence
and improving exploitation of narrow feasible regions.
Our experiments on the BBOB-constrained benchmark suite demonstrate that FuRBO consistently outperforms or matches the performance of existing state-of-the-art methods, particularly in
scenarios involving tight or complex constraints.
However, FuRBO also comes with a few limitations and directions for future work. First, the
inspector-based ranking and trust region construction introduce additional model evaluations,
making the algorithm computationally more expensive than other baselines, thus most appropriate
when function evaluations are costly and dominate the runtime. Second, FuRBO still faces challenges
in high-dimensional, heavily constrained problems, where it sometimes fails to find feasible regions.
Third, our approach is still limited to a single axis-aligned trust regionâ€”a limitation we aim to
overcome in future work by exploring more flexible and potentially multiple trust regions with
adaptive orientations based on landscape characteristics. Finally, while we have evaluated our
method on several benchmark problems inspired by physics and real-world engineering applications
(e.g., spring design, pressure vessels, route planning), we will extend our validation to more complex
scenarios that originally motivated this workâ€”specifically, structural systems subject to crash
constraints, modeled using the solution space approach [Zimmermann and De Weck, 2021].


Acknowledgements. The project leading to this application has received funding from the European
Unionâ€™s Horizon 2020 research and innovation program under the Marie SkÅ‚odowska-Curie grant
agreement No 955393. The authors gratefully acknowledge the computational and data resources
provided by the Leibniz Supercomputing Centre ( www.lrz.de ).


References


S. Amini, I. Vannieuwenhuyse, and A. Morales-HernÃ¡ndez. Constrained Bayesian Optimization: A
Review. _IEEE Access_, 13:1581â€“1593, 2025. ISSN 2169-3536. doi: 10.1109/ACCESS.2024.3522876.


S. Ariafar, J. Coll-Font, D. Brooks, and J. Dy. ADMMBO: Bayesian Optimization with Unknown
Constraints using ADMM. _Journal of Machine Learning Research_, 20(123):1â€“26, 2019. ISSN

1533-7928.


M. Balandat, B. Karrer, D. R. Jiang, S. Daulton, B. Letham, A. G. Wilson, and E. Bakshy. BoTorch: A
Framework for Efficient Monte-Carlo Bayesian Optimization. In _Advances in Neural Information_
_Processing Systems 33_, 2020. URL [http://arxiv.org/abs/1910.06403](http://arxiv.org/abs/1910.06403) .


H. Cai, L. Zhu, and S. Han. ProxylessNAS: Direct Neural Architecture Search on Target Task and
Hardware, Feb. 2019.


X. Du, J. Liang, J. Lei, J. Xu, and P. Xie. A radial-basis function mesh morphing and Bayesian
Optimization framework for vehicle crashworthiness design. _Structural and Multidisciplinary_
_Optimization_, 66(3):64, Mar. 2023. ISSN 1615-1488. doi: 10.1007/s00158-023-03496-x.


P. DufossÃ© and A. Atamna. Benchmarking several strategies to update the penalty parameters in
AL-CMA-ES on the BBOB-constrained testbed. In _Proceedings of the Genetic and Evolutionary_
_Computation Conference Companion_, pages 1691â€“1699, 2022.


P. DufossÃ©, N. Hansen, D. Brockhoff, P. R. Sampaio, A. Atamna, and A. Auger. The BBOB-Constrained
COCO Test Suite. 2022.


D. Eriksson and M. Poloczek. Scalable constrained Bayesian optimization. In _International conference_
_on artificial intelligence and statistics_, pages 730â€“738. PMLR, 2021. doi: 10.48550/arXiv.2002.08526.


10


D. Eriksson, M. Pearce, J. Gardner, R. D. Turner, and M. Poloczek. Scalable global optimization via
local bayesian optimization. _Advances in neural information processing systems_, 32, 2019. doi: 10.
48550/arXiv.1910.01739. URL [https://github.com/pytorch/botorch/blob/main/tutorials/](https://github.com/pytorch/botorch/blob/main/tutorials/scalable_constrained_bo/scalable_constrained_bo.ipynb)
[scalable_constrained_bo/scalable_constrained_bo.ipynb](https://github.com/pytorch/botorch/blob/main/tutorials/scalable_constrained_bo/scalable_constrained_bo.ipynb) .


M. Feurer, K. Eggensperger, S. Falkner, M. Lindauer, and F. Hutter. Auto-Sklearn 2.0: Hands-free
AutoML via Meta-Learning, Oct. 2022.


A. I. J. Forrester, A. SÃ³bester, and A. J. Keane. _Engineering Design via Surrogate Modelling - A_
_Practical Guide_ . John Wiley & Sons Ltd., 2008. ISBN 978-0-470-06068-1.


J. Gardner, M. Kusner, Zhixiang, K. Weinberger, and J. Cunningham. Bayesian Optimization with
Inequality Constraints. In _Proceedings of the 31st International Conference on Machine Learning_,
pages 937â€“945. PMLR, June 2014.


R. Garnett. _Bayesian Optimization_ . Cambridge University Press, 2023.


N. Hansen. The CMA evolution strategy: a comparing review. _Towards a new_
_evolutionary computation:_ _Advances in the estimation of distribution algorithms_, pages
75â€“102, 2006. URL [https://github.com/CMA-ES/pycma/blob/development/notebooks/](https://github.com/CMA-ES/pycma/blob/development/notebooks/notebook-usecases-constraints.ipynb)
[notebook-usecases-constraints.ipynb](https://github.com/CMA-ES/pycma/blob/development/notebooks/notebook-usecases-constraints.ipynb) .


N. Hansen, Y. Akimoto, and P. Baudis. CMA-ES/pycma on Github. Zenodo, Feb. 2019.


N. Hansen, A. Auger, R. Ros, O. Mersmann, T. TuÅ¡ar, and D. B. and. COCO: a platform for comparing
continuous optimizers in a black-box setting. _Optimization Methods and Software_, 36(1):114â€“144,
2021. doi: 10.1080/10556788.2020.1808977.


J. M. HernÃ¡ndez-Lobato, M. A. Gelbart, R. P. Adams, M. W. Hoffman, and Z. Ghahramani. A General
Framework for Constrained Bayesian Optimization using Information-based Search, Sept. 2016.


J. M. HernÃ¡ndez-Lobato, J. Requeima, E. O. Pyzer-Knapp, and A. Aspuru-Guzik. Parallel and
Distributed Thompson Sampling for Large-scale Accelerated Exploration of Chemical Space,
June 2017.


F. Hutter, L. Kotthoff, and J. Vanschoren. _Automated Machine Learning: Methods, Systems, Challenges_ .
Springer Nature, 2019.


H. Jin, F. Chollet, Q. Song, and X. Hu. Autokeras: An automl library for deep learning. _Journal of_
_Machine Learning Research_, 24(6):1â€“6, 2023. URL [http://jmlr.org/papers/v24/20-1355.html](http://jmlr.org/papers/v24/20-1355.html) .


A. Keane. Experiences with optimizers in structural design. In _Proceedings of the conference on_
_adaptive computing in engineering design and control_, volume 94, pages 14â€“27, 1994.


A. C. Lemonge, H. J. Barbosa, C. C. Borges, and F. B. Silva. Constrained optimization problems
in mechanical engineering design using a real-coded steady-state genetic algorithm. _MecÃ¡nica_
_Computacional_, 29(95):9287â€“9303, 2010.


V. Picheny, R. B. Gramacy, S. M. Wild, and S. L. Digabel. Bayesian optimization under mixed
constraints with a slack-variable augmented Lagrangian, May 2016.


M. J. Powell. _A direct search optimization method that models the objective and constraint functions_
_by linear interpolation_ . Springer, 1994. URL [https://docs.scipy.org/doc/scipy/reference/](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize)
[generated/scipy.optimize.minimize.html#scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize) .


11


W. B. Powell. A unified framework for stochastic optimization. _European Journal of Operational_
_Research_, 275(3):795â€“821, June 2019. ISSN 03772217. doi: 10.1016/j.ejor.2018.07.014.


E. Raponi, M. Bujny, M. Olhofer, N. Aulig, S. Boria, and F. Duddeck. Kriging-assisted topology
optimization of crash structures. _Computer Methods in Applied Mechanics and Engineering_, 348:
730â€“752, May 2019. ISSN 0045-7825. doi: 10.1016/j.cma.2019.02.002.


M. Schonlau, W. J. Welch, and D. R. Jones. Global versus local search in constrained optimization
of computer models. In _New Developments and Applications in Experimental Design_, volume 34,
pages 11â€“26. Institute of Mathematical Statistics, 1998. doi: 10.1214/lnms/1215456182.


W. R. Thompson. On the Likelihood that One Unknown Probability Exceeds Another in View
of the Evidence of Two Samples. _Biometrika_, 25(3/4):285â€“294, 1933. ISSN 0006-3444. doi:
10.2307/2332286.


J. Ungredda and J. Branke. Bayesian Optimisation for Constrained Problems. _ACM Trans. Model._
_Comput. Simul._, 34(2):9:1â€“9:26, Apr. 2024. ISSN 1049-3301. doi: 10.1145/3641544.


P. Virtanen, R. Gommers, T. E. Oliphant, M. Haberland, T. Reddy, D. Cournapeau, E. Burovski,
P. Peterson, W. Weckesser, J. Bright, S. J. van der Walt, M. Brett, J. Wilson, K. J. Millman,
N. Mayorov, A. R. J. Nelson, E. Jones, R. Kern, E. Larson, C. J. Carey, Ä°. Polat, Y. Feng, E. W. Moore,
J. VanderPlas, D. Laxalde, J. Perktold, R. Cimrman, I. Henriksen, E. A. Quintero, C. R. Harris,
A. M. Archibald, A. H. Ribeiro, F. Pedregosa, P. van Mulbregt, and SciPy 1.0 Contributors. SciPy
1.0: Fundamental Algorithms for Scientific Computing in Python. _Nature Methods_, 17:261â€“272,
2020. doi: 10.1038/s41592-019-0686-2.


Z. Wang, C. Gehring, P. Kohli, and S. Jegelka. Batched large-scale bayesian optimization in highdimensional spaces. In _International Conference on Artificial Intelligence and Statistics_, pages
745â€“754. PMLR, 2018. doi: 10.48550/arXiv.1706.01445.


M. Zimmermann and O. De Weck. Formulating Engineering Systems Requirements. In
A. Maier, J. Oehmen, and P. E. Vermaas, editors, _Handbook of Engineering Systems Design_,
pages 1â€“52. Springer International Publishing, Cham, 2021. ISBN 978-3-030-46054-9. doi:
10.1007/978-3-030-46054-9_33-1.


12


A Statistical evaluation


Here, we show the exact loss values reached by the algorithms at the end of the evaluation budget.
Table 1 presents the mean and standard error of the final objective values achieved by FuRBO
and SCBO across constrained BBOB problems in 2D. Table 2 and Table 3 show similar results for
dimensions 10 and 40, respectively. The results span increasing levels of constraint severityâ€”ranging
from 1 to 9 + âŒŠ 9 _ğ·_ / 2 âŒ‹ constraints with varying numbers of active constraints and diverse problem
landscapes (e.g., separable, ill-conditioned, multimodal). The best performance per setting is
highlighted in bold, and statistical significance (via the Wilcoxon rank-sum test) is indicated in
gray shading.


Table 1: Mean and standard error of the final performance across constrained BBOB problems in
2D. Best result is highlighted in bold. Statistical significance is assessed using the Wilcoxon
rank-sum test. Results in gray indicate when one algorithm statistically outperforms the
other.

|Col1|Constraints: 1 (Active: 1)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 3 (Active: 2)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 9 (Active: 6)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|
|---|---|---|---|
|_ğ‘“ğ‘ ğ‘â„ğ‘’ğ‘Ÿğ‘’_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–ğ‘ğ‘ ğ‘œğ‘–ğ‘‘_<br>_ğ‘“ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–_ğ‘Ÿğ‘œğ‘¡_<br>_ğ‘“ğ‘‘ğ‘–ğ‘ ğ‘ğ‘¢ğ‘ _<br>_ğ‘“ğ‘ğ‘’ğ‘›ğ‘¡_ğ‘ğ‘–ğ‘”ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘‘ğ‘–ğ‘“ğ‘“_ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡_ğ‘Ÿğ‘œğ‘¡_|0.210<br>0.040<br>0.527<br>0.079<br>0.210<br>0.038<br>0.249<br>0.054<br>0.018<br>0.003<br>0.040<br>0.006<br>1.213<br>0.242<br>1.723<br>0.339<br>0.645<br>0.169<br>0.550<br>0.086<br>1.270<br>0.555<br>1.196<br>0.226<br>2.828<br>1.185<br>3.306<br>1.054<br>93.082<br>16.884<br>93.329<br>11.818<br>73.645<br>9.311<br>82.339<br>9.907|2.218<br>0.231<br>4.000<br>0.561<br>8.843<br>1.067<br>16.295<br>2.378<br>1.615<br>0.255<br>2.711<br>0.397<br>11.792<br>2.008<br>18.158<br>3.125<br>6.643<br>0.688<br>13.904<br>0.971<br>1.052<br>0.212<br>1.844<br>0.329<br>10.584<br>3.024<br>7.576<br>1.116<br>57.056<br>10.020<br>71.572<br>12.851<br>46.497<br>10.778<br>73.251<br>11.686|4.181<br>0.721<br>6.794<br>0.987<br>19.783<br>2.363<br>49.156<br>7.773<br>2.748<br>0.261<br>4.518<br>0.413<br>16.756<br>1.427<br>50.838<br>4.230<br>20.132<br>4.756<br>46.491<br>8.410<br>55.458<br>11.197<br>123.389<br>14.978<br>14.498<br>2.651<br>16.235<br>2.274<br>76.061<br>17.027<br>88.406<br>12.570<br>56.962<br>11.597<br>54.464<br>5.800|
||Constraints: 9 + âŒŠ3_ğ·_/4âŒ‹(Active: 6 + âŒŠ_ğ·_/2âŒ‹)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + âŒŠ3_ğ·_/2âŒ‹(Active: 6 + D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + âŒŠ9_ğ·_/2âŒ‹(Active: 6 + 3D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|
|_ğ‘“ğ‘ ğ‘â„ğ‘’ğ‘Ÿğ‘’_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–ğ‘ğ‘ ğ‘œğ‘–ğ‘‘_<br>_ğ‘“ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–_ğ‘Ÿğ‘œğ‘¡_<br>_ğ‘“ğ‘‘ğ‘–ğ‘ ğ‘ğ‘¢ğ‘ _<br>_ğ‘“ğ‘ğ‘’ğ‘›ğ‘¡_ğ‘ğ‘–ğ‘”ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘‘ğ‘–ğ‘“ğ‘“_ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡_ğ‘Ÿğ‘œğ‘¡_|5.744<br>1.631<br>14.549<br>2.023<br>12.433<br>1.263<br>22.620<br>2.009<br>3.328<br>0.307<br>8.648<br>0.772<br>33.862<br>4.473<br>63.640<br>7.423<br>182.689<br>53.678<br>346.352<br>111.304<br>60.131<br>5.471<br>94.093<br>16.005<br>28.864<br>4.662<br>20.930<br>2.344<br>120.532<br>16.204<br>102.261<br>14.164<br>111.154<br>12.988<br>92.853<br>11.593|6.572<br>1.152<br>14.143<br>2.994<br>24.394<br>2.351<br>42.980<br>3.945<br>5.537<br>0.470<br>8.703<br>0.829<br>23.085<br>3.515<br>46.577<br>8.061<br>24.937<br>1.916<br>83.970<br>10.258<br>89.175<br>18.078<br>104.077<br>10.872<br>12.032<br>1.548<br>23.973<br>3.615<br>46.561<br>7.852<br>65.294<br>6.302<br>82.750<br>16.000<br>136.416<br>12.411|6.274<br>0.804<br>7.488<br>0.928<br>39.976<br>7.470<br>67.786<br>9.901<br>5.183<br>0.622<br>17.188<br>1.581<br>19.182<br>2.509<br>49.176<br>6.168<br>20.889<br>3.112<br>56.955<br>7.429<br>94.550<br>28.501<br>427.606<br>341.950<br>16.172<br>4.186<br>20.328<br>2.068<br>113.930<br>16.120<br>194.695<br>12.615<br>52.617<br>10.019<br>81.268<br>8.328|



We observe that, nearly on all problems and across all levels of constraint severity, FuRBO
outperforms or matches SCBO, often by a statistically significant margin. Notably:


  The superiority of FuRBO becomes evident as the dimensionality of the problem and the severity
of the constraint increases.


  In dimension 2, despite the final loss values achieved by SCBO are sometimes better under mild
constraints, the performance is nevere statistically better than the one of FuRBO.


  In dimension 2 and 10, under the most stringent settings FuRBO demonstrates robust better
performance, significantly outperforming SCBO, where SCBO also exhibits a larger variance.


  In dimension 40, both FuRBO and SCBO fail to converge effectively for highly severe constraint
settings (9 + âŒŠ 3 _ğ·_ / 2 âŒ‹ and 9 + âŒŠ 9 _ğ·_ / 2 âŒ‹ constraints). However, FuRBO manages to find feasible
solutions for 9 + âŒŠ3 _ğ·_ /4âŒ‹ constraints on nearly all benchmarks, while SCBO systematically fails.


These findings highlight FuRBOâ€™s superior adaptability in severely constrained scenarios, thanks
to its feasibility-aware TR strategy. Also, the consistent performance across diverse problem types
and constraint severities suggest that the algorithm generalizes well, effectively balancing global
exploration with local refinement.


13


Table 2: Mean and standard error of the final performance across constrained BBOB problems in
10D. Best result is highlighted in bold. Statistical significance is assessed using the Wilcoxon
rank-sum test. Results in gray indicate when one algorithm statistically outperforms the other.
If a feasible solution is not returned, the results are marked as not available (n/a).

|Col1|Constraints: 1 (Active: 1)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 3 (Active: 2)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 9 (Active: 6)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|
|---|---|---|---|
|_ğ‘“ğ‘ ğ‘â„ğ‘’ğ‘Ÿğ‘’_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–ğ‘ğ‘ ğ‘œğ‘–ğ‘‘_<br>_ğ‘“ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–_ğ‘Ÿğ‘œğ‘¡_<br>_ğ‘“ğ‘‘ğ‘–ğ‘ ğ‘ğ‘¢ğ‘ _<br>_ğ‘“ğ‘ğ‘’ğ‘›ğ‘¡_ğ‘ğ‘–ğ‘”ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘‘ğ‘–ğ‘“ğ‘“_ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡_ğ‘Ÿğ‘œğ‘¡_|21.964<br>1.388<br>138.804<br>10.956<br>5.831<br>0.481<br>19.519<br>1.359<br>0.122<br>0.022<br>0.087<br>0.017<br>13.956<br>1.076<br>22.265<br>1.618<br>0.523<br>0.098<br>0.638<br>0.087<br>156.625<br>11.214<br>1.011e+03<br>96.125<br>113.271<br>10.430<br>456.299<br>30.881<br>769.783<br>18.940<br>913.273<br>19.361<br>674.252<br>20.913<br>858.090<br>15.381|58.790<br>5.696<br>219.152<br>15.692<br>138.762<br>20.431<br>231.414<br>24.137<br>12.195<br>1.571<br>21.249<br>1.870<br>105.630<br>13.958<br>139.813<br>14.482<br>18.162<br>2.627<br>31.136<br>3.379<br>385.712<br>53.371<br>1.810e+03<br>142.890<br>121.649<br>9.565<br>470.231<br>29.952<br>887.369<br>32.102<br>1.209e+03<br>62.581<br>767.100<br>23.015<br>1.056e+03<br>33.444|198.514<br>18.634<br>585.673<br>39.943<br>512.837<br>34.019<br>1.083e+03<br>61.844<br>212.422<br>16.858<br>618.493<br>86.203<br>611.267<br>71.576<br>1.583e+03<br>142.554<br>288.711<br>17.185<br>765.207<br>71.978<br>1.453e+03<br>140.637<br>5.233e+03<br>480.111<br>196.147<br>13.799<br>693.546<br>72.736<br>1.128e+03<br>40.189<br>2.517e+03<br>379.334<br>958.011<br>34.706<br>2.033e+03<br>181.885|
||Constraints: 9 + âŒŠ3_ğ·_/4âŒ‹(Active: 6 + âŒŠ_ğ·_/2âŒ‹)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + âŒŠ3_ğ·_/2âŒ‹(Active: 6 + D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + âŒŠ9_ğ·_/2âŒ‹(Active: 6 + 3D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|
|_ğ‘“ğ‘ ğ‘â„ğ‘’ğ‘Ÿğ‘’_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–ğ‘ğ‘ ğ‘œğ‘–ğ‘‘_<br>_ğ‘“ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–_ğ‘Ÿğ‘œğ‘¡_<br>_ğ‘“ğ‘‘ğ‘–ğ‘ ğ‘ğ‘¢ğ‘ _<br>_ğ‘“ğ‘ğ‘’ğ‘›ğ‘¡_ğ‘ğ‘–ğ‘”ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘‘ğ‘–ğ‘“ğ‘“_ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡_ğ‘Ÿğ‘œğ‘¡_|543.153<br>116.179<br>3.729e+03<br>114.165<br>1.534e+03<br>160.652<br>4.952e+03<br>630.699<br>258.470<br>29.091<br>809.796<br>103.165<br>1.056e+03<br>96.825<br>4.644e+03<br>601.538<br>424.307<br>31.046<br>5.358e+03<br>907.447<br>1.955e+03<br>164.335<br>8.968e+03<br>1.072e+03<br>282.976<br>22.572<br>885.045<br>86.379<br>1.797e+03<br>258.449<br>3.554e+03<br>321.989<br>1.086e+03<br>70.368<br>2.582e+03<br>210.997|369.019<br>15.963<br>1.805e+03<br>160.573<br>2.584e+03<br>395.692<br>3.967e+03<br>400.501<br>196.186<br>9.024<br>909.622<br>108.059<br>680.446<br>45.009<br>6.133e+03<br>566.422<br>3.337e+03<br>567.569<br>7.617e+03<br>239.395<br>2.753e+03<br>204.529<br>1.023e+04<br>618.958<br>310.649<br>15.017<br>1.783e+04<br>6.714e+03<br>1.171e+03<br>25.633<br>2.911e+03<br>295.358<br>1.245e+03<br>64.740<br>4.105e+03<br>252.273|2.976e+03<br>643.900<br>9.106e+03<br>215.199<br>3.446e+03<br>250.820<br>n/a<br>n/a<br>535.789<br>44.294<br>811.818<br>10.493<br>3.111e+03<br>587.884<br>1.347e+04<br>403.178<br>3.164e+03<br>243.911<br>n/a<br>n/a<br>1.092e+04<br>1.831e+03<br>2.640e+04<br>758.083<br>875.926<br>164.867<br>2.308e+03<br>59.269<br>1.650e+03<br>36.467<br>4.308e+03<br>164.089<br>1.840e+03<br>136.922<br>n/a<br>n/a|



Table 3: Mean and standard error of the final performance across constrained BBOB problems in
40D. Best result is highlighted in bold. Statistical significance is assessed using the Wilcoxon
rank-sum test. Results in gray indicate when one algorithm statistically outperforms the other.
If a feasible solution is not returned, the results are marked as not available (n/a).

|Col1|Constraints: 1 (Active: 1)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 3 (Active: 2)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|Constraints: 9 (Active: 6)<br>FuRBO SCBO<br>Mean S.E. Mean S.E.|
|---|---|---|---|
|_ğ‘“ğ‘ ğ‘â„ğ‘’ğ‘Ÿğ‘’_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–ğ‘ğ‘ ğ‘œğ‘–ğ‘‘_<br>_ğ‘“ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–_ğ‘Ÿğ‘œğ‘¡_<br>_ğ‘“ğ‘‘ğ‘–ğ‘ ğ‘ğ‘¢ğ‘ _<br>_ğ‘“ğ‘ğ‘’ğ‘›ğ‘¡_ğ‘ğ‘–ğ‘”ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘‘ğ‘–ğ‘“ğ‘“_ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡_ğ‘Ÿğ‘œğ‘¡_|191.905<br>9.743<br>1.235e+03<br>74.848<br>72.660<br>4.706<br>199.098<br>15.666<br>0.120<br>0.026<br>0.063<br>0.019<br>83.392<br>7.957<br>249.737<br>23.016<br>0.181<br>0.046<br>0.284<br>0.043<br>1.770e+03<br>112.493<br>1.447e+04<br>720.873<br>1.510e+03<br>80.505<br>2.793e+03<br>133.038<br>3.804e+03<br>146.398<br>4.959e+03<br>101.575<br>4.318e+03<br>99.437<br>5.109e+03<br>161.808|891.213<br>56.888<br>2.195e+03<br>120.958<br>1.471e+03<br>251.414<br>1.594e+03<br>116.509<br>47.281<br>9.592<br>133.901<br>28.004<br>1.064e+03<br>67.244<br>1.602e+03<br>113.814<br>43.144<br>6.356<br>56.058<br>9.523<br>1.704e+04<br>1.369e+03<br>3.033e+04<br>1.906e+03<br>2.417e+03<br>200.116<br>6.807e+03<br>500.896<br>4.743e+03<br>138.682<br>6.602e+03<br>167.442<br>5.227e+03<br>174.590<br>6.311e+03<br>152.997|2.846e+03<br>187.348<br>4.947e+03<br>284.815<br>1.332e+03<br>135.523<br>4.121e+03<br>429.439<br>333.052<br>23.110<br>857.128<br>100.898<br>5.368e+03<br>424.582<br>1.046e+04<br>1.250e+03<br>265.416<br>35.171<br>666.984<br>77.161<br>5.530e+04<br>9.294e+03<br>1.130e+05<br>1.100e+04<br>5.250e+03<br>759.436<br>2.413e+04<br>3.647e+03<br>5.936e+03<br>197.260<br>8.826e+03<br>181.602<br>8.753e+03<br>447.437<br>1.484e+04<br>814.410|
||Constraints: 9 + âŒŠ3_ğ·_/4âŒ‹(Active: 6 + âŒŠ_ğ·_/2âŒ‹)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + âŒŠ3_ğ·_/2âŒ‹(Active: 6 + D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|Constraints: 9 + âŒŠ9_ğ·_/2âŒ‹(Active: 6 + 3D)<br>FuRBO<br>SCBO<br>Mean<br>S.E.<br>Mean<br>S.E.|
|_ğ‘“ğ‘ ğ‘â„ğ‘’ğ‘Ÿğ‘’_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–ğ‘ğ‘ ğ‘œğ‘–ğ‘‘_<br>_ğ‘“ğ‘™ğ‘–ğ‘›ğ‘’ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘’ğ‘™ğ‘™ğ‘–_ğ‘Ÿğ‘œğ‘¡_<br>_ğ‘“ğ‘‘ğ‘–ğ‘ ğ‘ğ‘¢ğ‘ _<br>_ğ‘“ğ‘ğ‘’ğ‘›ğ‘¡_ğ‘ğ‘–ğ‘”ğ‘ğ‘Ÿ_<br>_ğ‘“ğ‘‘ğ‘–ğ‘“ğ‘“_ğ‘ğ‘œğ‘¤ğ‘’ğ‘Ÿ_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡ğ‘Ÿğ‘–ğ‘”ğ‘–ğ‘›_<br>_ğ‘“ğ‘Ÿğ‘ğ‘ ğ‘¡_ğ‘Ÿğ‘œğ‘¡_|6.150e+03<br>539.698<br>n/a<br>n/a<br>1.307e+04<br>1.064e+03<br>n/a<br>n/a<br>2.413e+03<br>263.602<br>n/a<br>n/a<br>1.837e+04<br>1.347e+03<br>n/a<br>n/a<br>1.381e+04<br>524.696<br>n/a<br>n/a<br>7.508e+04<br>5.295e+03<br>n/a<br>n/a<br>8.737e+03<br>2.276e+03<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>1.191e+04<br>821.514<br>n/a<br>n/a|5.735e+03<br>238.843<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a|n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a<br>n/a|



Table 4 reports the final performance of FuRBO and four other SOTA baselines: SCBO, CEI,
COBYLA, and CMA-ES, on three representative benchmark functions in 10D: _ğ‘“_ sphere, _ğ‘“_ bent_cigar, and
_ğ‘“_ rast_rot . We omit random sampling because it never found a feasible solution in our comparison.
These chosen functions represent diverse landscape characteristics, from simple convex and separable functions, to ill-conditioned and multimodal. We highlight the best-performing algorithm
in bold, with statistical significance (via a pairwise Wilcoxon rank-sum test) indicated by gray
shading. This means that we highlight in gray a method only if it statistically outperformed all the
others in a problem setting.


14


On _ğ‘“_ sphere, a smooth, convex, and separable problem, FuRBO clearly outperforms SCBO and
dramatically outpaces CEI, COBYLA, and CMA-ES. On the ill-conditioned _ğ‘“_ bent_cigar function,
FuRBO again leads with a significantly lower final objective value than all baselines, highlighting
its capacity to exploit narrow feasible valleys. For the multimodal _ğ‘“_ rast_rot, FuRBO maintains its
lead, demonstrating superior exploration of complex feasible regions and local minima. However,
the final loss value significantly increases compared to the two simpler functions. These results
further highlight FuRBOâ€™s strength, not only over its direct competitor SCBO, but also against
well-established baselines fro constrained optimization from the literature.


Table 4: Mean and standard error of the final performance on the class representative functions in 10D.
The best result for each function is highlighted in bold. Statistical significance is assessed
using the Wilcoxon rank-sum test. Results in gray indicate when one algorithm statistically
outperforms all the others.


_ğ‘“_ _ğ‘ ğ‘â„ğ‘’ğ‘Ÿğ‘’_ _ğ‘“_ _ğ‘ğ‘’ğ‘›ğ‘¡_ _ _ğ‘ğ‘–ğ‘”ğ‘ğ‘Ÿ_ _ğ‘“_ _ğ‘Ÿğ‘ğ‘ ğ‘¡_ _ _ğ‘Ÿğ‘œğ‘¡_
Mean S.E. Mean S.E. Mean S.E.

FuRBO 7.286 0.580 68.944 5.132 760.095 38.507

SCBO 14.237 0.696 107.133 5.568 925.548 47.247

CEI 829.146 87.943 798.386 96.740 2093.581 270.394

COBYLA 126.358 86.315 5787.570 1536.906 1156.212 126.745

CMA-ES 1211.966 116.424 8874.131 1200.243 3331.974 350.704


B Scalability of FuRBO


Figure 4 illustrates the mean loss convergence of FuRBO and SCBO on three constrained BBOB
functions: _ğ‘“_ sphere, _ğ‘“_ bent_cigar, and _ğ‘“_ rast_rot, evaluated at a mid-severe constraint level (9 + âŒŠ 3 _ğ·_ / 4 âŒ‹
constraints, out of which 6 + âŒŠ _ğ·_ / 2 âŒ‹ are active) in dimensions 2, 10, and 40. The results are averaged
across 3 problem instances and 10 repetitions each, with shaded areas representing one standard

error.

FuRBO demonstrates clear scalability advantages as dimensionality increases. In 2D, FuRBO and
SCBO perform similarly, with FuRBO showing slightly faster convergence in the early evaluations.
In 10D and 40D, FuRBO consistently outperforms SCBO, achieving lower final losses and faster

convergence.
We note that, particularly in higher dimensions, the convergence curves exhibit a step-wise
pattern. This behavior is due to the chosen batch size of _ğ‘_ = 3 _ğ·_ and the way solutions within each
batch are automatically ordered by objective value (from worst to best) by the BoTorch package,
from which we took the SCBO implementation and on which we also base our own. As a result,
early points in each batch tend to be of lower quality and are often outperformed by previously
found solutions, leading to flat segments in the convergence curves. Instead, the last solutions
returned in the batch, which are of higher quality, typically bring an improvement.


15


Figure 4: Loss convergence curve on _ğ‘“_ sphere, _ğ‘“_ bent_cigar, and _ğ‘“_ rast_rot constrained BBOB functions at 10D
and mid-severe constraint level, for varying dimensionality of the problems. Results are
averaged across 3 instances with 10 repetitions each. The plot shows the mean loss with
shaded areas indicating one standard error. FuRBO clearly outperforms SCBO in 10D and
40D, while it shows comparable performance to SCBO in 2D, with slightly faster convergence.



16


C Full results on Constrained BBOB


In this section, we show the comparison between FuRBO and SCBO on the full constrained BBOB
test suite for dimension 10.
In 2D (Figure 5), both FuRBO and SCBO perform similarly across most functions and constraint
levels.
In 40D (Figure 6), the difference becomes more pronounced. FuRBO outperforms SCBO under
moderate constraint counts. This is particularly evident on the 9 constraints (6 active) column.
As the constraint severity increases, SCBO stops finding any feasible solutions, as indicated by
the constant convergence trend, while FuRBO continues to make progress. In more extreme cases
(9 + âŒŠ 3 _ğ·_ / 2 âŒ‹ or 9 + âŒŠ 9 _ğ·_ / 2 âŒ‹ constraints), both methods struggle to find feasible improvements within
the available evaluation budget.


Figure 5: Loss convergence curve on the full constrained BBOB suite at 2D. Results are averaged
across 3 instances with 10 repetitions each. The plot shows the mean loss with shaded areas
indicating one standard error. FuRBO and SCBO have comparable convergence trends.


17


Figure 6: Loss convergence curve on the full constrained BBOB suite at 40D. Results are averaged
across 3 instances with 10 repetitions each. The plot shows the mean loss with shaded
areas indicating one standard error. FuRBO is on par or outperforms SCBO for mild and
medium-severe constraints, while both methods fail in finding feasible solutions for strongly
constrained scenarios.



18


D CPU time


Figure 7: Average CPU time (in seconds) of FuRBO and SCBO across 10D all the constrained BBOB
functions under increasing numbers of constraints. The two methods have comparable
runtime, which increases with constraint severity.



19


Figure 7 presents the average CPU time required by FuRBO and SCBO in 10D, as the number of
constraints and problem complexity increase. The batch size set for both algorithms is _ğ‘_ = 3 _ğ·_ .
Across all test functions, both methods show a similar scaling trend: runtime increases with
the number of constraints, as expected due to the additional computational burden of constraint
modeling and feasibility checking. FuRBOâ€™s computational cost presents only marginal increases
compared to SCBOâ€™s, as it performs additional calls to the objective and constraint approximation
models for the definition of the TR.
Figure 8 compares FuRBO and SCBO with other established baselines (CEI, COBYLA, and CMAES) on three representative functions in 10D and medium-high constraint severity (9 + âŒŠ 3 _ğ·_ / 4 âŒ‹
constraints, 6 + âŒŠ _ğ·_ / 2 âŒ‹ active). As expected, the surrogate-based methods (CEI, SCBO, and FuRBO)
are by far the most expensive. COBYLA and CMA-ES are significantly faster, but at the cost of
substantially poorer optimization performance (as shown in Figure 3 and Table 4).
Please note that the runtime tracked for FuRBO and SCBO for these settings seem in contrast
with the one shown in Figure 8, for the same dimensionality. This is motivated by the fact that here,
for comparison purposes, we are running all the methods (except CMA-ES, due to its inherently
parallel design) in serial mode.
In summary, FuRBO offers a favorable balance between performance and runtime, finding
better solutions than baselines like SCBO and CEI, while keeping computational overhead well
within practical limits.


Figure 8: Average CPU time (log scale) of FuRBO against other four baselines (SCBO, CEI, COBYLA,
and CMA-ES) on three representative 10D functions: _ğ‘“_ sphere, _ğ‘“_ bent_cigar, and _ğ‘“_ rast_rot . FuRBO
and SCBO have similar runtimes, while CEI is slightly more expensive. COBYLA and CMA-ES
are much faster but at the cost of reduced solution quality (see Table 4).


E Ablation studies


In this section, we provide ablation studies on four influential hyperparameters of FuRBO. The size
of the initial sample, the initial radius _ğ‘…_ of the ball containing the uniformly distributed population
of inspectors, the percentage of investigators used to define the trust region, and the batch size
_ğ‘_ . All the studies in this section are performed on the _ğ‘“_ bent_cigar function with 24 constraints in
dimension 10. We do not present a study on the effect of the number of investigators, as it did
not show any noticeable impact in our experiments. We also experimented with using the total
constraint violation, as done in SCBO [Eriksson et al., 2019], but observed no notable difference in


20


performance compared to our current ranking based on maximum normalized constraint violation.
The corresponding plots are available in the GitHub repository.


E.1 Initial sample size


Figure 9 presents a study on the impact of the size of the initial sample set, also referred to as
Design of Experiments (DoE), on the optimization performance of FuRBO. We compare four DoE
sizes proportional to the problem dimensionality, specifically, 1D, 3D, 5D, and 10D initial points.
The results show that larger DoE sizes (e.g., 10D) tend to delay early convergence, as more
evaluations are used upfront for model initialization before optimization begins. In contrast, smaller
DoE sizes (1Dâ€“5D) enable comparable (and faster compared to the 10D size) progress by allowing
the iterative procedure to start earlier, without noticeably compromising the accuracy of the
approximation models of the objective and constraints, and thus preserving the effectiveness of the
landscape-aware mechanism for TR definition.


Figure 9: Study on the impact of the initial sample size on FuRBO in dimension 10 on the _ğ‘“_ bent_cigar
BBOB function with 24 constraints. Initial sample sizes equal to 1D, 3D, 5D and 10D are
compared. Experiments run on _ğ‘“_ bent_cigar BBOB function with 24 constraints.


E.2 Sampling radius


Figure 10 shows the effects of changing the initial value of the sampling radius _ğ‘…_ for the population
of inspectors. We compare the performance of five different starting radii, _ğ‘…_ = { 1 _._ 0 _,_ 0 _._ 5 _,_ 0 _._ 2 _,_ 0 _._ 1 _,_ 0 _._ 05 },
on the constrained _ğ‘“_ bent_cigar function (with 24 constraints).

The results show that, when FuRBO is initialized with a radius smaller than 0 _._ 5, the algorithmâ€™s
performance deteriorates due to overlocalization of the search from the very first iterations, limiting
its ability to search for feasible solutions and explore the landscape before convergence. No
difference in performance was observed for _ğ‘…_ = 1 _._ 0 and _ğ‘…_ = 0 _._ 5 as both these choices allowed for a
full coverage of the search space.


E.3 Inspector percentage


Figure 11 investigates the effect of the percentage _ğ‘ƒ_ % of inspectors selected to define the TR in
FuRBO. Specifically, we compare the performance on the constrained _ğ‘“_ bent_cigar function (with 24
constraints) using selection rates of 1%, 5%, 10%, and 20%.


21


Figure 10: Study on the impact of the initial radius of the uniform distribution for the inspectors. The
following initial radii are compared on the _ğ‘“_ bent_cigar BBOB function with 24 constraints:
_ğ‘…_ = {1 _._ 0 _,_ 0 _._ 5 _,_ 0 _._ 2 _,_ 0 _._ 1 _,_ 0 _._ 05}.


The results show that the algorithmâ€™s performance deteriorates as this percentage increases.
However, we believe that these results highly depend on the landscape of the problem at hand. Very
small percentages (e.g., 1%) enable faster initial progress by quickly narrowing down to promising
regions, but they may limit the algorithmâ€™s ability to explore diverse feasible areas. Conversely,
larger values (e.g., 20%) lead to slower progress, as the TR is influenced by a broader sample set,
which may dilute the effect of high-quality candidates. Given this sensitivity, it would be beneficial
to perform a dedicated hyperparameter optimization for this selection percentage to adapt it to the
problem at hand.


Figure 11: Study on the impact of the percentage _ğ‘ƒ_ % of inspectors selected to define the position
and extension of the TR. The following percentages are compared: 1%, 5%, 10%, and 20%.
Experiments run on _ğ‘“_ bent_cigar BBOB function with 24 constraints.


22


(a) Loss. (b) CPU time.


Figure 12: Study on the impact of the batch size _ğ‘_ on the performance of FuRBO. The following
configurations are compared: 1 (sequential), 1D, 2D, 3D, 4D, and 5D samples per batch.
Experiments run on _ğ‘“_ bent_cigar BBOB function with 24 constraints.


E.4 Batch size


Figure 12 examines the impact of batch size _ğ‘_ on FuRBOâ€™s performance and computational cost.
We compare six batch configurations: sequential (1 sample per iteration), and parallel batches of
size 1D, 2D, 3D, 4D, and 5D.
Figure 12a shows that larger batch sizes generally lead to slower convergence as many samples
are evaluated per iteration without the model being updated. The sequential setting (batch size = 1)
achieves the fastest convergence in terms of evaluations, but as seen in Figure 12b, it incurs the
highest computational cost due to frequent model updates and definitions of the TR.
Conversely, increasing the batch size significantly reduces CPU time, with a 5D batch being
about 20 times faster than the sequential setup, while maintaining competitive final performance.
Thus, intermediate batch sizes from 2D to 4D seem to provide a favorable trade-off, offering
both efficiency and robust convergence behavior. FuRBO is therefore well-suited for optimization
problems that require parallel evaluations of the objective and constraint functions, particularly
when wall-clock time is a critical factor and parallel computing nodes are available.


F Results on other benchmarks


In this section, we present additional comparisons between FuRBO and SCBO. We include the
minimization of the 30D Keane Bump function under two constraints, as well as several physicsinspired benchmark problems spanning dimensions from 3 to 60. For all problems, we independently
ran both algorithms and report the results obtained from our own experiments.


F.1 Keane bump function (30D)


We consider the Keane function [Keane, 1994] in 30 dimensions under two constraints over the
domain [0 _,_ 10] _[ğ·]_ :


23


ï¸ƒ

ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½



min _ğ‘“_ ( _ğ‘¥_ ) = âˆ’

ï¸ƒ



ï¸ƒ

ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½



ï¿½ _ğ‘–ğ·_ =1 [cos] [4] [(] _[ğ‘¥]_ _[ğ‘–]_ [) âˆ’] [2] [ï¿½] _ğ‘–_ _[ğ·]_ =1 [cos] [2] [(] _[ğ‘¥]_ _[ğ‘–]_ [)]

ï¸ƒ _ğ·_
~~âˆšï¿½~~ _ğ‘–_ =1 _[ğ‘–ğ‘¥]_ _ğ‘–_ [2]



ï¸ƒ


(2)



ï¸ƒ


s _._ t _. ğ‘_ 1 ( _ğ‘¥_ ) = 0 _._ 75 âˆ’



ï¸ƒ


_ğ·_


_ğ‘¥_ _ğ‘–_ â‰¤ 0 _,_

ï¿½

_ğ‘–_ =1



ï¸ƒ


_ğ‘_ 2 ( _ğ‘¥_ ) =



ï¸ƒ


_ğ·_


_ğ‘¥_ _ğ‘–_ âˆ’ 7 _._ 5 _ğ‘‘_ â‰¤ 0 _._

âˆ‘ï¸

_ğ‘–_ =1



ï¸ƒ


The algorithms are evaluated with an initial DoE of 3D, a batch size of 3D, and a total budget of
30D. More specifically, FuRBO starts with an initial radius of 1 _._ 0 for the inspector population, and
defines the TR by considering the top 10% of the investigators.

The results in Figure 13 indicate that FuRBO slightly outperforms SCBO on the 30D Keane
Bump function, particularly in the later stages of the optimization. This suggests that FuRBOâ€™s trust
region mechanism can offer benefits in high-dimensional settings. However, since the problem is
only mildly constrained, the performance gap remains modest.

ï¸ƒ



Figure 13: Convergence of FuRBO and SCBO on the 30D Keane Bump function under two constraints
in the domain [ 0 _,_ 10 ] _[ğ·]_ . Results are averaged over 10 independent runs for each algorithm.
The plot shows the mean objective value, with shaded areas representing one standard

error.


F.2 Spring volume minimization (3D)


The first physics-inspired benchmark we evaluate is the minimization of the volume of a spring
under four mechanical constraints [Lemonge et al., 2010]. The spring is described by three design
parameters: the number of active coils of the spring _ğ‘_ âˆˆ[ 2 _,_ 15 ], the winding diameter _ğ·_ _ğ‘¤_ âˆˆ

[ 0 _._ 25 _,_ 1 _._ 3 ], and the wire diameter _ğ‘‘_ _ğ‘¤_ âˆˆ[ 0 _._ 05 _,_ 2 ] . We compare the performance of FuRBO and SCBO
with an initial DoE of 3D, a batch size of 3D, and a total budget of 30D.

Figure 14 shows the convergence behavior of FuRBO and SCBO on the 3D Spring design
problem. Both methods steadily reduce the volume as the number of evaluations increases. While
SCBO converges faster in the early stages and maintains a performance advantage throughout most
of the optimization, the gap between the two methods is small. These results suggest that FuRBO


24


does not offer a significant benefit over SCBO in low-dimensional, lightly constrained problems,
where the added complexity of its feasibility-driven trust region mechanism may be less impactful.


Figure 14: Convergence of FuRBO and SCBO on the 3D Spring design problem with three design
variables, under four constraints. Results are averaged over 10 independent runs for each
algorithm. The plot shows the mean objective value (volume), with shaded areas representing one standard error.


F.3 Welded beam cost minimization (4D)


The second physics-inspired problem is the minimization of the welding costs for a beam under
five mechanical constraints [Lemonge et al., 2010]. The design space is described by the length
_ğ‘™_ âˆˆ[ 0 _._ 1 _,_ 10 _._ 0 ] and the height _â„_ âˆˆ[ 0 _._ 125 _,_ 10 _._ 0 ] of the welding, and the thickness _ğ‘¡_ âˆˆ[ 0 _._ 1 _,_ 10 _._ 0 ] and
the width _ğ‘_ âˆˆ[ 0 _._ 1 _,_ 10 _._ 0 ] of the beam. Both FuRBO and SCBO are initialized with an initial DoE 3D
samples, a batch size of 3D, and a total budget of 30D.

Figure 15 shows minimal difference between SCBO and FuRBO, which, as in the previous
benchmark, can be attributed to the problemâ€™s low dimensionality and weak constraint structure.


Figure 15: Convergence of FuRBO and SCBO on the 4D welded beam cost minimization problem,
formulated with four design variables and five constraints. Results are averaged over 10
independent runs for each algorithm. The plot shows the mean objective value (cost), with
shaded areas representing one standard error.


25


F.4 Pressure vessel mass minimization (4D)


The third physics-inspired is the mass minimization of a pressure vessel [Lemonge et al., 2010].
The problem is described by four parameters ( _ğ‘‡_ _ğ‘ _, _ğ‘‡_ _â„_, _ğ‘…_, _ğ¿_ ) and constrained by four functions. In
this case, the thickness of the walls of the pressure vessel _ğ‘‡_ _ğ‘ _ and the thickness of the wall of the
head of the vessel _ğ‘‡_ _â„_ vary in the range [ 0 _._ 0625 _,_ 5 ], in constant steps of 0 _._ 0625. Instead, the inner
radius of the vessel _ğ‘…_ and the length of the cylindrical component _ğ¿_ are defined in the [ 10 _,_ 200 ]
interval and continuous. We compare the performance between FuRBO and SCBO with an initial
DoE size of 3D, a batch size of 3D, and a total budget of 30D. Because of the low dimensionality
and the weak constraints, the two algorithms show very similar performance (Figure 16).


Figure 16: Convergence of FuRBO and SCBO on the pressure vessel design problem with four design
parameters and four constraints. Results are averaged over 10 independent runs for each
algorithm. The plot shows the mean objective value (weight), with shaded areas representing
one standard error.


F.5 Speed reducer volume minimization (7D)


The speed reducer volume minimization [Lemonge et al., 2010] problem presents 7 parameters and
11 constraints. The parameters are the gear face width _ğ‘_ âˆˆ[ 2 _._ 6 _,_ 3 _._ 6 ], the teeth module _ğ‘š_ âˆˆ[ 0 _._ 7 _,_ 0 _._ 8 ],
the number of teeth on the pinion _ğ‘›_ âˆˆ[ 17 _,_ 28 ], the length of the first shaft between the supporting
bearings _ğ‘™_ 1 âˆˆ[ 7 _._ 3 _,_ 8 _._ 3 ], the length of the second shaft between the supporting bearings _ğ‘™_ 2 âˆˆ[ 7 _._ 8 _,_ 8 _._ 3 ],
the diameter of the first shaft _ğ‘‘_ 1 âˆˆ[2 _._ 9 _,_ 3 _._ 9], and the diameter of the second shaft _ğ‘‘_ 2 âˆˆ[2 _._ 9 _,_ 3 _._ 9].

Although this problem has a low dimensionality, it is highly constrained. As the results in
Figure 17 show, FuRBO outperforms SCBO by a significant margin.


F.6 Rover trajectory planning (60D)


The last benchmark on which we compare SCBO and FuRBO is the problem of planning the route
of a rover over a terrain with different types of obstacles [Wang et al., 2018]. Similarly to Eriksson
et al. [2019], we modify the original unconstrained trajectory optimization problem to include 15
hard constraints. The optimization problem is defined over a decision vector _ğ‘¥_ âˆˆ[ 0 _,_ 1 ] [60], which
encodes the trajectory _ğ›¾_ ( _ğ‘¥_ ) of a rover navigating a grid environment. The environment contains
112 yellow obstacles, which the rover may cross at a cost, and 15 red obstacles, which must be
avoided. A visualization of the problem definition is provided in Figure 18a, where the yellow
squares represent the obstacles that the rover can overcome, while the red squares represent the
obstacles to be avoided.


26


Figure 17: Convergence of FuRBO and SCBO on the speed reducer design problem with seven design
parameters and eleven constraints. Results are averaged over 10 independent runs for
each algorithm. The plot shows the mean objective value (volume), with shaded areas
representing one standard error.


The objective function _ğ‘“_ ( _ğ‘¥_ ) is defined as a reward function, which combines the trajectory cost
with penalties on initial and final positions and is given by:


_ğ‘“_ ( _ğ‘¥_ ) = _ğ‘_ ( _ğ‘¥_ ) + _ğœ†_ [ï¿½] âˆ¥ _ğ‘¥_ 0 _,_ 1 âˆ’ _ğ‘ _ âˆ¥ 1 + âˆ¥ _ğ‘¥_ 59 _,_ 60 âˆ’ _ğ‘”_ âˆ¥ 1 ï¿½ + _ğ‘,_


where _ğ‘_ ( _ğ‘¥_ ) is a trajectory cost that penalizes any collision with an object along the trajectory by
-20, _ğ‘ _ and _ğ‘”_ are the start and goal coordinates, _ğœ†_ = âˆ’ 10 is a weighting factor, and _ğ‘_ = 5 is a bias term.
We redefine the hard constraint functions _ğ‘_ _ğ‘–_ ( _ğ‘¥_ ), each associated with a red obstacle _ğ‘œ_ _ğ‘–_, as:



_ğ‘‘_ ( _ğ›¼,_ center( _ğ‘œ_ _ğ‘–_ )) if _ğ›¾_ ( _ğ‘¥_ ) âˆ© _ğ‘œ_ _ğ‘–_ â‰  âˆ… _,_

âˆ‘ï¸

_ğ›¼_ âˆˆ _ğ›¾_ ( _ğ‘¥_ )âˆ© _ğ‘œ_ _ğ‘–_

âˆ’ min otherwise _,_
_ğ›¼_ âˆˆ _ğ›¾_ ( _ğ‘¥_ ) _[ğ‘‘]_ [(] _[ğ›¼,]_ [ center][(] _[ğ‘œ]_ _[ğ‘–]_ [))]



_ğ‘_ _ğ‘–_ ( _ğ‘¥_ ) =



ï£±ï£´ï£´ï£´ï£²

ï£´ï£´ï£´ï£³



where _ğ‘‘_ (Â· _,_ - ) denotes the Euclidean distance.
This defines a maximization problem in which the rover is penalized for traversing yellow
obstacles and for deviating from the start and goal positions. The 15 red obstacles are enforced
as hard constraints: if the rover intersects a red square, the corresponding constraint returns the
total distance from the center to the intruding trajectory points; otherwise, it returns the negative
distance from the center to the closest trajectory point. The constraint _ğ‘_ _ğ‘–_ ( _ğ‘¥_ ) â‰¤ 0 ensures that a
trajectory solution avoids the _ğ‘–_ -th red obstacle.
For performance evaluation, both SCBO and FuRBO are initialized with 100 samples, use a
batch size of 100, and are run for a total budget of 2000 evaluations. As shown in Figure 18b, SCBOâ€™s
convergence stagnates at a lower reward value compared to FuRBO.


27


(a) Trajectory planning problem. (b) Convergence.


Figure 18: Study on the trajectory-finding problem of a rover in dimension 60, under 15 constraints. (a)
Visualization of the design domain problem and a trajectory solution. The yellow squares
represent the obstacles the rover can overcome at a pre-fixed cost. The red squares represent
the obstacles the rover must avoid (hard constraints). The blue line is a trajectory solution
from the starting point (the white circle) to the goal point (the white cross). (b) Performance
comparison between SCBO and FuRBO, averaged over 10 independent runs per algorithm.



28


